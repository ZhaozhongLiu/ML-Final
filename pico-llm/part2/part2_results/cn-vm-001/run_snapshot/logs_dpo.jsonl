{"stage": "dpo", "step": 50, "epoch": 1, "train_loss": 0.5029582187533379, "policy_chosen_logp": -36.56062698364258, "policy_rejected_logp": -1050.893310546875, "ref_chosen_logp": -39.85821533203125, "ref_rejected_logp": -1008.321044921875, "chosen_reward": 0.32975900173187256, "rejected_reward": -4.257237434387207, "time": 1765817723.012861}
{"stage": "dpo", "step": 100, "epoch": 2, "train_loss": 0.3039641141891479, "policy_chosen_logp": -22.047653198242188, "policy_rejected_logp": -1014.4310302734375, "ref_chosen_logp": -28.513839721679688, "ref_rejected_logp": -935.84423828125, "chosen_reward": 0.6466187238693237, "rejected_reward": -7.858682632446289, "time": 1765817725.4834015}
{"stage": "dpo", "step": 150, "epoch": 3, "train_loss": 0.1598754981160164, "policy_chosen_logp": -34.39081573486328, "policy_rejected_logp": -1080.169677734375, "ref_chosen_logp": -35.609622955322266, "ref_rejected_logp": -1038.944580078125, "chosen_reward": 0.12188048660755157, "rejected_reward": -4.122521877288818, "time": 1765817727.9230182}
{"stage": "dpo", "step": 200, "epoch": 4, "train_loss": 0.053806072473526, "policy_chosen_logp": -28.4346923828125, "policy_rejected_logp": -1039.635986328125, "ref_chosen_logp": -22.964372634887695, "ref_rejected_logp": -982.9656372070312, "chosen_reward": -0.5470321178436279, "rejected_reward": -5.667027473449707, "time": 1765817730.3801703}
{"stage": "dpo", "step": 250, "epoch": 4, "train_loss": 0.4409725433588028, "policy_chosen_logp": -16.73525047302246, "policy_rejected_logp": -1052.77734375, "ref_chosen_logp": -22.346607208251953, "ref_rejected_logp": -996.0846557617188, "chosen_reward": 0.5611356496810913, "rejected_reward": -5.669271945953369, "time": 1765817732.8635352}
{"stage": "dpo", "step": 300, "epoch": 5, "train_loss": 0.3452859139442444, "policy_chosen_logp": -39.198486328125, "policy_rejected_logp": -1117.2879638671875, "ref_chosen_logp": -35.604698181152344, "ref_rejected_logp": -1051.2008056640625, "chosen_reward": -0.35937902331352234, "rejected_reward": -6.608708381652832, "time": 1765817735.3035293}
{"stage": "dpo", "step": 320, "epoch": 5, "val_pref_acc": 1.0, "time": 1765817736.4215255}
{"stage": "dpo", "step": 350, "epoch": 6, "train_loss": 0.199198617041111, "policy_chosen_logp": -38.401302337646484, "policy_rejected_logp": -1006.250244140625, "ref_chosen_logp": -36.2664794921875, "ref_rejected_logp": -954.6156005859375, "chosen_reward": -0.21348223090171814, "rejected_reward": -5.1634626388549805, "time": 1765817737.7594016}
{"stage": "dpo", "step": 400, "epoch": 7, "train_loss": 0.09029918104410171, "policy_chosen_logp": -31.74014663696289, "policy_rejected_logp": -1097.0841064453125, "ref_chosen_logp": -33.10496520996094, "ref_rejected_logp": -1059.412109375, "chosen_reward": 0.13648182153701782, "rejected_reward": -3.767198324203491, "time": 1765817740.2295809}
{"stage": "dpo", "step": 450, "epoch": 8, "train_loss": 0.014119187593460083, "policy_chosen_logp": -38.80466079711914, "policy_rejected_logp": -1101.116455078125, "ref_chosen_logp": -44.074913024902344, "ref_rejected_logp": -1055.738525390625, "chosen_reward": 0.5270254015922546, "rejected_reward": -4.537802219390869, "time": 1765817742.7058947}
{"stage": "dpo", "step": 500, "epoch": 8, "train_loss": 0.334919938147068, "policy_chosen_logp": -44.17628479003906, "policy_rejected_logp": -1083.7789306640625, "ref_chosen_logp": -53.926055908203125, "ref_rejected_logp": -1053.268798828125, "chosen_reward": 0.9749774932861328, "rejected_reward": -3.0510146617889404, "time": 1765817745.186392}
{"stage": "dpo", "step": 550, "epoch": 9, "train_loss": 0.25674417585134507, "policy_chosen_logp": -24.533424377441406, "policy_rejected_logp": -1096.615478515625, "ref_chosen_logp": -34.98638153076172, "ref_rejected_logp": -1065.290283203125, "chosen_reward": 1.0452954769134521, "rejected_reward": -3.132534980773926, "time": 1765817747.6512702}
{"stage": "dpo", "step": 600, "epoch": 10, "train_loss": 0.1547129851579666, "policy_chosen_logp": -38.09822082519531, "policy_rejected_logp": -1062.85546875, "ref_chosen_logp": -44.55078887939453, "ref_rejected_logp": -1013.5609130859375, "chosen_reward": 0.6452568769454956, "rejected_reward": -4.929460525512695, "time": 1765817750.159091}
{"stage": "dpo", "step": 640, "epoch": 10, "val_pref_acc": 1.0, "time": 1765817752.353532}
{"stage": "dpo", "step": 650, "epoch": 11, "train_loss": 0.06477517932653427, "policy_chosen_logp": -17.461931228637695, "policy_rejected_logp": -1036.8109130859375, "ref_chosen_logp": -22.88429832458496, "ref_rejected_logp": -981.51025390625, "chosen_reward": 0.5422368049621582, "rejected_reward": -5.530059814453125, "time": 1765817752.764334}
{"stage": "dpo", "step": 700, "epoch": 11, "train_loss": 0.3187886714935303, "policy_chosen_logp": -40.22312927246094, "policy_rejected_logp": -1014.043212890625, "ref_chosen_logp": -40.48683547973633, "ref_rejected_logp": -962.52783203125, "chosen_reward": 0.02637055516242981, "rejected_reward": -5.1515398025512695, "time": 1765817755.1728482}
{"stage": "dpo", "step": 750, "epoch": 12, "train_loss": 0.2848296248912811, "policy_chosen_logp": -35.535064697265625, "policy_rejected_logp": -1125.1485595703125, "ref_chosen_logp": -41.49243927001953, "ref_rejected_logp": -1084.376953125, "chosen_reward": 0.5957373976707458, "rejected_reward": -4.077145576477051, "time": 1765817757.6790843}
{"stage": "dpo", "step": 800, "epoch": 13, "train_loss": 0.18717123478651046, "policy_chosen_logp": -38.25245666503906, "policy_rejected_logp": -1046.74560546875, "ref_chosen_logp": -45.21040344238281, "ref_rejected_logp": -1008.60546875, "chosen_reward": 0.6957946419715881, "rejected_reward": -3.8140106201171875, "time": 1765817760.1574624}
{"stage": "dpo", "step": 850, "epoch": 14, "train_loss": 0.1120907735824585, "policy_chosen_logp": -30.270902633666992, "policy_rejected_logp": -1001.679443359375, "ref_chosen_logp": -42.148170471191406, "ref_rejected_logp": -979.561767578125, "chosen_reward": 1.1877270936965942, "rejected_reward": -2.2117645740509033, "time": 1765817762.638116}
{"stage": "dpo", "step": 900, "epoch": 15, "train_loss": 0.020977796018123628, "policy_chosen_logp": -18.15976905822754, "policy_rejected_logp": -1050.015380859375, "ref_chosen_logp": -23.325820922851562, "ref_rejected_logp": -1004.0480346679688, "chosen_reward": 0.5166053771972656, "rejected_reward": -4.596726894378662, "time": 1765817765.114959}
{"stage": "dpo", "step": 950, "epoch": 15, "train_loss": 0.3048022073507309, "policy_chosen_logp": -32.265533447265625, "policy_rejected_logp": -1116.164794921875, "ref_chosen_logp": -36.942405700683594, "ref_rejected_logp": -1080.48779296875, "chosen_reward": 0.4676870107650757, "rejected_reward": -3.567683458328247, "time": 1765817767.5624616}
{"stage": "dpo", "step": 960, "epoch": 15, "val_pref_acc": 1.0, "time": 1765817768.1882527}
{"stage": "dpo", "step": 1000, "epoch": 16, "train_loss": 0.2531146019697189, "policy_chosen_logp": -27.053293228149414, "policy_rejected_logp": -1004.5222778320312, "ref_chosen_logp": -37.350074768066406, "ref_rejected_logp": -955.2908325195312, "chosen_reward": 1.0296783447265625, "rejected_reward": -4.9231462478637695, "time": 1765817770.07297}
{"stage": "dpo", "step": 1050, "epoch": 17, "train_loss": 0.16211493462324142, "policy_chosen_logp": -29.617359161376953, "policy_rejected_logp": -968.1676025390625, "ref_chosen_logp": -40.55804443359375, "ref_rejected_logp": -921.529296875, "chosen_reward": 1.0940687656402588, "rejected_reward": -4.6638336181640625, "time": 1765817772.2635064}
{"stage": "dpo", "step": 1100, "epoch": 18, "train_loss": 0.09598006188869476, "policy_chosen_logp": -23.595359802246094, "policy_rejected_logp": -1154.4105224609375, "ref_chosen_logp": -27.063018798828125, "ref_rejected_logp": -1089.705078125, "chosen_reward": 0.34676593542099, "rejected_reward": -6.470538139343262, "time": 1765817774.6123214}
{"stage": "dpo", "step": 1150, "epoch": 18, "train_loss": 0.32627311497926714, "policy_chosen_logp": -16.59303855895996, "policy_rejected_logp": -1091.923095703125, "ref_chosen_logp": -22.730712890625, "ref_rejected_logp": -1034.674560546875, "chosen_reward": 0.6137676239013672, "rejected_reward": -5.724862575531006, "time": 1765817777.0900338}
{"stage": "dpo", "step": 1200, "epoch": 19, "train_loss": 0.32183570057153704, "policy_chosen_logp": -33.58938217163086, "policy_rejected_logp": -1066.3009033203125, "ref_chosen_logp": -46.473731994628906, "ref_rejected_logp": -1062.574951171875, "chosen_reward": 1.2884347438812256, "rejected_reward": -0.37259674072265625, "time": 1765817779.544802}
{"stage": "dpo", "step": 1250, "epoch": 20, "train_loss": 0.21686528265476226, "policy_chosen_logp": -27.445844650268555, "policy_rejected_logp": -1071.4771728515625, "ref_chosen_logp": -29.58574867248535, "ref_rejected_logp": -1004.073974609375, "chosen_reward": 0.21399037539958954, "rejected_reward": -6.740316867828369, "time": 1765817782.0484107}
{"stage": "dpo", "step": 1280, "epoch": 20, "val_pref_acc": 1.0, "time": 1765817783.6628494}
{"stage": "dpo", "step": 1300, "epoch": 21, "train_loss": 0.12217122435569763, "policy_chosen_logp": -32.386558532714844, "policy_rejected_logp": -1144.5341796875, "ref_chosen_logp": -36.32338333129883, "ref_rejected_logp": -1105.21337890625, "chosen_reward": 0.3936827778816223, "rejected_reward": -3.9320647716522217, "time": 1765817784.5220568}
{"stage": "dpo", "step": 1350, "epoch": 22, "train_loss": 0.03859552383422851, "policy_chosen_logp": -49.52451705932617, "policy_rejected_logp": -1108.06640625, "ref_chosen_logp": -52.06901931762695, "ref_rejected_logp": -1048.0013427734375, "chosen_reward": 0.25445032119750977, "rejected_reward": -6.006507873535156, "time": 1765817787.0930548}
{"stage": "dpo", "step": 1400, "epoch": 22, "train_loss": 0.34051558792591097, "policy_chosen_logp": -38.75394821166992, "policy_rejected_logp": -1084.1378173828125, "ref_chosen_logp": -43.21636199951172, "ref_rejected_logp": -1055.67041015625, "chosen_reward": 0.4462414085865021, "rejected_reward": -2.8467469215393066, "time": 1765817789.6226854}
{"stage": "dpo", "step": 1450, "epoch": 23, "train_loss": 0.27594748347997666, "policy_chosen_logp": -34.5443229675293, "policy_rejected_logp": -1057.47314453125, "ref_chosen_logp": -44.818939208984375, "ref_rejected_logp": -1007.9891967773438, "chosen_reward": 1.0274617671966553, "rejected_reward": -4.948389053344727, "time": 1765817792.1636665}
{"stage": "dpo", "step": 1500, "epoch": 24, "train_loss": 0.17496927440166474, "policy_chosen_logp": -31.48026466369629, "policy_rejected_logp": -1040.6207275390625, "ref_chosen_logp": -35.25307846069336, "ref_rejected_logp": -977.3536376953125, "chosen_reward": 0.37728139758110046, "rejected_reward": -6.3267107009887695, "time": 1765817794.7801166}
{"stage": "dpo", "step": 1550, "epoch": 25, "train_loss": 0.08874775350093841, "policy_chosen_logp": -31.281139373779297, "policy_rejected_logp": -1030.82568359375, "ref_chosen_logp": -35.11198806762695, "ref_rejected_logp": -965.974365234375, "chosen_reward": 0.38308513164520264, "rejected_reward": -6.485133647918701, "time": 1765817797.3261156}
{"stage": "dpo", "step": 1600, "epoch": 25, "train_loss": 0.3050769978761673, "policy_chosen_logp": -26.2497501373291, "policy_rejected_logp": -1070.567138671875, "ref_chosen_logp": -33.2944450378418, "ref_rejected_logp": -1028.6934814453125, "chosen_reward": 0.7044692039489746, "rejected_reward": -4.187376499176025, "time": 1765817799.8761835}
{"stage": "dpo", "step": 1600, "epoch": 25, "val_pref_acc": 1.0, "time": 1765817800.00392}
{"stage": "dpo", "step": 1650, "epoch": 26, "train_loss": 0.3203535440564156, "policy_chosen_logp": -30.858470916748047, "policy_rejected_logp": -1149.084228515625, "ref_chosen_logp": -38.828834533691406, "ref_rejected_logp": -1095.18212890625, "chosen_reward": 0.7970362305641174, "rejected_reward": -5.390203952789307, "time": 1765817802.3874006}
{"stage": "dpo", "step": 1700, "epoch": 27, "train_loss": 0.22236448109149934, "policy_chosen_logp": -26.80520248413086, "policy_rejected_logp": -1100.47021484375, "ref_chosen_logp": -27.67153549194336, "ref_rejected_logp": -1071.8603515625, "chosen_reward": 0.08663308620452881, "rejected_reward": -2.8609910011291504, "time": 1765817804.8710396}
{"stage": "dpo", "step": 1750, "epoch": 28, "train_loss": 0.14313822388648986, "policy_chosen_logp": -38.99595642089844, "policy_rejected_logp": -1176.7969970703125, "ref_chosen_logp": -35.86203384399414, "ref_rejected_logp": -1145.956787109375, "chosen_reward": -0.3133922219276428, "rejected_reward": -3.084023952484131, "time": 1765817807.3831706}
{"stage": "dpo", "step": 1800, "epoch": 29, "train_loss": 0.04871619194746017, "policy_chosen_logp": -37.7586669921875, "policy_rejected_logp": -1017.22412109375, "ref_chosen_logp": -48.939598083496094, "ref_rejected_logp": -967.9261474609375, "chosen_reward": 1.1180931329727173, "rejected_reward": -4.9297990798950195, "time": 1765817809.6718612}
{"stage": "dpo", "step": 1850, "epoch": 29, "train_loss": 0.3148310425877571, "policy_chosen_logp": -24.93095588684082, "policy_rejected_logp": -1050.87158203125, "ref_chosen_logp": -26.38976287841797, "ref_rejected_logp": -1025.2994384765625, "chosen_reward": 0.14588075876235962, "rejected_reward": -2.5572144985198975, "time": 1765817811.8068779}
{"stage": "dpo", "step": 1900, "epoch": 30, "train_loss": 0.26336034685373305, "policy_chosen_logp": -27.913291931152344, "policy_rejected_logp": -1129.6611328125, "ref_chosen_logp": -31.29322624206543, "ref_rejected_logp": -1090.437255859375, "chosen_reward": 0.33799344301223755, "rejected_reward": -3.922372579574585, "time": 1765817813.9086905}
{"stage": "dpo", "step": 1920, "epoch": 30, "val_pref_acc": 1.0, "time": 1765817815.0275266}
{"stage": "dpo", "step": 1950, "epoch": 31, "train_loss": 0.17700485438108443, "policy_chosen_logp": -26.020263671875, "policy_rejected_logp": -1033.3660888671875, "ref_chosen_logp": -30.39211654663086, "ref_rejected_logp": -984.4833984375, "chosen_reward": 0.43718525767326355, "rejected_reward": -4.8882646560668945, "time": 1765817816.390995}
{"stage": "dpo", "step": 2000, "epoch": 32, "train_loss": 0.10705531120300293, "policy_chosen_logp": -31.48611831665039, "policy_rejected_logp": -1107.8876953125, "ref_chosen_logp": -41.62106704711914, "ref_rejected_logp": -1070.871826171875, "chosen_reward": 1.0134949684143066, "rejected_reward": -3.7015929222106934, "time": 1765817818.8760512}
{"stage": "dpo", "step": 2050, "epoch": 33, "train_loss": 0.010344327688217162, "policy_chosen_logp": -26.559452056884766, "policy_rejected_logp": -990.273681640625, "ref_chosen_logp": -34.28812026977539, "ref_rejected_logp": -949.5897827148438, "chosen_reward": 0.7728668451309204, "rejected_reward": -4.06838846206665, "time": 1765817821.3821495}
{"stage": "dpo", "step": 2100, "epoch": 33, "train_loss": 0.29117667347192766, "policy_chosen_logp": -31.862285614013672, "policy_rejected_logp": -1110.6142578125, "ref_chosen_logp": -42.34442901611328, "ref_rejected_logp": -1074.3782958984375, "chosen_reward": 1.0482146739959717, "rejected_reward": -3.6236069202423096, "time": 1765817823.8746076}
{"stage": "dpo", "step": 2150, "epoch": 34, "train_loss": 0.22057547986507417, "policy_chosen_logp": -30.257076263427734, "policy_rejected_logp": -1017.3033447265625, "ref_chosen_logp": -29.707550048828125, "ref_rejected_logp": -985.77392578125, "chosen_reward": -0.05495283007621765, "rejected_reward": -3.1529436111450195, "time": 1765817826.3498828}
{"stage": "dpo", "step": 2200, "epoch": 35, "train_loss": 0.14982210099697113, "policy_chosen_logp": -38.057533264160156, "policy_rejected_logp": -1062.609375, "ref_chosen_logp": -46.139530181884766, "ref_rejected_logp": -1022.8115844726562, "chosen_reward": 0.8081998229026794, "rejected_reward": -3.9797821044921875, "time": 1765817828.820392}
{"stage": "dpo", "step": 2240, "epoch": 35, "val_pref_acc": 1.0, "time": 1765817830.9212935}
{"stage": "dpo", "step": 2250, "epoch": 36, "train_loss": 0.055889843106269835, "policy_chosen_logp": -26.096309661865234, "policy_rejected_logp": -1046.562744140625, "ref_chosen_logp": -38.9844970703125, "ref_rejected_logp": -1022.0067138671875, "chosen_reward": 1.2888187170028687, "rejected_reward": -2.4555985927581787, "time": 1765817831.312312}
{"stage": "dpo", "step": 2300, "epoch": 36, "train_loss": 0.28838333159685137, "policy_chosen_logp": -27.334747314453125, "policy_rejected_logp": -1099.751220703125, "ref_chosen_logp": -28.65609359741211, "ref_rejected_logp": -1043.830810546875, "chosen_reward": 0.13213461637496948, "rejected_reward": -5.592038154602051, "time": 1765817833.8141286}
{"stage": "dpo", "step": 2350, "epoch": 37, "train_loss": 0.2770215234160423, "policy_chosen_logp": -26.55552864074707, "policy_rejected_logp": -1195.12255859375, "ref_chosen_logp": -35.19499969482422, "ref_rejected_logp": -1140.619873046875, "chosen_reward": 0.8639472723007202, "rejected_reward": -5.450259208679199, "time": 1765817836.316252}
{"stage": "dpo", "step": 2400, "epoch": 38, "train_loss": 0.1910734596848488, "policy_chosen_logp": -27.074417114257812, "policy_rejected_logp": -953.8508911132812, "ref_chosen_logp": -37.914188385009766, "ref_rejected_logp": -910.9578857421875, "chosen_reward": 1.083977222442627, "rejected_reward": -4.289300918579102, "time": 1765817838.8132088}
{"stage": "dpo", "step": 2450, "epoch": 39, "train_loss": 0.1257917684316635, "policy_chosen_logp": -32.37797546386719, "policy_rejected_logp": -1170.76806640625, "ref_chosen_logp": -34.31086349487305, "ref_rejected_logp": -1117.353271484375, "chosen_reward": 0.1932886838912964, "rejected_reward": -5.341477870941162, "time": 1765817841.2912934}
{"stage": "dpo", "step": 2500, "epoch": 40, "train_loss": 0.021083769500255586, "policy_chosen_logp": -31.00643539428711, "policy_rejected_logp": -1105.807861328125, "ref_chosen_logp": -29.20248794555664, "ref_rejected_logp": -1066.807861328125, "chosen_reward": -0.18039476871490479, "rejected_reward": -3.9000015258789062, "time": 1765817843.6360915}
{"stage": "dpo", "step": 2550, "epoch": 40, "train_loss": 0.2817645660042763, "policy_chosen_logp": -23.959327697753906, "policy_rejected_logp": -1063.30908203125, "ref_chosen_logp": -26.560489654541016, "ref_rejected_logp": -999.9144897460938, "chosen_reward": 0.26011598110198975, "rejected_reward": -6.339447021484375, "time": 1765817846.091174}
{"stage": "dpo", "step": 2560, "epoch": 40, "val_pref_acc": 1.0, "time": 1765817846.7124538}
{"stage": "dpo", "step": 2600, "epoch": 41, "train_loss": 0.24521319657564164, "policy_chosen_logp": -26.776779174804688, "policy_rejected_logp": -1094.1658935546875, "ref_chosen_logp": -35.29263687133789, "ref_rejected_logp": -1070.3209228515625, "chosen_reward": 0.8515858054161072, "rejected_reward": -2.3844878673553467, "time": 1765817848.5838852}
{"stage": "dpo", "step": 2650, "epoch": 42, "train_loss": 0.14606423497200013, "policy_chosen_logp": -30.393707275390625, "policy_rejected_logp": -1026.52099609375, "ref_chosen_logp": -42.69108581542969, "ref_rejected_logp": -990.8265380859375, "chosen_reward": 1.2297378778457642, "rejected_reward": -3.5694565773010254, "time": 1765817851.0763671}
{"stage": "dpo", "step": 2700, "epoch": 43, "train_loss": 0.07675852119922638, "policy_chosen_logp": -31.19357681274414, "policy_rejected_logp": -1085.537109375, "ref_chosen_logp": -36.36152648925781, "ref_rejected_logp": -1050.8514404296875, "chosen_reward": 0.5167951583862305, "rejected_reward": -3.4685685634613037, "time": 1765817853.560905}
{"stage": "dpo", "step": 2750, "epoch": 43, "train_loss": 0.2878130176663399, "policy_chosen_logp": -31.33072853088379, "policy_rejected_logp": -1148.6260986328125, "ref_chosen_logp": -38.725528717041016, "ref_rejected_logp": -1107.674072265625, "chosen_reward": 0.7394800186157227, "rejected_reward": -4.0952043533325195, "time": 1765817856.0394788}
{"stage": "dpo", "step": 2800, "epoch": 44, "train_loss": 0.2771138975024223, "policy_chosen_logp": -33.48997116088867, "policy_rejected_logp": -1092.90673828125, "ref_chosen_logp": -40.12462615966797, "ref_rejected_logp": -1034.375732421875, "chosen_reward": 0.6634653806686401, "rejected_reward": -5.853093147277832, "time": 1765817858.522969}
{"stage": "dpo", "step": 2850, "epoch": 45, "train_loss": 0.1967783260345459, "policy_chosen_logp": -23.616817474365234, "policy_rejected_logp": -1055.587890625, "ref_chosen_logp": -32.5334587097168, "ref_rejected_logp": -1016.563232421875, "chosen_reward": 0.8916640281677246, "rejected_reward": -3.9024736881256104, "time": 1765817860.9933777}
{"stage": "dpo", "step": 2880, "epoch": 45, "val_pref_acc": 1.0, "time": 1765817862.6016066}
{"stage": "dpo", "step": 2900, "epoch": 46, "train_loss": 0.1113037520647049, "policy_chosen_logp": -22.227333068847656, "policy_rejected_logp": -1078.2548828125, "ref_chosen_logp": -25.24657440185547, "ref_rejected_logp": -1026.89013671875, "chosen_reward": 0.3019242584705353, "rejected_reward": -5.136470317840576, "time": 1765817863.4581678}
{"stage": "dpo", "step": 2950, "epoch": 47, "train_loss": 0.03567436963319778, "policy_chosen_logp": -22.525531768798828, "policy_rejected_logp": -1088.121337890625, "ref_chosen_logp": -34.97930908203125, "ref_rejected_logp": -1068.179443359375, "chosen_reward": 1.2453774213790894, "rejected_reward": -1.99419105052948, "time": 1765817865.9285629}
{"stage": "dpo", "step": 3000, "epoch": 47, "train_loss": 0.2791532164812088, "policy_chosen_logp": -32.729347229003906, "policy_rejected_logp": -971.256591796875, "ref_chosen_logp": -34.96116638183594, "ref_rejected_logp": -921.3802490234375, "chosen_reward": 0.22318238019943237, "rejected_reward": -4.987637519836426, "time": 1765817868.3845153}
{"stage": "dpo", "step": 3050, "epoch": 48, "train_loss": 0.25901399344205855, "policy_chosen_logp": -29.03995132446289, "policy_rejected_logp": -1067.982421875, "ref_chosen_logp": -34.04487228393555, "ref_rejected_logp": -1040.164306640625, "chosen_reward": 0.5004919767379761, "rejected_reward": -2.7818145751953125, "time": 1765817870.850147}
{"stage": "dpo", "step": 3100, "epoch": 49, "train_loss": 0.16434600621461867, "policy_chosen_logp": -38.8460578918457, "policy_rejected_logp": -1141.98095703125, "ref_chosen_logp": -38.086936950683594, "ref_rejected_logp": -1105.038330078125, "chosen_reward": -0.07591228932142258, "rejected_reward": -3.694272041320801, "time": 1765817873.0777278}
{"stage": "dpo", "step": 3150, "epoch": 50, "train_loss": 0.07641271859407425, "policy_chosen_logp": -27.148670196533203, "policy_rejected_logp": -1066.500244140625, "ref_chosen_logp": -34.200164794921875, "ref_rejected_logp": -1034.62158203125, "chosen_reward": 0.7051492929458618, "rejected_reward": -3.187870979309082, "time": 1765817875.1028767}
{"stage": "dpo", "step": 3200, "epoch": 50, "train_loss": 0.28759466886520385, "policy_chosen_logp": -22.289608001708984, "policy_rejected_logp": -1130.369384765625, "ref_chosen_logp": -24.37937355041504, "ref_rejected_logp": -1086.9658203125, "chosen_reward": 0.20897644758224487, "rejected_reward": -4.340359687805176, "time": 1765817877.6283524}
{"stage": "dpo", "step": 3200, "epoch": 50, "val_pref_acc": 1.0, "time": 1765817877.7559586}
{"stage": "dpo", "step": 3250, "epoch": 51, "train_loss": 0.30619181811809537, "policy_chosen_logp": -31.390291213989258, "policy_rejected_logp": -986.4876708984375, "ref_chosen_logp": -38.40119171142578, "ref_rejected_logp": -954.9880981445312, "chosen_reward": 0.7010900974273682, "rejected_reward": -3.1499574184417725, "time": 1765817880.1676788}
{"stage": "dpo", "step": 3300, "epoch": 52, "train_loss": 0.20290104150772095, "policy_chosen_logp": -25.654991149902344, "policy_rejected_logp": -1180.737548828125, "ref_chosen_logp": -29.131853103637695, "ref_rejected_logp": -1157.399658203125, "chosen_reward": 0.3476863503456116, "rejected_reward": -2.333782911300659, "time": 1765817882.7021217}
{"stage": "dpo", "step": 3350, "epoch": 53, "train_loss": 0.12315831869840622, "policy_chosen_logp": -29.116966247558594, "policy_rejected_logp": -1048.8116455078125, "ref_chosen_logp": -32.15932846069336, "ref_rejected_logp": -990.7886962890625, "chosen_reward": 0.30423611402511597, "rejected_reward": -5.802299499511719, "time": 1765817885.1617327}
{"stage": "dpo", "step": 3400, "epoch": 54, "train_loss": 0.05424718379974365, "policy_chosen_logp": -25.843341827392578, "policy_rejected_logp": -1071.127197265625, "ref_chosen_logp": -35.694488525390625, "ref_rejected_logp": -1025.896728515625, "chosen_reward": 0.9851144552230835, "rejected_reward": -4.523048400878906, "time": 1765817887.7755024}
{"stage": "dpo", "step": 3450, "epoch": 54, "train_loss": 0.27954732567071916, "policy_chosen_logp": -22.624801635742188, "policy_rejected_logp": -1006.53076171875, "ref_chosen_logp": -27.55480194091797, "ref_rejected_logp": -955.20849609375, "chosen_reward": 0.4930000901222229, "rejected_reward": -5.1322221755981445, "time": 1765817890.2580736}
{"stage": "dpo", "step": 3500, "epoch": 55, "train_loss": 0.2378113654255867, "policy_chosen_logp": -21.47292137145996, "policy_rejected_logp": -1136.3167724609375, "ref_chosen_logp": -40.02973556518555, "ref_rejected_logp": -1108.5279541015625, "chosen_reward": 1.8556814193725586, "rejected_reward": -2.7788803577423096, "time": 1765817892.6601431}
{"stage": "dpo", "step": 3520, "epoch": 55, "val_pref_acc": 1.0, "time": 1765817893.7770705}
{"stage": "dpo", "step": 3550, "epoch": 56, "train_loss": 0.15864291787147522, "policy_chosen_logp": -24.19599151611328, "policy_rejected_logp": -1079.5634765625, "ref_chosen_logp": -33.120201110839844, "ref_rejected_logp": -1038.682861328125, "chosen_reward": 0.8924208283424377, "rejected_reward": -4.088066101074219, "time": 1765817895.1301265}
{"stage": "dpo", "step": 3600, "epoch": 57, "train_loss": 0.08552529603242874, "policy_chosen_logp": -31.86650848388672, "policy_rejected_logp": -1109.082275390625, "ref_chosen_logp": -33.93190002441406, "ref_rejected_logp": -1074.714599609375, "chosen_reward": 0.20653921365737915, "rejected_reward": -3.436764717102051, "time": 1765817897.5888314}
{"stage": "dpo", "step": 3650, "epoch": 58, "train_loss": 0.009997878968715668, "policy_chosen_logp": -27.629579544067383, "policy_rejected_logp": -1017.1317138671875, "ref_chosen_logp": -38.83271789550781, "ref_rejected_logp": -988.3673095703125, "chosen_reward": 1.1203138828277588, "rejected_reward": -2.8764495849609375, "time": 1765817900.0882137}
{"stage": "dpo", "step": 3700, "epoch": 58, "train_loss": 0.27001213520765305, "policy_chosen_logp": -37.257911682128906, "policy_rejected_logp": -1129.3177490234375, "ref_chosen_logp": -53.5091667175293, "ref_rejected_logp": -1098.980224609375, "chosen_reward": 1.6251252889633179, "rejected_reward": -3.033738613128662, "time": 1765817902.580978}
{"stage": "dpo", "step": 3750, "epoch": 59, "train_loss": 0.22591486990451812, "policy_chosen_logp": -15.497660636901855, "policy_rejected_logp": -1017.4683837890625, "ref_chosen_logp": -28.042320251464844, "ref_rejected_logp": -977.578125, "chosen_reward": 1.2544660568237305, "rejected_reward": -3.989025831222534, "time": 1765817905.0547316}
{"stage": "dpo", "step": 3800, "epoch": 60, "train_loss": 0.13368456810712814, "policy_chosen_logp": -27.643177032470703, "policy_rejected_logp": -1070.16845703125, "ref_chosen_logp": -31.53166389465332, "ref_rejected_logp": -1025.5, "chosen_reward": 0.3888486623764038, "rejected_reward": -4.466836929321289, "time": 1765817907.5497735}
{"stage": "dpo", "step": 3840, "epoch": 60, "val_pref_acc": 1.0, "time": 1765817909.671148}
{"stage": "dpo", "step": 3850, "epoch": 61, "train_loss": 0.05949244886636734, "policy_chosen_logp": -33.63707733154297, "policy_rejected_logp": -1001.3228149414062, "ref_chosen_logp": -42.25670623779297, "ref_rejected_logp": -971.0337524414062, "chosen_reward": 0.8619626760482788, "rejected_reward": -3.0289032459259033, "time": 1765817910.070282}
{"stage": "dpo", "step": 3900, "epoch": 61, "train_loss": 0.2793137195706368, "policy_chosen_logp": -23.44692611694336, "policy_rejected_logp": -1131.0078125, "ref_chosen_logp": -35.63048553466797, "ref_rejected_logp": -1091.560302734375, "chosen_reward": 1.2183558940887451, "rejected_reward": -3.9447600841522217, "time": 1765817912.5256476}
{"stage": "dpo", "step": 3950, "epoch": 62, "train_loss": 0.2599245139956474, "policy_chosen_logp": -14.811872482299805, "policy_rejected_logp": -1062.9375, "ref_chosen_logp": -14.986808776855469, "ref_rejected_logp": -1012.0531616210938, "chosen_reward": 0.01749364286661148, "rejected_reward": -5.088421821594238, "time": 1765817915.0201538}
{"stage": "dpo", "step": 4000, "epoch": 63, "train_loss": 0.2006335324048996, "policy_chosen_logp": -27.943960189819336, "policy_rejected_logp": -1100.1611328125, "ref_chosen_logp": -36.83641815185547, "ref_rejected_logp": -1051.588623046875, "chosen_reward": 0.8892459869384766, "rejected_reward": -4.857261657714844, "time": 1765817917.5218093}
{"stage": "dpo", "step": 4050, "epoch": 64, "train_loss": 0.0987752702832222, "policy_chosen_logp": -22.029056549072266, "policy_rejected_logp": -1033.606201171875, "ref_chosen_logp": -24.305917739868164, "ref_rejected_logp": -1002.725830078125, "chosen_reward": 0.2276861071586609, "rejected_reward": -3.088038682937622, "time": 1765817919.9625728}
{"stage": "dpo", "step": 4100, "epoch": 65, "train_loss": 0.024944225549697874, "policy_chosen_logp": -32.536094665527344, "policy_rejected_logp": -1159.921142578125, "ref_chosen_logp": -42.133766174316406, "ref_rejected_logp": -1110.3271484375, "chosen_reward": 0.9597670435905457, "rejected_reward": -4.959417343139648, "time": 1765817922.5156908}
{"stage": "dpo", "step": 4150, "epoch": 65, "train_loss": 0.2988571187853813, "policy_chosen_logp": -21.48984146118164, "policy_rejected_logp": -1053.7252197265625, "ref_chosen_logp": -25.328380584716797, "ref_rejected_logp": -1019.9913330078125, "chosen_reward": 0.3838537931442261, "rejected_reward": -3.373396396636963, "time": 1765817925.061099}
{"stage": "dpo", "step": 4160, "epoch": 65, "val_pref_acc": 1.0, "time": 1765817925.7077773}
{"stage": "dpo", "step": 4200, "epoch": 66, "train_loss": 0.22086889743804933, "policy_chosen_logp": -34.59789276123047, "policy_rejected_logp": -989.5188598632812, "ref_chosen_logp": -42.765716552734375, "ref_rejected_logp": -963.7431640625, "chosen_reward": 0.8167822957038879, "rejected_reward": -2.577571153640747, "time": 1765817927.6285715}
{"stage": "dpo", "step": 4250, "epoch": 67, "train_loss": 0.1410761594772339, "policy_chosen_logp": -35.648475646972656, "policy_rejected_logp": -1105.97412109375, "ref_chosen_logp": -42.52902603149414, "ref_rejected_logp": -1066.490478515625, "chosen_reward": 0.6880547404289246, "rejected_reward": -3.9483704566955566, "time": 1765817930.136062}
{"stage": "dpo", "step": 4300, "epoch": 68, "train_loss": 0.06938396751880646, "policy_chosen_logp": -16.96062660217285, "policy_rejected_logp": -1066.4617919921875, "ref_chosen_logp": -25.531688690185547, "ref_rejected_logp": -1027.51318359375, "chosen_reward": 0.8571062088012695, "rejected_reward": -3.8948519229888916, "time": 1765817932.6513593}
{"stage": "dpo", "step": 4350, "epoch": 68, "train_loss": 0.28882263630628585, "policy_chosen_logp": -26.00167465209961, "policy_rejected_logp": -1108.93212890625, "ref_chosen_logp": -34.717655181884766, "ref_rejected_logp": -1080.951904296875, "chosen_reward": 0.8715980052947998, "rejected_reward": -2.798020839691162, "time": 1765817935.1197834}
{"stage": "dpo", "step": 4400, "epoch": 69, "train_loss": 0.2823990896344185, "policy_chosen_logp": -26.858057022094727, "policy_rejected_logp": -1069.7381591796875, "ref_chosen_logp": -44.824424743652344, "ref_rejected_logp": -1038.5634765625, "chosen_reward": 1.796636700630188, "rejected_reward": -3.1174745559692383, "time": 1765817937.6475842}
{"stage": "dpo", "step": 4450, "epoch": 70, "train_loss": 0.19543678760528566, "policy_chosen_logp": -29.983457565307617, "policy_rejected_logp": -1170.689453125, "ref_chosen_logp": -38.40531921386719, "ref_rejected_logp": -1152.4521484375, "chosen_reward": 0.8421860933303833, "rejected_reward": -1.8237152099609375, "time": 1765817940.1294177}
{"stage": "dpo", "step": 4480, "epoch": 70, "val_pref_acc": 1.0, "time": 1765817941.7283492}
{"stage": "dpo", "step": 4500, "epoch": 71, "train_loss": 0.11464444130659103, "policy_chosen_logp": -15.679998397827148, "policy_rejected_logp": -1073.1605224609375, "ref_chosen_logp": -21.69479751586914, "ref_rejected_logp": -1041.704345703125, "chosen_reward": 0.6014798283576965, "rejected_reward": -3.1456174850463867, "time": 1765817942.6097434}
{"stage": "dpo", "step": 4550, "epoch": 72, "train_loss": 0.032991276383399964, "policy_chosen_logp": -17.14167594909668, "policy_rejected_logp": -989.1119995117188, "ref_chosen_logp": -25.742399215698242, "ref_rejected_logp": -968.0807495117188, "chosen_reward": 0.8600724935531616, "rejected_reward": -2.1031250953674316, "time": 1765817945.1172762}
{"stage": "dpo", "step": 4600, "epoch": 72, "train_loss": 0.28942255228757857, "policy_chosen_logp": -28.39887237548828, "policy_rejected_logp": -1024.343017578125, "ref_chosen_logp": -39.496803283691406, "ref_rejected_logp": -1001.3582763671875, "chosen_reward": 1.1097933053970337, "rejected_reward": -2.2984681129455566, "time": 1765817947.5876906}
{"stage": "dpo", "step": 4650, "epoch": 73, "train_loss": 0.2261812859773636, "policy_chosen_logp": -25.540443420410156, "policy_rejected_logp": -963.1856079101562, "ref_chosen_logp": -39.39051818847656, "ref_rejected_logp": -941.5376586914062, "chosen_reward": 1.385007619857788, "rejected_reward": -2.164794921875, "time": 1765817950.072539}
{"stage": "dpo", "step": 4700, "epoch": 74, "train_loss": 0.15572987914085387, "policy_chosen_logp": -17.5496768951416, "policy_rejected_logp": -1009.479736328125, "ref_chosen_logp": -26.752107620239258, "ref_rejected_logp": -980.8370971679688, "chosen_reward": 0.9202430844306946, "rejected_reward": -2.8642578125, "time": 1765817952.364677}
{"stage": "dpo", "step": 4750, "epoch": 75, "train_loss": 0.09045434802770615, "policy_chosen_logp": -29.314361572265625, "policy_rejected_logp": -1062.25146484375, "ref_chosen_logp": -39.07948303222656, "ref_rejected_logp": -1037.257080078125, "chosen_reward": 0.97651207447052, "rejected_reward": -2.4994475841522217, "time": 1765817954.8521557}
{"stage": "dpo", "step": 4800, "epoch": 75, "train_loss": 0.2771601048111916, "policy_chosen_logp": -20.24801254272461, "policy_rejected_logp": -1108.853271484375, "ref_chosen_logp": -32.470130920410156, "ref_rejected_logp": -1086.2564697265625, "chosen_reward": 1.2222118377685547, "rejected_reward": -2.2596774101257324, "time": 1765817957.3568816}
{"stage": "dpo", "step": 4800, "epoch": 75, "val_pref_acc": 1.0, "time": 1765817957.4850056}
{"stage": "dpo", "step": 4850, "epoch": 76, "train_loss": 0.27579091489315033, "policy_chosen_logp": -21.912107467651367, "policy_rejected_logp": -1057.8345947265625, "ref_chosen_logp": -32.4078254699707, "ref_rejected_logp": -1031.5347900390625, "chosen_reward": 1.0495718717575073, "rejected_reward": -2.6299850940704346, "time": 1765817959.819031}
{"stage": "dpo", "step": 4900, "epoch": 77, "train_loss": 0.18651207238435746, "policy_chosen_logp": -27.01976776123047, "policy_rejected_logp": -1098.765380859375, "ref_chosen_logp": -38.956729888916016, "ref_rejected_logp": -1069.2781982421875, "chosen_reward": 1.1936962604522705, "rejected_reward": -2.948704719543457, "time": 1765817962.3021216}
{"stage": "dpo", "step": 4950, "epoch": 78, "train_loss": 0.11201830953359604, "policy_chosen_logp": -24.21267318725586, "policy_rejected_logp": -1126.2364501953125, "ref_chosen_logp": -33.13971710205078, "ref_rejected_logp": -1095.8175048828125, "chosen_reward": 0.8927046060562134, "rejected_reward": -3.041896343231201, "time": 1765817964.631028}
{"stage": "dpo", "step": 5000, "epoch": 79, "train_loss": 0.041637228429317476, "policy_chosen_logp": -19.09330940246582, "policy_rejected_logp": -1023.30908203125, "ref_chosen_logp": -26.590553283691406, "ref_rejected_logp": -1004.5032958984375, "chosen_reward": 0.749724268913269, "rejected_reward": -1.880589246749878, "time": 1765817967.12849}
{"stage": "dpo", "step": 5050, "epoch": 79, "train_loss": 0.29453671544790266, "policy_chosen_logp": -24.1812801361084, "policy_rejected_logp": -995.9920654296875, "ref_chosen_logp": -35.062232971191406, "ref_rejected_logp": -962.1294555664062, "chosen_reward": 1.0880951881408691, "rejected_reward": -3.3862595558166504, "time": 1765817969.7059922}
{"stage": "dpo", "step": 5100, "epoch": 80, "train_loss": 0.24777566015720368, "policy_chosen_logp": -22.110782623291016, "policy_rejected_logp": -1175.4462890625, "ref_chosen_logp": -36.61030197143555, "ref_rejected_logp": -1150.651611328125, "chosen_reward": 1.4499520063400269, "rejected_reward": -2.479464530944824, "time": 1765817972.2744381}
{"stage": "dpo", "step": 5120, "epoch": 80, "val_pref_acc": 1.0, "time": 1765817973.439132}
{"stage": "dpo", "step": 5150, "epoch": 81, "train_loss": 0.16186779379844665, "policy_chosen_logp": -19.910327911376953, "policy_rejected_logp": -1147.16162109375, "ref_chosen_logp": -30.066261291503906, "ref_rejected_logp": -1132.9891357421875, "chosen_reward": 1.01559317111969, "rejected_reward": -1.4172577857971191, "time": 1765817974.8077047}
{"stage": "dpo", "step": 5200, "epoch": 82, "train_loss": 0.08725225180387497, "policy_chosen_logp": -34.46598815917969, "policy_rejected_logp": -1069.1663818359375, "ref_chosen_logp": -49.15230941772461, "ref_rejected_logp": -1039.845703125, "chosen_reward": 1.4686321020126343, "rejected_reward": -2.9320709705352783, "time": 1765817977.2777846}
{"stage": "dpo", "step": 5250, "epoch": 83, "train_loss": 0.010362692475318909, "policy_chosen_logp": -36.077754974365234, "policy_rejected_logp": -1113.941650390625, "ref_chosen_logp": -47.33062744140625, "ref_rejected_logp": -1078.783447265625, "chosen_reward": 1.1252871751785278, "rejected_reward": -3.515821933746338, "time": 1765817979.7616677}
{"stage": "dpo", "step": 5300, "epoch": 83, "train_loss": 0.27418217837810516, "policy_chosen_logp": -13.610414505004883, "policy_rejected_logp": -1043.0478515625, "ref_chosen_logp": -27.90909194946289, "ref_rejected_logp": -1026.373046875, "chosen_reward": 1.4298678636550903, "rejected_reward": -1.6674728393554688, "time": 1765817982.3047562}
{"stage": "dpo", "step": 5350, "epoch": 84, "train_loss": 0.20624498277902603, "policy_chosen_logp": -24.315448760986328, "policy_rejected_logp": -1037.225830078125, "ref_chosen_logp": -31.046907424926758, "ref_rejected_logp": -999.30029296875, "chosen_reward": 0.6731458902359009, "rejected_reward": -3.7925615310668945, "time": 1765817984.7569866}
{"stage": "dpo", "step": 5400, "epoch": 85, "train_loss": 0.13765753507614137, "policy_chosen_logp": -20.04819107055664, "policy_rejected_logp": -1092.505859375, "ref_chosen_logp": -24.33445930480957, "ref_rejected_logp": -1036.688720703125, "chosen_reward": 0.4286268949508667, "rejected_reward": -5.58171272277832, "time": 1765817987.2257485}
{"stage": "dpo", "step": 5440, "epoch": 85, "val_pref_acc": 1.0, "time": 1765817989.3359993}
{"stage": "dpo", "step": 5450, "epoch": 86, "train_loss": 0.05638532996177673, "policy_chosen_logp": -19.55561065673828, "policy_rejected_logp": -1042.2655029296875, "ref_chosen_logp": -30.38720703125, "ref_rejected_logp": -1016.7706909179688, "chosen_reward": 1.0831596851348877, "rejected_reward": -2.5494751930236816, "time": 1765817989.7359102}
{"stage": "dpo", "step": 5500, "epoch": 86, "train_loss": 0.2655507308244705, "policy_chosen_logp": -27.847061157226562, "policy_rejected_logp": -1026.718017578125, "ref_chosen_logp": -37.633216857910156, "ref_rejected_logp": -999.2125244140625, "chosen_reward": 0.9786158800125122, "rejected_reward": -2.7505478858947754, "time": 1765817992.185245}
{"stage": "dpo", "step": 5550, "epoch": 87, "train_loss": 0.24846701353788375, "policy_chosen_logp": -21.058414459228516, "policy_rejected_logp": -1118.77685546875, "ref_chosen_logp": -27.67227554321289, "ref_rejected_logp": -1078.5413818359375, "chosen_reward": 0.6613863110542297, "rejected_reward": -4.0235443115234375, "time": 1765817994.6532686}
{"stage": "dpo", "step": 5600, "epoch": 88, "train_loss": 0.16604384541511535, "policy_chosen_logp": -19.526859283447266, "policy_rejected_logp": -1060.6636962890625, "ref_chosen_logp": -32.106529235839844, "ref_rejected_logp": -1034.569091796875, "chosen_reward": 1.2579668760299683, "rejected_reward": -2.609457492828369, "time": 1765817997.1499288}
{"stage": "dpo", "step": 5650, "epoch": 89, "train_loss": 0.09800351351499557, "policy_chosen_logp": -13.355561256408691, "policy_rejected_logp": -1038.819091796875, "ref_chosen_logp": -21.887371063232422, "ref_rejected_logp": -1004.4196166992188, "chosen_reward": 0.853181004524231, "rejected_reward": -3.4399490356445312, "time": 1765817999.6512218}
{"stage": "dpo", "step": 5700, "epoch": 90, "train_loss": 0.019648610353469848, "policy_chosen_logp": -24.852373123168945, "policy_rejected_logp": -1000.2095947265625, "ref_chosen_logp": -31.609542846679688, "ref_rejected_logp": -972.9644775390625, "chosen_reward": 0.6757169365882874, "rejected_reward": -2.724505662918091, "time": 1765818002.1351705}
{"stage": "dpo", "step": 5750, "epoch": 90, "train_loss": 0.2740505090355873, "policy_chosen_logp": -27.325023651123047, "policy_rejected_logp": -1025.64013671875, "ref_chosen_logp": -42.629730224609375, "ref_rejected_logp": -1003.8677978515625, "chosen_reward": 1.530470371246338, "rejected_reward": -2.1772477626800537, "time": 1765818004.6203468}
{"stage": "dpo", "step": 5760, "epoch": 90, "val_pref_acc": 1.0, "time": 1765818005.2510214}
{"stage": "dpo", "step": 5800, "epoch": 91, "train_loss": 0.21564551711082458, "policy_chosen_logp": -30.97687339782715, "policy_rejected_logp": -939.2296142578125, "ref_chosen_logp": -38.202301025390625, "ref_rejected_logp": -922.759521484375, "chosen_reward": 0.7225428819656372, "rejected_reward": -1.6470123529434204, "time": 1765818007.0964892}
{"stage": "dpo", "step": 5850, "epoch": 92, "train_loss": 0.12792702734470368, "policy_chosen_logp": -21.046585083007812, "policy_rejected_logp": -1015.4612426757812, "ref_chosen_logp": -38.105186462402344, "ref_rejected_logp": -998.4324951171875, "chosen_reward": 1.7058600187301636, "rejected_reward": -1.7028778791427612, "time": 1765818009.2576406}
{"stage": "dpo", "step": 5900, "epoch": 93, "train_loss": 0.06393602073192596, "policy_chosen_logp": -25.06208038330078, "policy_rejected_logp": -1079.428466796875, "ref_chosen_logp": -30.214004516601562, "ref_rejected_logp": -1046.517822265625, "chosen_reward": 0.5151923298835754, "rejected_reward": -3.29107666015625, "time": 1765818011.4961786}
{"stage": "dpo", "step": 5950, "epoch": 93, "train_loss": 0.26926939725875854, "policy_chosen_logp": -19.883209228515625, "policy_rejected_logp": -1075.28955078125, "ref_chosen_logp": -32.397735595703125, "ref_rejected_logp": -1042.6666259765625, "chosen_reward": 1.2514525651931763, "rejected_reward": -3.26228928565979, "time": 1765818014.0778732}
{"stage": "dpo", "step": 6000, "epoch": 94, "train_loss": 0.247921404838562, "policy_chosen_logp": -27.713287353515625, "policy_rejected_logp": -1056.7847900390625, "ref_chosen_logp": -41.89548873901367, "ref_rejected_logp": -1030.36962890625, "chosen_reward": 1.4182202816009521, "rejected_reward": -2.6415207386016846, "time": 1765818016.6188688}
{"stage": "dpo", "step": 6050, "epoch": 95, "train_loss": 0.17633380442857743, "policy_chosen_logp": -28.243499755859375, "policy_rejected_logp": -1047.427001953125, "ref_chosen_logp": -33.47700881958008, "ref_rejected_logp": -1006.776611328125, "chosen_reward": 0.5233506560325623, "rejected_reward": -4.065055847167969, "time": 1765818019.1934257}
{"stage": "dpo", "step": 6080, "epoch": 95, "val_pref_acc": 1.0, "time": 1765818020.8401473}
{"stage": "dpo", "step": 6100, "epoch": 96, "train_loss": 0.11566297262907028, "policy_chosen_logp": -28.01128387451172, "policy_rejected_logp": -1178.4197998046875, "ref_chosen_logp": -37.77701187133789, "ref_rejected_logp": -1145.4532470703125, "chosen_reward": 0.97657310962677, "rejected_reward": -3.296658515930176, "time": 1765818021.7230892}
{"stage": "dpo", "step": 6150, "epoch": 97, "train_loss": 0.03031478136777878, "policy_chosen_logp": -15.698892593383789, "policy_rejected_logp": -1081.68359375, "ref_chosen_logp": -29.912921905517578, "ref_rejected_logp": -1061.25341796875, "chosen_reward": 1.421402931213379, "rejected_reward": -2.043004035949707, "time": 1765818024.2576766}
{"stage": "dpo", "step": 6200, "epoch": 97, "train_loss": 0.26466973692178725, "policy_chosen_logp": -15.22945785522461, "policy_rejected_logp": -1014.2899169921875, "ref_chosen_logp": -25.65288734436035, "ref_rejected_logp": -975.0025024414062, "chosen_reward": 1.0423429012298584, "rejected_reward": -3.9287493228912354, "time": 1765818026.7328126}
{"stage": "dpo", "step": 6250, "epoch": 98, "train_loss": 0.2293919339776039, "policy_chosen_logp": -20.380817413330078, "policy_rejected_logp": -997.808837890625, "ref_chosen_logp": -37.76689147949219, "ref_rejected_logp": -977.0601806640625, "chosen_reward": 1.738607406616211, "rejected_reward": -2.0748610496520996, "time": 1765818029.204067}
{"stage": "dpo", "step": 6300, "epoch": 99, "train_loss": 0.1404255959391594, "policy_chosen_logp": -18.899675369262695, "policy_rejected_logp": -1074.33935546875, "ref_chosen_logp": -33.81349563598633, "ref_rejected_logp": -1048.8885498046875, "chosen_reward": 1.491382122039795, "rejected_reward": -2.5450868606567383, "time": 1765818031.656845}
{"stage": "dpo", "step": 6350, "epoch": 100, "train_loss": 0.07666357934474945, "policy_chosen_logp": -22.785858154296875, "policy_rejected_logp": -1032.850830078125, "ref_chosen_logp": -35.28221130371094, "ref_rejected_logp": -1011.28271484375, "chosen_reward": 1.249634861946106, "rejected_reward": -2.1568117141723633, "time": 1765818034.1422567}
{"stage": "dpo", "step": 6400, "epoch": 100, "train_loss": 0.28711594581604005, "policy_chosen_logp": -20.453144073486328, "policy_rejected_logp": -1039.23583984375, "ref_chosen_logp": -36.81858825683594, "ref_rejected_logp": -1005.5799560546875, "chosen_reward": 1.6365442276000977, "rejected_reward": -3.3655776977539062, "time": 1765818036.6188428}
{"stage": "dpo", "step": 6400, "epoch": 100, "val_pref_acc": 1.0, "time": 1765818036.7481303}
{"stage": "dpo", "step": 6450, "epoch": 101, "train_loss": 0.2609944373369217, "policy_chosen_logp": -26.74150848388672, "policy_rejected_logp": -1075.795654296875, "ref_chosen_logp": -39.32793426513672, "ref_rejected_logp": -1038.5341796875, "chosen_reward": 1.2586429119110107, "rejected_reward": -3.726161241531372, "time": 1765818039.083779}
{"stage": "dpo", "step": 6500, "epoch": 102, "train_loss": 0.18528223782777786, "policy_chosen_logp": -24.42182159423828, "policy_rejected_logp": -1126.3382568359375, "ref_chosen_logp": -38.08970642089844, "ref_rejected_logp": -1094.864013671875, "chosen_reward": 1.366788625717163, "rejected_reward": -3.1474151611328125, "time": 1765818041.5495129}
{"stage": "dpo", "step": 6550, "epoch": 103, "train_loss": 0.11020195305347442, "policy_chosen_logp": -11.025087356567383, "policy_rejected_logp": -1099.435546875, "ref_chosen_logp": -20.031694412231445, "ref_rejected_logp": -1077.8291015625, "chosen_reward": 0.9006607532501221, "rejected_reward": -2.1606369018554688, "time": 1765818044.0062468}
{"stage": "dpo", "step": 6600, "epoch": 104, "train_loss": 0.03744543582201004, "policy_chosen_logp": -24.071788787841797, "policy_rejected_logp": -1187.097412109375, "ref_chosen_logp": -41.598480224609375, "ref_rejected_logp": -1168.296630859375, "chosen_reward": 1.752669095993042, "rejected_reward": -1.8800811767578125, "time": 1765818046.464642}
{"stage": "dpo", "step": 6650, "epoch": 104, "train_loss": 0.25444639056921003, "policy_chosen_logp": -28.715456008911133, "policy_rejected_logp": -1025.1187744140625, "ref_chosen_logp": -45.72725296020508, "ref_rejected_logp": -1002.7755737304688, "chosen_reward": 1.7011796236038208, "rejected_reward": -2.234318733215332, "time": 1765818048.929163}
{"stage": "dpo", "step": 6700, "epoch": 105, "train_loss": 0.22919369488954544, "policy_chosen_logp": -17.79781723022461, "policy_rejected_logp": -1037.8128662109375, "ref_chosen_logp": -29.390853881835938, "ref_rejected_logp": -1000.8984375, "chosen_reward": 1.1593035459518433, "rejected_reward": -3.6914401054382324, "time": 1765818051.4072042}
{"stage": "dpo", "step": 6720, "epoch": 105, "val_pref_acc": 1.0, "time": 1765818052.5197325}
{"stage": "dpo", "step": 6750, "epoch": 106, "train_loss": 0.15470785588026048, "policy_chosen_logp": -15.274413108825684, "policy_rejected_logp": -1117.557861328125, "ref_chosen_logp": -26.432886123657227, "ref_rejected_logp": -1089.83349609375, "chosen_reward": 1.1158472299575806, "rejected_reward": -2.772435188293457, "time": 1765818053.8583362}
{"stage": "dpo", "step": 6800, "epoch": 107, "train_loss": 0.08095340996980667, "policy_chosen_logp": -13.630929946899414, "policy_rejected_logp": -944.98095703125, "ref_chosen_logp": -24.567092895507812, "ref_rejected_logp": -910.4437866210938, "chosen_reward": 1.0936163663864136, "rejected_reward": -3.4537155628204346, "time": 1765818056.3532836}
{"stage": "dpo", "step": 6850, "epoch": 108, "train_loss": 0.01002708226442337, "policy_chosen_logp": -20.6436767578125, "policy_rejected_logp": -1058.578125, "ref_chosen_logp": -37.75588607788086, "ref_rejected_logp": -1029.0982666015625, "chosen_reward": 1.7112209796905518, "rejected_reward": -2.947988986968994, "time": 1765818058.9614658}
{"stage": "dpo", "step": 6900, "epoch": 108, "train_loss": 0.25658406257629396, "policy_chosen_logp": -22.21368408203125, "policy_rejected_logp": -1007.2459716796875, "ref_chosen_logp": -37.388587951660156, "ref_rejected_logp": -974.3955688476562, "chosen_reward": 1.5174906253814697, "rejected_reward": -3.285038709640503, "time": 1765818061.4565294}
{"stage": "dpo", "step": 6950, "epoch": 109, "train_loss": 0.20163616627454758, "policy_chosen_logp": -22.528217315673828, "policy_rejected_logp": -1120.949462890625, "ref_chosen_logp": -36.97614288330078, "ref_rejected_logp": -1093.4373779296875, "chosen_reward": 1.444792628288269, "rejected_reward": -2.751216173171997, "time": 1765818063.982506}
{"stage": "dpo", "step": 7000, "epoch": 110, "train_loss": 0.12845231622457504, "policy_chosen_logp": -27.50726890563965, "policy_rejected_logp": -1092.006103515625, "ref_chosen_logp": -43.08695602416992, "ref_rejected_logp": -1064.6005859375, "chosen_reward": 1.5579688549041748, "rejected_reward": -2.7405641078948975, "time": 1765818066.450824}
{"stage": "dpo", "step": 7040, "epoch": 110, "val_pref_acc": 1.0, "time": 1765818068.60424}
{"stage": "dpo", "step": 7050, "epoch": 111, "train_loss": 0.04830797404050827, "policy_chosen_logp": -30.36984634399414, "policy_rejected_logp": -1093.216552734375, "ref_chosen_logp": -31.834999084472656, "ref_rejected_logp": -1050.2894287109375, "chosen_reward": 0.14651526510715485, "rejected_reward": -4.292703151702881, "time": 1765818068.9984574}
{"stage": "dpo", "step": 7100, "epoch": 111, "train_loss": 0.2557090950012207, "policy_chosen_logp": -17.542675018310547, "policy_rejected_logp": -1152.64208984375, "ref_chosen_logp": -30.3536434173584, "ref_rejected_logp": -1138.7255859375, "chosen_reward": 1.2810969352722168, "rejected_reward": -1.3916535377502441, "time": 1765818071.4771342}
{"stage": "dpo", "step": 7150, "epoch": 112, "train_loss": 0.2529242673516274, "policy_chosen_logp": -27.002254486083984, "policy_rejected_logp": -955.283447265625, "ref_chosen_logp": -38.546409606933594, "ref_rejected_logp": -928.2047119140625, "chosen_reward": 1.154415488243103, "rejected_reward": -2.707869052886963, "time": 1765818074.0224373}
{"stage": "dpo", "step": 7200, "epoch": 113, "train_loss": 0.16333017468452454, "policy_chosen_logp": -27.747655868530273, "policy_rejected_logp": -1092.794677734375, "ref_chosen_logp": -44.682735443115234, "ref_rejected_logp": -1059.969482421875, "chosen_reward": 1.6935077905654907, "rejected_reward": -3.282518148422241, "time": 1765818076.5071895}
{"stage": "dpo", "step": 7250, "epoch": 114, "train_loss": 0.09765735000371933, "policy_chosen_logp": -23.854209899902344, "policy_rejected_logp": -933.7740478515625, "ref_chosen_logp": -28.884449005126953, "ref_rejected_logp": -901.0145263671875, "chosen_reward": 0.5030239820480347, "rejected_reward": -3.275956869125366, "time": 1765818078.979708}
{"stage": "dpo", "step": 7300, "epoch": 115, "train_loss": 0.02393795073032379, "policy_chosen_logp": -25.39995574951172, "policy_rejected_logp": -1128.8953857421875, "ref_chosen_logp": -45.73240661621094, "ref_rejected_logp": -1098.3624267578125, "chosen_reward": 2.033245086669922, "rejected_reward": -3.0532960891723633, "time": 1765818081.4480648}
{"stage": "dpo", "step": 7350, "epoch": 115, "train_loss": 0.25724871695041657, "policy_chosen_logp": -21.329448699951172, "policy_rejected_logp": -1012.322021484375, "ref_chosen_logp": -38.317405700683594, "ref_rejected_logp": -977.2032470703125, "chosen_reward": 1.6987957954406738, "rejected_reward": -3.5118775367736816, "time": 1765818083.9159355}
{"stage": "dpo", "step": 7360, "epoch": 115, "val_pref_acc": 1.0, "time": 1765818084.5364676}
{"stage": "dpo", "step": 7400, "epoch": 116, "train_loss": 0.20604662001132965, "policy_chosen_logp": -28.752437591552734, "policy_rejected_logp": -1077.8016357421875, "ref_chosen_logp": -44.2307014465332, "ref_rejected_logp": -1043.5341796875, "chosen_reward": 1.5478262901306152, "rejected_reward": -3.426745653152466, "time": 1765818086.3845527}
{"stage": "dpo", "step": 7450, "epoch": 117, "train_loss": 0.14247566133737563, "policy_chosen_logp": -18.65180778503418, "policy_rejected_logp": -1105.84814453125, "ref_chosen_logp": -28.740215301513672, "ref_rejected_logp": -1076.55615234375, "chosen_reward": 1.0088409185409546, "rejected_reward": -2.929196357727051, "time": 1765818088.847758}
{"stage": "dpo", "step": 7500, "epoch": 118, "train_loss": 0.054824664890766144, "policy_chosen_logp": -15.540613174438477, "policy_rejected_logp": -1056.6334228515625, "ref_chosen_logp": -25.678958892822266, "ref_rejected_logp": -1033.0557861328125, "chosen_reward": 1.0138345956802368, "rejected_reward": -2.35776686668396, "time": 1765818091.3024015}
{"stage": "dpo", "step": 7550, "epoch": 118, "train_loss": 0.2668087100982666, "policy_chosen_logp": -15.12747859954834, "policy_rejected_logp": -994.5149536132812, "ref_chosen_logp": -26.605693817138672, "ref_rejected_logp": -965.2100830078125, "chosen_reward": 1.1478214263916016, "rejected_reward": -2.9304823875427246, "time": 1765818093.7725282}
{"stage": "dpo", "step": 7600, "epoch": 119, "train_loss": 0.23608253747224808, "policy_chosen_logp": -17.305747985839844, "policy_rejected_logp": -1120.8284912109375, "ref_chosen_logp": -26.76866912841797, "ref_rejected_logp": -1097.2078857421875, "chosen_reward": 0.9462920427322388, "rejected_reward": -2.3620574474334717, "time": 1765818096.2442627}
{"stage": "dpo", "step": 7650, "epoch": 120, "train_loss": 0.17727604180574416, "policy_chosen_logp": -23.884668350219727, "policy_rejected_logp": -1216.517578125, "ref_chosen_logp": -32.64939498901367, "ref_rejected_logp": -1179.782470703125, "chosen_reward": 0.8764727711677551, "rejected_reward": -3.67352294921875, "time": 1765818098.7160065}
{"stage": "dpo", "step": 7680, "epoch": 120, "val_pref_acc": 1.0, "time": 1765818100.3514063}
{"stage": "dpo", "step": 7700, "epoch": 121, "train_loss": 0.10011400520801544, "policy_chosen_logp": -17.145835876464844, "policy_rejected_logp": -1092.971923828125, "ref_chosen_logp": -37.405906677246094, "ref_rejected_logp": -1068.1243896484375, "chosen_reward": 2.0260074138641357, "rejected_reward": -2.4847536087036133, "time": 1765818101.2337687}
{"stage": "dpo", "step": 7750, "epoch": 122, "train_loss": 0.028734080493450165, "policy_chosen_logp": -27.73339080810547, "policy_rejected_logp": -997.3811645507812, "ref_chosen_logp": -42.74650955200195, "ref_rejected_logp": -982.8311157226562, "chosen_reward": 1.501312017440796, "rejected_reward": -1.4550049304962158, "time": 1765818103.706591}
{"stage": "dpo", "step": 7800, "epoch": 122, "train_loss": 0.26397700399160384, "policy_chosen_logp": -25.069530487060547, "policy_rejected_logp": -1140.583740234375, "ref_chosen_logp": -39.473289489746094, "ref_rejected_logp": -1094.3662109375, "chosen_reward": 1.440375566482544, "rejected_reward": -4.6217546463012695, "time": 1765818106.2368634}
{"stage": "dpo", "step": 7850, "epoch": 123, "train_loss": 0.21233594805002212, "policy_chosen_logp": -16.703121185302734, "policy_rejected_logp": -1020.3948364257812, "ref_chosen_logp": -27.84335708618164, "ref_rejected_logp": -988.7235717773438, "chosen_reward": 1.1140235662460327, "rejected_reward": -3.167123317718506, "time": 1765818108.7771723}
{"stage": "dpo", "step": 7900, "epoch": 124, "train_loss": 0.13913741409778596, "policy_chosen_logp": -19.980146408081055, "policy_rejected_logp": -957.839111328125, "ref_chosen_logp": -28.843120574951172, "ref_rejected_logp": -943.4346313476562, "chosen_reward": 0.8862975835800171, "rejected_reward": -1.4404464960098267, "time": 1765818111.3232613}
{"stage": "dpo", "step": 7950, "epoch": 125, "train_loss": 0.0749749419093132, "policy_chosen_logp": -15.915142059326172, "policy_rejected_logp": -1029.63720703125, "ref_chosen_logp": -28.01624298095703, "ref_rejected_logp": -1004.8602294921875, "chosen_reward": 1.2101099491119385, "rejected_reward": -2.4776978492736816, "time": 1765818113.822281}
{"stage": "dpo", "step": 8000, "epoch": 125, "train_loss": 0.2554072621464729, "policy_chosen_logp": -16.344451904296875, "policy_rejected_logp": -1049.85205078125, "ref_chosen_logp": -22.65418815612793, "ref_rejected_logp": -1025.25732421875, "chosen_reward": 0.6309736967086792, "rejected_reward": -2.459459066390991, "time": 1765818116.3010128}
{"stage": "dpo", "step": 8000, "epoch": 125, "val_pref_acc": 1.0, "time": 1765818116.4308941}
{"stage": "dpo", "step": 8050, "epoch": 126, "train_loss": 0.2475367969274521, "policy_chosen_logp": -14.485346794128418, "policy_rejected_logp": -1018.9049682617188, "ref_chosen_logp": -18.820690155029297, "ref_rejected_logp": -996.707275390625, "chosen_reward": 0.4335343837738037, "rejected_reward": -2.219766139984131, "time": 1765818118.7853982}
{"stage": "dpo", "step": 8100, "epoch": 127, "train_loss": 0.1762065052986145, "policy_chosen_logp": -20.204307556152344, "policy_rejected_logp": -964.455078125, "ref_chosen_logp": -35.393280029296875, "ref_rejected_logp": -940.319580078125, "chosen_reward": 1.5188970565795898, "rejected_reward": -2.413552761077881, "time": 1765818121.2558887}
{"stage": "dpo", "step": 8150, "epoch": 128, "train_loss": 0.11234835684299468, "policy_chosen_logp": -18.25343132019043, "policy_rejected_logp": -1123.4693603515625, "ref_chosen_logp": -34.10589599609375, "ref_rejected_logp": -1103.119873046875, "chosen_reward": 1.5852463245391846, "rejected_reward": -2.0349550247192383, "time": 1765818123.7354653}
{"stage": "dpo", "step": 8200, "epoch": 129, "train_loss": 0.03991075664758682, "policy_chosen_logp": -26.334335327148438, "policy_rejected_logp": -993.78466796875, "ref_chosen_logp": -35.03179168701172, "ref_rejected_logp": -957.6297607421875, "chosen_reward": 0.8697456121444702, "rejected_reward": -3.615490674972534, "time": 1765818125.803553}
{"stage": "dpo", "step": 8250, "epoch": 129, "train_loss": 0.251599979698658, "policy_chosen_logp": -25.34314727783203, "policy_rejected_logp": -1056.359130859375, "ref_chosen_logp": -36.3684196472168, "ref_rejected_logp": -1033.66748046875, "chosen_reward": 1.102527379989624, "rejected_reward": -2.269155979156494, "time": 1765818128.2197711}
{"stage": "dpo", "step": 8300, "epoch": 130, "train_loss": 0.23244572520256043, "policy_chosen_logp": -25.89901351928711, "policy_rejected_logp": -1074.8988037109375, "ref_chosen_logp": -45.13524627685547, "ref_rejected_logp": -1056.39501953125, "chosen_reward": 1.9236235618591309, "rejected_reward": -1.8503844738006592, "time": 1765818130.7150474}
{"stage": "dpo", "step": 8320, "epoch": 130, "val_pref_acc": 1.0, "time": 1765818131.8482625}
{"stage": "dpo", "step": 8350, "epoch": 131, "train_loss": 0.14438300877809523, "policy_chosen_logp": -27.43231201171875, "policy_rejected_logp": -1112.94384765625, "ref_chosen_logp": -38.72121810913086, "ref_rejected_logp": -1091.8760986328125, "chosen_reward": 1.128890872001648, "rejected_reward": -2.1067733764648438, "time": 1765818133.2139847}
{"stage": "dpo", "step": 8400, "epoch": 132, "train_loss": 0.07848148494958877, "policy_chosen_logp": -27.818988800048828, "policy_rejected_logp": -1000.7769165039062, "ref_chosen_logp": -49.08264923095703, "ref_rejected_logp": -983.9571533203125, "chosen_reward": 2.126365900039673, "rejected_reward": -1.6819748878479004, "time": 1765818135.694292}
{"stage": "dpo", "step": 8450, "epoch": 133, "train_loss": 0.00893253207206726, "policy_chosen_logp": -20.62841796875, "policy_rejected_logp": -1069.197265625, "ref_chosen_logp": -29.100244522094727, "ref_rejected_logp": -1033.19677734375, "chosen_reward": 0.8471826910972595, "rejected_reward": -3.600041151046753, "time": 1765818138.1906698}
{"stage": "dpo", "step": 8500, "epoch": 133, "train_loss": 0.24960358142852784, "policy_chosen_logp": -20.569412231445312, "policy_rejected_logp": -1041.9149169921875, "ref_chosen_logp": -32.10626220703125, "ref_rejected_logp": -1014.5914916992188, "chosen_reward": 1.1536850929260254, "rejected_reward": -2.7323455810546875, "time": 1765818140.667541}
{"stage": "dpo", "step": 8550, "epoch": 134, "train_loss": 0.18583369374275208, "policy_chosen_logp": -17.574661254882812, "policy_rejected_logp": -1043.20849609375, "ref_chosen_logp": -28.877635955810547, "ref_rejected_logp": -1021.56591796875, "chosen_reward": 1.1302976608276367, "rejected_reward": -2.1642608642578125, "time": 1765818143.153746}
{"stage": "dpo", "step": 8600, "epoch": 135, "train_loss": 0.13052765280008316, "policy_chosen_logp": -20.9352970123291, "policy_rejected_logp": -1159.688720703125, "ref_chosen_logp": -44.92095184326172, "ref_rejected_logp": -1149.4422607421875, "chosen_reward": 2.3985652923583984, "rejected_reward": -1.024652123451233, "time": 1765818145.6168017}
{"stage": "dpo", "step": 8640, "epoch": 135, "val_pref_acc": 1.0, "time": 1765818147.7423713}
{"stage": "dpo", "step": 8650, "epoch": 136, "train_loss": 0.05273509591817856, "policy_chosen_logp": -12.722190856933594, "policy_rejected_logp": -1138.9417724609375, "ref_chosen_logp": -31.365955352783203, "ref_rejected_logp": -1115.6322021484375, "chosen_reward": 1.8643766641616821, "rejected_reward": -2.3309478759765625, "time": 1765818148.138724}
{"stage": "dpo", "step": 8700, "epoch": 136, "train_loss": 0.2631084468960762, "policy_chosen_logp": -28.003721237182617, "policy_rejected_logp": -1024.808349609375, "ref_chosen_logp": -39.54829406738281, "ref_rejected_logp": -988.5540771484375, "chosen_reward": 1.1544572114944458, "rejected_reward": -3.6254305839538574, "time": 1765818150.6000535}
{"stage": "dpo", "step": 8750, "epoch": 137, "train_loss": 0.23185926884412766, "policy_chosen_logp": -20.98169708251953, "policy_rejected_logp": -1032.004150390625, "ref_chosen_logp": -44.556888580322266, "ref_rejected_logp": -999.57421875, "chosen_reward": 2.3575191497802734, "rejected_reward": -3.24298095703125, "time": 1765818153.0948224}
{"stage": "dpo", "step": 8800, "epoch": 138, "train_loss": 0.16266961842775346, "policy_chosen_logp": -17.235736846923828, "policy_rejected_logp": -1036.5162353515625, "ref_chosen_logp": -31.454771041870117, "ref_rejected_logp": -1016.899169921875, "chosen_reward": 1.4219034910202026, "rejected_reward": -1.9617035388946533, "time": 1765818155.6029744}
{"stage": "dpo", "step": 8850, "epoch": 139, "train_loss": 0.09126978933811188, "policy_chosen_logp": -14.947574615478516, "policy_rejected_logp": -1167.10791015625, "ref_chosen_logp": -35.69574737548828, "ref_rejected_logp": -1149.296875, "chosen_reward": 2.074817180633545, "rejected_reward": -1.7811096906661987, "time": 1765818158.1232984}
{"stage": "dpo", "step": 8900, "epoch": 140, "train_loss": 0.018910676538944245, "policy_chosen_logp": -22.542327880859375, "policy_rejected_logp": -1146.866943359375, "ref_chosen_logp": -32.10862731933594, "ref_rejected_logp": -1120.3538818359375, "chosen_reward": 0.9566304087638855, "rejected_reward": -2.6513078212738037, "time": 1765818160.6370363}
{"stage": "dpo", "step": 8950, "epoch": 140, "train_loss": 0.2518205282092094, "policy_chosen_logp": -14.451955795288086, "policy_rejected_logp": -1119.5091552734375, "ref_chosen_logp": -35.0668830871582, "ref_rejected_logp": -1109.32275390625, "chosen_reward": 2.061492681503296, "rejected_reward": -1.0186448097229004, "time": 1765818163.127985}
{"stage": "dpo", "step": 8960, "epoch": 140, "val_pref_acc": 1.0, "time": 1765818163.7525127}
{"stage": "dpo", "step": 9000, "epoch": 141, "train_loss": 0.19586418747901915, "policy_chosen_logp": -23.48422622680664, "policy_rejected_logp": -1075.1982421875, "ref_chosen_logp": -40.458648681640625, "ref_rejected_logp": -1068.740478515625, "chosen_reward": 1.6974422931671143, "rejected_reward": -0.6457732915878296, "time": 1765818165.6007228}
{"stage": "dpo", "step": 9050, "epoch": 142, "train_loss": 0.12808498233556748, "policy_chosen_logp": -36.261383056640625, "policy_rejected_logp": -1076.5157470703125, "ref_chosen_logp": -47.943790435791016, "ref_rejected_logp": -1043.170654296875, "chosen_reward": 1.1682405471801758, "rejected_reward": -3.3345139026641846, "time": 1765818167.915829}
{"stage": "dpo", "step": 9100, "epoch": 143, "train_loss": 0.06226966470479965, "policy_chosen_logp": -18.909347534179688, "policy_rejected_logp": -1143.799560546875, "ref_chosen_logp": -31.746231079101562, "ref_rejected_logp": -1099.4344482421875, "chosen_reward": 1.2836883068084717, "rejected_reward": -4.436513900756836, "time": 1765818170.3571305}
{"stage": "dpo", "step": 9150, "epoch": 143, "train_loss": 0.2478953206539154, "policy_chosen_logp": -25.503833770751953, "policy_rejected_logp": -1040.727294921875, "ref_chosen_logp": -39.18447494506836, "ref_rejected_logp": -1003.58349609375, "chosen_reward": 1.368064284324646, "rejected_reward": -3.714372158050537, "time": 1765818172.855591}
{"stage": "dpo", "step": 9200, "epoch": 144, "train_loss": 0.23678505033254624, "policy_chosen_logp": -18.988643646240234, "policy_rejected_logp": -1042.070556640625, "ref_chosen_logp": -34.55175018310547, "ref_rejected_logp": -1028.9801025390625, "chosen_reward": 1.556310772895813, "rejected_reward": -1.3090499639511108, "time": 1765818175.3294547}
{"stage": "dpo", "step": 9250, "epoch": 145, "train_loss": 0.17132589101791382, "policy_chosen_logp": -20.212148666381836, "policy_rejected_logp": -1034.4044189453125, "ref_chosen_logp": -36.92887878417969, "ref_rejected_logp": -992.2698364257812, "chosen_reward": 1.6716729402542114, "rejected_reward": -4.213457107543945, "time": 1765818177.7997398}
{"stage": "dpo", "step": 9280, "epoch": 145, "val_pref_acc": 1.0, "time": 1765818179.4121277}
{"stage": "dpo", "step": 9300, "epoch": 146, "train_loss": 0.09775535017251968, "policy_chosen_logp": -14.417354583740234, "policy_rejected_logp": -998.7635498046875, "ref_chosen_logp": -31.614133834838867, "ref_rejected_logp": -975.01220703125, "chosen_reward": 1.7196780443191528, "rejected_reward": -2.3751327991485596, "time": 1765818180.285058}
{"stage": "dpo", "step": 9350, "epoch": 147, "train_loss": 0.03266936182975769, "policy_chosen_logp": -22.51518440246582, "policy_rejected_logp": -1038.6181640625, "ref_chosen_logp": -31.428573608398438, "ref_rejected_logp": -1002.9510498046875, "chosen_reward": 0.8913388848304749, "rejected_reward": -3.5667145252227783, "time": 1765818182.7381496}
{"stage": "dpo", "step": 9400, "epoch": 147, "train_loss": 0.2412360590696335, "policy_chosen_logp": -19.388254165649414, "policy_rejected_logp": -1076.860595703125, "ref_chosen_logp": -37.688743591308594, "ref_rejected_logp": -1051.0123291015625, "chosen_reward": 1.8300485610961914, "rejected_reward": -2.584829807281494, "time": 1765818185.1910062}
{"stage": "dpo", "step": 9450, "epoch": 148, "train_loss": 0.21352521032094957, "policy_chosen_logp": -20.219566345214844, "policy_rejected_logp": -1098.129638671875, "ref_chosen_logp": -26.877426147460938, "ref_rejected_logp": -1077.11962890625, "chosen_reward": 0.6657858490943909, "rejected_reward": -2.1010024547576904, "time": 1765818187.6698196}
{"stage": "dpo", "step": 9500, "epoch": 149, "train_loss": 0.13758740067481995, "policy_chosen_logp": -27.468055725097656, "policy_rejected_logp": -1059.83349609375, "ref_chosen_logp": -46.06099319458008, "ref_rejected_logp": -1042.73876953125, "chosen_reward": 1.8592936992645264, "rejected_reward": -1.70947265625, "time": 1765818190.1616821}
{"stage": "dpo", "step": 9550, "epoch": 150, "train_loss": 0.07387508779764175, "policy_chosen_logp": -16.7341365814209, "policy_rejected_logp": -1009.5701904296875, "ref_chosen_logp": -34.20608901977539, "ref_rejected_logp": -1003.8075561523438, "chosen_reward": 1.7471951246261597, "rejected_reward": -0.5762603282928467, "time": 1765818192.6333222}
{"stage": "dpo", "step": 9600, "epoch": 150, "train_loss": 0.24397656440734863, "policy_chosen_logp": -23.853498458862305, "policy_rejected_logp": -1090.307861328125, "ref_chosen_logp": -36.95024871826172, "ref_rejected_logp": -1050.567138671875, "chosen_reward": 1.3096752166748047, "rejected_reward": -3.974073886871338, "time": 1765818195.139402}
{"stage": "dpo", "step": 9600, "epoch": 150, "val_pref_acc": 1.0, "time": 1765818195.276979}
{"stage": "dpo", "step": 9650, "epoch": 151, "train_loss": 0.24953773140907287, "policy_chosen_logp": -10.515680313110352, "policy_rejected_logp": -1087.73681640625, "ref_chosen_logp": -41.09967803955078, "ref_rejected_logp": -1076.25830078125, "chosen_reward": 3.0584001541137695, "rejected_reward": -1.1478592157363892, "time": 1765818197.7046142}
{"stage": "dpo", "step": 9700, "epoch": 152, "train_loss": 0.18161152482032775, "policy_chosen_logp": -20.784130096435547, "policy_rejected_logp": -1054.8228759765625, "ref_chosen_logp": -38.72566223144531, "ref_rejected_logp": -1013.8472900390625, "chosen_reward": 1.7941534519195557, "rejected_reward": -4.097558975219727, "time": 1765818200.2411547}
{"stage": "dpo", "step": 9750, "epoch": 153, "train_loss": 0.11008470118045807, "policy_chosen_logp": -18.583232879638672, "policy_rejected_logp": -1008.9539794921875, "ref_chosen_logp": -20.527379989624023, "ref_rejected_logp": -986.432861328125, "chosen_reward": 0.19441476464271545, "rejected_reward": -2.2521164417266846, "time": 1765818202.8110816}
{"stage": "dpo", "step": 9800, "epoch": 154, "train_loss": 0.037509976625442504, "policy_chosen_logp": -18.358966827392578, "policy_rejected_logp": -1119.673095703125, "ref_chosen_logp": -36.480064392089844, "ref_rejected_logp": -1098.659912109375, "chosen_reward": 1.8121100664138794, "rejected_reward": -2.1013307571411133, "time": 1765818205.2877872}
{"stage": "dpo", "step": 9850, "epoch": 154, "train_loss": 0.24176062613725663, "policy_chosen_logp": -28.56720542907715, "policy_rejected_logp": -1058.195556640625, "ref_chosen_logp": -51.71125030517578, "ref_rejected_logp": -1036.899658203125, "chosen_reward": 2.3144044876098633, "rejected_reward": -2.1295852661132812, "time": 1765818207.7559748}
{"stage": "dpo", "step": 9900, "epoch": 155, "train_loss": 0.2179572719335556, "policy_chosen_logp": -22.84038734436035, "policy_rejected_logp": -990.4804077148438, "ref_chosen_logp": -30.88175392150879, "ref_rejected_logp": -972.66162109375, "chosen_reward": 0.8041366934776306, "rejected_reward": -1.7818787097930908, "time": 1765818210.216274}
{"stage": "dpo", "step": 9920, "epoch": 155, "val_pref_acc": 1.0, "time": 1765818211.3324387}
{"stage": "dpo", "step": 9950, "epoch": 156, "train_loss": 0.14214318603277207, "policy_chosen_logp": -14.792489051818848, "policy_rejected_logp": -1038.0042724609375, "ref_chosen_logp": -28.890527725219727, "ref_rejected_logp": -1019.1004028320312, "chosen_reward": 1.4098039865493774, "rejected_reward": -1.8903838396072388, "time": 1765818212.6868725}
{"stage": "dpo", "step": 10000, "epoch": 157, "train_loss": 0.08465845137834549, "policy_chosen_logp": -17.876800537109375, "policy_rejected_logp": -1130.219482421875, "ref_chosen_logp": -37.44666290283203, "ref_rejected_logp": -1101.4173583984375, "chosen_reward": 1.9569863080978394, "rejected_reward": -2.8802199363708496, "time": 1765818215.1615655}
{"stage": "dpo", "step": 10050, "epoch": 158, "train_loss": 0.00926516681909561, "policy_chosen_logp": -23.36797332763672, "policy_rejected_logp": -1045.339111328125, "ref_chosen_logp": -35.652015686035156, "ref_rejected_logp": -1029.858642578125, "chosen_reward": 1.2284042835235596, "rejected_reward": -1.5480453968048096, "time": 1765818217.6998117}
{"stage": "dpo", "step": 10100, "epoch": 158, "train_loss": 0.2439568296074867, "policy_chosen_logp": -11.653632164001465, "policy_rejected_logp": -996.9051513671875, "ref_chosen_logp": -19.25301170349121, "ref_rejected_logp": -965.066162109375, "chosen_reward": 0.7599380016326904, "rejected_reward": -3.18389892578125, "time": 1765818220.1549308}
{"stage": "dpo", "step": 10150, "epoch": 159, "train_loss": 0.18479602068662643, "policy_chosen_logp": -7.366066932678223, "policy_rejected_logp": -1192.0059814453125, "ref_chosen_logp": -23.545452117919922, "ref_rejected_logp": -1158.883056640625, "chosen_reward": 1.61793851852417, "rejected_reward": -3.3122804164886475, "time": 1765818222.6307113}
{"stage": "dpo", "step": 10200, "epoch": 160, "train_loss": 0.11600668370723724, "policy_chosen_logp": -15.917176246643066, "policy_rejected_logp": -1074.49755859375, "ref_chosen_logp": -32.04536437988281, "ref_rejected_logp": -1058.47314453125, "chosen_reward": 1.612818956375122, "rejected_reward": -1.602447509765625, "time": 1765818225.0822957}
{"stage": "dpo", "step": 10240, "epoch": 160, "val_pref_acc": 1.0, "time": 1765818227.1997602}
{"stage": "dpo", "step": 10250, "epoch": 161, "train_loss": 0.0493790790438652, "policy_chosen_logp": -28.969013214111328, "policy_rejected_logp": -1085.97412109375, "ref_chosen_logp": -48.59481430053711, "ref_rejected_logp": -1062.3629150390625, "chosen_reward": 1.9625800848007202, "rejected_reward": -2.3611221313476562, "time": 1765818227.58845}
{"stage": "dpo", "step": 10300, "epoch": 161, "train_loss": 0.2412346965074539, "policy_chosen_logp": -8.333227157592773, "policy_rejected_logp": -1112.092529296875, "ref_chosen_logp": -19.1328125, "ref_rejected_logp": -1083.8946533203125, "chosen_reward": 1.0799585580825806, "rejected_reward": -2.819779872894287, "time": 1765818230.0203984}
{"stage": "dpo", "step": 10350, "epoch": 162, "train_loss": 0.22289187997579574, "policy_chosen_logp": -13.5553617477417, "policy_rejected_logp": -1102.759765625, "ref_chosen_logp": -29.58089828491211, "ref_rejected_logp": -1080.348388671875, "chosen_reward": 1.6025537252426147, "rejected_reward": -2.2411468029022217, "time": 1765818232.4891837}
{"stage": "dpo", "step": 10400, "epoch": 163, "train_loss": 0.14683036386966705, "policy_chosen_logp": -21.304718017578125, "policy_rejected_logp": -1085.0650634765625, "ref_chosen_logp": -33.428558349609375, "ref_rejected_logp": -1066.0911865234375, "chosen_reward": 1.2123842239379883, "rejected_reward": -1.8973908424377441, "time": 1765818234.9380925}
{"stage": "dpo", "step": 10450, "epoch": 164, "train_loss": 0.0825882089138031, "policy_chosen_logp": -10.683355331420898, "policy_rejected_logp": -1145.108154296875, "ref_chosen_logp": -24.68523406982422, "ref_rejected_logp": -1116.712646484375, "chosen_reward": 1.4001879692077637, "rejected_reward": -2.8395447731018066, "time": 1765818237.387482}
{"stage": "dpo", "step": 10500, "epoch": 165, "train_loss": 0.019742456376552583, "policy_chosen_logp": -16.35869026184082, "policy_rejected_logp": -1044.9595947265625, "ref_chosen_logp": -41.207489013671875, "ref_rejected_logp": -1029.3880615234375, "chosen_reward": 2.484879970550537, "rejected_reward": -1.557154893875122, "time": 1765818239.865805}
{"stage": "dpo", "step": 10550, "epoch": 165, "train_loss": 0.24320388257503509, "policy_chosen_logp": -24.400514602661133, "policy_rejected_logp": -1061.4122314453125, "ref_chosen_logp": -39.65464782714844, "ref_rejected_logp": -1025.6888427734375, "chosen_reward": 1.5254135131835938, "rejected_reward": -3.5723328590393066, "time": 1765818242.3240619}
{"stage": "dpo", "step": 10560, "epoch": 165, "val_pref_acc": 1.0, "time": 1765818242.9928107}
{"stage": "dpo", "step": 10600, "epoch": 166, "train_loss": 0.19936119943857192, "policy_chosen_logp": -24.542430877685547, "policy_rejected_logp": -1125.3104248046875, "ref_chosen_logp": -44.18317794799805, "ref_rejected_logp": -1106.08642578125, "chosen_reward": 1.9640746116638184, "rejected_reward": -1.9223999977111816, "time": 1765818244.866391}
{"stage": "dpo", "step": 10650, "epoch": 167, "train_loss": 0.1302450704574585, "policy_chosen_logp": -24.46318817138672, "policy_rejected_logp": -1064.3402099609375, "ref_chosen_logp": -34.54607009887695, "ref_rejected_logp": -1035.1693115234375, "chosen_reward": 1.008288025856018, "rejected_reward": -2.917092800140381, "time": 1765818247.4261177}
{"stage": "dpo", "step": 10700, "epoch": 168, "train_loss": 0.054338668584823606, "policy_chosen_logp": -12.458256721496582, "policy_rejected_logp": -1047.680419921875, "ref_chosen_logp": -26.17664337158203, "ref_rejected_logp": -1027.34130859375, "chosen_reward": 1.3718388080596924, "rejected_reward": -2.0339064598083496, "time": 1765818249.892572}
{"stage": "dpo", "step": 10750, "epoch": 168, "train_loss": 0.24097683846950532, "policy_chosen_logp": -28.21345329284668, "policy_rejected_logp": -1153.005859375, "ref_chosen_logp": -38.41834259033203, "ref_rejected_logp": -1134.176513671875, "chosen_reward": 1.02048921585083, "rejected_reward": -1.8829345703125, "time": 1765818252.3870413}
{"stage": "dpo", "step": 10800, "epoch": 169, "train_loss": 0.23622988939285278, "policy_chosen_logp": -16.262134552001953, "policy_rejected_logp": -1009.133056640625, "ref_chosen_logp": -26.47808074951172, "ref_rejected_logp": -992.3441772460938, "chosen_reward": 1.021594524383545, "rejected_reward": -1.6788926124572754, "time": 1765818254.8654003}
{"stage": "dpo", "step": 10850, "epoch": 170, "train_loss": 0.1605082109570503, "policy_chosen_logp": -20.657188415527344, "policy_rejected_logp": -971.620361328125, "ref_chosen_logp": -37.93394088745117, "ref_rejected_logp": -944.3634033203125, "chosen_reward": 1.7276756763458252, "rejected_reward": -2.725694179534912, "time": 1765818257.3379157}
{"stage": "dpo", "step": 10880, "epoch": 170, "val_pref_acc": 1.0, "time": 1765818258.9753356}
{"stage": "dpo", "step": 10900, "epoch": 171, "train_loss": 0.0944235372543335, "policy_chosen_logp": -18.881023406982422, "policy_rejected_logp": -1042.32470703125, "ref_chosen_logp": -36.51920700073242, "ref_rejected_logp": -1014.6842041015625, "chosen_reward": 1.763818383216858, "rejected_reward": -2.7640485763549805, "time": 1765818259.829394}
{"stage": "dpo", "step": 10950, "epoch": 172, "train_loss": 0.027689969539642333, "policy_chosen_logp": -23.615440368652344, "policy_rejected_logp": -1001.115966796875, "ref_chosen_logp": -34.794761657714844, "ref_rejected_logp": -976.7444458007812, "chosen_reward": 1.117931842803955, "rejected_reward": -2.4371535778045654, "time": 1765818262.3159394}
{"stage": "dpo", "step": 11000, "epoch": 172, "train_loss": 0.2404403007030487, "policy_chosen_logp": -21.35711669921875, "policy_rejected_logp": -1080.160888671875, "ref_chosen_logp": -40.643836975097656, "ref_rejected_logp": -1067.176513671875, "chosen_reward": 1.9286720752716064, "rejected_reward": -1.2984375953674316, "time": 1765818264.77175}
{"stage": "dpo", "step": 11050, "epoch": 173, "train_loss": 0.2098488026857376, "policy_chosen_logp": -15.211210250854492, "policy_rejected_logp": -1131.492919921875, "ref_chosen_logp": -37.123783111572266, "ref_rejected_logp": -1133.4033203125, "chosen_reward": 2.1912574768066406, "rejected_reward": 0.19104614853858948, "time": 1765818267.2522557}
{"stage": "dpo", "step": 11100, "epoch": 174, "train_loss": 0.1355417600274086, "policy_chosen_logp": -15.618379592895508, "policy_rejected_logp": -1056.4803466796875, "ref_chosen_logp": -33.95384216308594, "ref_rejected_logp": -1047.693115234375, "chosen_reward": 1.8335462808609009, "rejected_reward": -0.8787323832511902, "time": 1765818269.7212355}
{"stage": "dpo", "step": 11150, "epoch": 175, "train_loss": 0.06735392659902573, "policy_chosen_logp": -12.532501220703125, "policy_rejected_logp": -1114.6328125, "ref_chosen_logp": -23.351531982421875, "ref_rejected_logp": -1105.148681640625, "chosen_reward": 1.0819029808044434, "rejected_reward": -0.9484100341796875, "time": 1765818272.187114}
{"stage": "dpo", "step": 11200, "epoch": 175, "train_loss": 0.2479107791185379, "policy_chosen_logp": -18.691553115844727, "policy_rejected_logp": -1070.432373046875, "ref_chosen_logp": -37.29256820678711, "ref_rejected_logp": -1040.2418212890625, "chosen_reward": 1.860101342201233, "rejected_reward": -3.0190536975860596, "time": 1765818274.651426}
{"stage": "dpo", "step": 11200, "epoch": 175, "val_pref_acc": 1.0, "time": 1765818274.7789323}
{"stage": "dpo", "step": 11250, "epoch": 176, "train_loss": 0.25058311253786086, "policy_chosen_logp": -20.972824096679688, "policy_rejected_logp": -970.227783203125, "ref_chosen_logp": -30.190872192382812, "ref_rejected_logp": -953.423828125, "chosen_reward": 0.9218047261238098, "rejected_reward": -1.6803940534591675, "time": 1765818277.119886}
{"stage": "dpo", "step": 11300, "epoch": 177, "train_loss": 0.17656014502048492, "policy_chosen_logp": -22.09834861755371, "policy_rejected_logp": -1024.7374267578125, "ref_chosen_logp": -30.416770935058594, "ref_rejected_logp": -998.2689208984375, "chosen_reward": 0.8318424224853516, "rejected_reward": -2.646855354309082, "time": 1765818279.6020088}
{"stage": "dpo", "step": 11350, "epoch": 178, "train_loss": 0.10672019958496094, "policy_chosen_logp": -27.411697387695312, "policy_rejected_logp": -1050.936279296875, "ref_chosen_logp": -54.21896743774414, "ref_rejected_logp": -1040.813720703125, "chosen_reward": 2.680727243423462, "rejected_reward": -1.0122498273849487, "time": 1765818282.1268103}
{"stage": "dpo", "step": 11400, "epoch": 179, "train_loss": 0.03710485279560089, "policy_chosen_logp": -24.69278335571289, "policy_rejected_logp": -1092.4459228515625, "ref_chosen_logp": -38.490478515625, "ref_rejected_logp": -1075.4677734375, "chosen_reward": 1.3797693252563477, "rejected_reward": -1.6978164911270142, "time": 1765818284.629502}
{"stage": "dpo", "step": 11450, "epoch": 179, "train_loss": 0.23703079611063005, "policy_chosen_logp": -19.04833984375, "policy_rejected_logp": -1141.192626953125, "ref_chosen_logp": -35.01921844482422, "ref_rejected_logp": -1118.40087890625, "chosen_reward": 1.5970877408981323, "rejected_reward": -2.2791748046875, "time": 1765818287.1395905}
{"stage": "dpo", "step": 11500, "epoch": 180, "train_loss": 0.20851694613695146, "policy_chosen_logp": -15.143295288085938, "policy_rejected_logp": -1046.37060546875, "ref_chosen_logp": -25.798568725585938, "ref_rejected_logp": -1018.7703857421875, "chosen_reward": 1.0655274391174316, "rejected_reward": -2.760032892227173, "time": 1765818289.6318305}
{"stage": "dpo", "step": 11520, "epoch": 180, "val_pref_acc": 1.0, "time": 1765818290.77464}
{"stage": "dpo", "step": 11550, "epoch": 181, "train_loss": 0.1416251167654991, "policy_chosen_logp": -15.724876403808594, "policy_rejected_logp": -1113.472412109375, "ref_chosen_logp": -29.525928497314453, "ref_rejected_logp": -1109.446533203125, "chosen_reward": 1.3801050186157227, "rejected_reward": -0.40258485078811646, "time": 1765818292.1755981}
{"stage": "dpo", "step": 11600, "epoch": 182, "train_loss": 0.07627221077680588, "policy_chosen_logp": -18.953243255615234, "policy_rejected_logp": -1064.0062255859375, "ref_chosen_logp": -32.679237365722656, "ref_rejected_logp": -1045.290283203125, "chosen_reward": 1.3725992441177368, "rejected_reward": -1.871595859527588, "time": 1765818294.648109}
{"stage": "dpo", "step": 11650, "epoch": 183, "train_loss": 0.00956564486026764, "policy_chosen_logp": -19.37516212463379, "policy_rejected_logp": -1113.208740234375, "ref_chosen_logp": -31.200292587280273, "ref_rejected_logp": -1088.6099853515625, "chosen_reward": 1.1825129985809326, "rejected_reward": -2.459878444671631, "time": 1765818297.1295216}
{"stage": "dpo", "step": 11700, "epoch": 183, "train_loss": 0.2368350750207901, "policy_chosen_logp": -20.56125259399414, "policy_rejected_logp": -1075.913330078125, "ref_chosen_logp": -29.98639488220215, "ref_rejected_logp": -1047.583740234375, "chosen_reward": 0.9425142407417297, "rejected_reward": -2.832951307296753, "time": 1765818299.2696612}
{"stage": "dpo", "step": 11750, "epoch": 184, "train_loss": 0.17951804548501968, "policy_chosen_logp": -21.619251251220703, "policy_rejected_logp": -1178.79833984375, "ref_chosen_logp": -32.11132049560547, "ref_rejected_logp": -1151.4271240234375, "chosen_reward": 1.0492068529129028, "rejected_reward": -2.737130641937256, "time": 1765818301.7590895}
{"stage": "dpo", "step": 11800, "epoch": 185, "train_loss": 0.10974053025245667, "policy_chosen_logp": -24.785911560058594, "policy_rejected_logp": -981.6116943359375, "ref_chosen_logp": -40.01700973510742, "ref_rejected_logp": -961.281982421875, "chosen_reward": 1.5231099128723145, "rejected_reward": -2.0329787731170654, "time": 1765818304.2693975}
{"stage": "dpo", "step": 11840, "epoch": 185, "val_pref_acc": 1.0, "time": 1765818306.3491552}
{"stage": "dpo", "step": 11850, "epoch": 186, "train_loss": 0.04655550181865692, "policy_chosen_logp": -23.611572265625, "policy_rejected_logp": -1069.01708984375, "ref_chosen_logp": -30.457359313964844, "ref_rejected_logp": -1036.5748291015625, "chosen_reward": 0.6845784783363342, "rejected_reward": -3.244229316711426, "time": 1765818306.7493951}
{"stage": "dpo", "step": 11900, "epoch": 186, "train_loss": 0.2351862159371376, "policy_chosen_logp": -26.567663192749023, "policy_rejected_logp": -1068.044677734375, "ref_chosen_logp": -38.05601501464844, "ref_rejected_logp": -1038.978515625, "chosen_reward": 1.1488351821899414, "rejected_reward": -2.906620979309082, "time": 1765818309.2087255}
{"stage": "dpo", "step": 11950, "epoch": 187, "train_loss": 0.2155776971578598, "policy_chosen_logp": -27.294666290283203, "policy_rejected_logp": -970.4332275390625, "ref_chosen_logp": -52.11309814453125, "ref_rejected_logp": -946.6263427734375, "chosen_reward": 2.4818429946899414, "rejected_reward": -2.3806869983673096, "time": 1765818311.674881}
{"stage": "dpo", "step": 12000, "epoch": 188, "train_loss": 0.15419537752866744, "policy_chosen_logp": -16.30120849609375, "policy_rejected_logp": -1097.6470947265625, "ref_chosen_logp": -30.332670211791992, "ref_rejected_logp": -1078.1885986328125, "chosen_reward": 1.4031463861465454, "rejected_reward": -1.9458496570587158, "time": 1765818314.14498}
{"stage": "dpo", "step": 12050, "epoch": 189, "train_loss": 0.089587462246418, "policy_chosen_logp": -13.446928024291992, "policy_rejected_logp": -1058.554443359375, "ref_chosen_logp": -20.646575927734375, "ref_rejected_logp": -1021.863525390625, "chosen_reward": 0.7199647426605225, "rejected_reward": -3.6690874099731445, "time": 1765818316.584778}
{"stage": "dpo", "step": 12100, "epoch": 190, "train_loss": 0.019380567371845247, "policy_chosen_logp": -22.632081985473633, "policy_rejected_logp": -1096.569580078125, "ref_chosen_logp": -36.032012939453125, "ref_rejected_logp": -1070.7127685546875, "chosen_reward": 1.3399932384490967, "rejected_reward": -2.585693359375, "time": 1765818319.0275733}
{"stage": "dpo", "step": 12150, "epoch": 190, "train_loss": 0.24012679785490035, "policy_chosen_logp": -31.702495574951172, "policy_rejected_logp": -1019.797607421875, "ref_chosen_logp": -46.68162155151367, "ref_rejected_logp": -981.7581787109375, "chosen_reward": 1.4979124069213867, "rejected_reward": -3.803941249847412, "time": 1765818321.502413}
{"stage": "dpo", "step": 12160, "epoch": 190, "val_pref_acc": 1.0, "time": 1765818322.1184835}
{"stage": "dpo", "step": 12200, "epoch": 191, "train_loss": 0.18410225003957748, "policy_chosen_logp": -28.856502532958984, "policy_rejected_logp": -989.8151245117188, "ref_chosen_logp": -32.880523681640625, "ref_rejected_logp": -958.5126953125, "chosen_reward": 0.4024021625518799, "rejected_reward": -3.130244493484497, "time": 1765818323.9619207}
{"stage": "dpo", "step": 12250, "epoch": 192, "train_loss": 0.12164832681417465, "policy_chosen_logp": -24.98077964782715, "policy_rejected_logp": -986.929931640625, "ref_chosen_logp": -44.145565032958984, "ref_rejected_logp": -975.212158203125, "chosen_reward": 1.9164786338806152, "rejected_reward": -1.1717742681503296, "time": 1765818326.424457}
{"stage": "dpo", "step": 12300, "epoch": 193, "train_loss": 0.05699673503637314, "policy_chosen_logp": -17.10390281677246, "policy_rejected_logp": -1041.248046875, "ref_chosen_logp": -30.205068588256836, "ref_rejected_logp": -1023.1470947265625, "chosen_reward": 1.3101166486740112, "rejected_reward": -1.8100981712341309, "time": 1765818328.902995}
{"stage": "dpo", "step": 12350, "epoch": 193, "train_loss": 0.24294739037752153, "policy_chosen_logp": -22.631610870361328, "policy_rejected_logp": -1000.8790283203125, "ref_chosen_logp": -37.78337860107422, "ref_rejected_logp": -966.5933837890625, "chosen_reward": 1.5151770114898682, "rejected_reward": -3.4285600185394287, "time": 1765818331.3666341}
{"stage": "dpo", "step": 12400, "epoch": 194, "train_loss": 0.23234993785619737, "policy_chosen_logp": -11.130086898803711, "policy_rejected_logp": -1009.604248046875, "ref_chosen_logp": -27.792959213256836, "ref_rejected_logp": -977.7611083984375, "chosen_reward": 1.6662871837615967, "rejected_reward": -3.1843154430389404, "time": 1765818333.8467538}
{"stage": "dpo", "step": 12450, "epoch": 195, "train_loss": 0.15515506625175476, "policy_chosen_logp": -19.139278411865234, "policy_rejected_logp": -1036.430419921875, "ref_chosen_logp": -33.4231071472168, "ref_rejected_logp": -1007.32421875, "chosen_reward": 1.4283828735351562, "rejected_reward": -2.9106171131134033, "time": 1765818336.3644748}
{"stage": "dpo", "step": 12480, "epoch": 195, "val_pref_acc": 1.0, "time": 1765818337.9594026}
{"stage": "dpo", "step": 12500, "epoch": 196, "train_loss": 0.09234524190425873, "policy_chosen_logp": -13.534578323364258, "policy_rejected_logp": -1039.69775390625, "ref_chosen_logp": -22.5289306640625, "ref_rejected_logp": -1019.4078369140625, "chosen_reward": 0.8994351029396057, "rejected_reward": -2.028996229171753, "time": 1765818338.8236072}
{"stage": "dpo", "step": 12550, "epoch": 197, "train_loss": 0.02929611921310425, "policy_chosen_logp": -29.977615356445312, "policy_rejected_logp": -1028.490234375, "ref_chosen_logp": -47.02500915527344, "ref_rejected_logp": -1006.790283203125, "chosen_reward": 1.7047390937805176, "rejected_reward": -2.170001268386841, "time": 1765818341.2909834}
{"stage": "dpo", "step": 12600, "epoch": 197, "train_loss": 0.2352769622206688, "policy_chosen_logp": -18.590543746948242, "policy_rejected_logp": -1030.378173828125, "ref_chosen_logp": -37.35636901855469, "ref_rejected_logp": -1018.8484497070312, "chosen_reward": 1.8765828609466553, "rejected_reward": -1.152978539466858, "time": 1765818343.7633407}
{"stage": "dpo", "step": 12650, "epoch": 198, "train_loss": 0.19840167671442033, "policy_chosen_logp": -26.86266326904297, "policy_rejected_logp": -1014.2843627929688, "ref_chosen_logp": -38.255916595458984, "ref_rejected_logp": -986.622802734375, "chosen_reward": 1.1393253803253174, "rejected_reward": -2.766162157058716, "time": 1765818346.234276}
{"stage": "dpo", "step": 12700, "epoch": 199, "train_loss": 0.1326954597234726, "policy_chosen_logp": -15.293892860412598, "policy_rejected_logp": -1051.61474609375, "ref_chosen_logp": -23.308246612548828, "ref_rejected_logp": -1018.29736328125, "chosen_reward": 0.8014352321624756, "rejected_reward": -3.3317384719848633, "time": 1765818348.687462}
{"stage": "dpo", "step": 12750, "epoch": 200, "train_loss": 0.0671539705991745, "policy_chosen_logp": -18.8138370513916, "policy_rejected_logp": -1090.853515625, "ref_chosen_logp": -28.882465362548828, "ref_rejected_logp": -1061.5380859375, "chosen_reward": 1.006862759590149, "rejected_reward": -2.931540012359619, "time": 1765818351.1489983}
{"stage": "dpo", "step": 12800, "epoch": 200, "train_loss": 0.23949697822332383, "policy_chosen_logp": -19.37718391418457, "policy_rejected_logp": -1079.7176513671875, "ref_chosen_logp": -32.24285125732422, "ref_rejected_logp": -1063.2860107421875, "chosen_reward": 1.2865666151046753, "rejected_reward": -1.6431595087051392, "time": 1765818353.6083593}
{"stage": "dpo", "step": 12800, "epoch": 200, "val_pref_acc": 1.0, "time": 1765818353.735073}
{"stage": "dpo", "step": 12850, "epoch": 201, "train_loss": 0.2392711415886879, "policy_chosen_logp": -17.44082260131836, "policy_rejected_logp": -1011.195068359375, "ref_chosen_logp": -36.16596984863281, "ref_rejected_logp": -986.4221801757812, "chosen_reward": 1.8725149631500244, "rejected_reward": -2.477292060852051, "time": 1765818356.1093893}
{"stage": "dpo", "step": 12900, "epoch": 202, "train_loss": 0.18146425276994704, "policy_chosen_logp": -17.488229751586914, "policy_rejected_logp": -1071.415771484375, "ref_chosen_logp": -38.75101089477539, "ref_rejected_logp": -1051.427978515625, "chosen_reward": 2.1262779235839844, "rejected_reward": -1.998773217201233, "time": 1765818358.6271408}
{"stage": "dpo", "step": 12950, "epoch": 203, "train_loss": 0.10427371352910995, "policy_chosen_logp": -15.44670295715332, "policy_rejected_logp": -991.0889282226562, "ref_chosen_logp": -27.802881240844727, "ref_rejected_logp": -961.8056640625, "chosen_reward": 1.2356178760528564, "rejected_reward": -2.9283218383789062, "time": 1765818361.1449776}
{"stage": "dpo", "step": 13000, "epoch": 204, "train_loss": 0.03753576964139938, "policy_chosen_logp": -23.7452392578125, "policy_rejected_logp": -1069.1053466796875, "ref_chosen_logp": -38.808998107910156, "ref_rejected_logp": -1045.3759765625, "chosen_reward": 1.506376028060913, "rejected_reward": -2.3729279041290283, "time": 1765818363.6416085}
{"stage": "dpo", "step": 13050, "epoch": 204, "train_loss": 0.2367280474305153, "policy_chosen_logp": -15.647712707519531, "policy_rejected_logp": -1044.2523193359375, "ref_chosen_logp": -35.89464569091797, "ref_rejected_logp": -1033.153076171875, "chosen_reward": 2.024693012237549, "rejected_reward": -1.1099228858947754, "time": 1765818366.126522}
{"stage": "dpo", "step": 13100, "epoch": 205, "train_loss": 0.20544956743717194, "policy_chosen_logp": -23.344989776611328, "policy_rejected_logp": -1147.1409912109375, "ref_chosen_logp": -39.197120666503906, "ref_rejected_logp": -1125.404541015625, "chosen_reward": 1.585213303565979, "rejected_reward": -2.1736526489257812, "time": 1765818368.6009498}
{"stage": "dpo", "step": 13120, "epoch": 205, "val_pref_acc": 1.0, "time": 1765818369.7272527}
{"stage": "dpo", "step": 13150, "epoch": 206, "train_loss": 0.14463940232992173, "policy_chosen_logp": -15.431907653808594, "policy_rejected_logp": -1087.384521484375, "ref_chosen_logp": -32.631473541259766, "ref_rejected_logp": -1061.482177734375, "chosen_reward": 1.7199565172195435, "rejected_reward": -2.590235948562622, "time": 1765818371.1209092}
{"stage": "dpo", "step": 13200, "epoch": 207, "train_loss": 0.07372785359621048, "policy_chosen_logp": -19.40370750427246, "policy_rejected_logp": -975.315673828125, "ref_chosen_logp": -29.19381332397461, "ref_rejected_logp": -954.1458129882812, "chosen_reward": 0.9790104627609253, "rejected_reward": -2.116987705230713, "time": 1765818373.6873481}
{"stage": "dpo", "step": 13250, "epoch": 208, "train_loss": 0.008952863216400146, "policy_chosen_logp": -16.879993438720703, "policy_rejected_logp": -942.0784301757812, "ref_chosen_logp": -28.423673629760742, "ref_rejected_logp": -914.1192016601562, "chosen_reward": 1.1543681621551514, "rejected_reward": -2.795924663543701, "time": 1765818376.1945333}
{"stage": "dpo", "step": 13300, "epoch": 208, "train_loss": 0.23702989101409913, "policy_chosen_logp": -18.973979949951172, "policy_rejected_logp": -966.7898559570312, "ref_chosen_logp": -34.8185920715332, "ref_rejected_logp": -948.3663940429688, "chosen_reward": 1.5844613313674927, "rejected_reward": -1.8423508405685425, "time": 1765818378.816958}
{"stage": "dpo", "step": 13350, "epoch": 209, "train_loss": 0.17597678154706956, "policy_chosen_logp": -23.170001983642578, "policy_rejected_logp": -1029.186279296875, "ref_chosen_logp": -31.404321670532227, "ref_rejected_logp": -999.112060546875, "chosen_reward": 0.8234318494796753, "rejected_reward": -3.007420301437378, "time": 1765818381.3598852}
{"stage": "dpo", "step": 13400, "epoch": 210, "train_loss": 0.11464464128017425, "policy_chosen_logp": -13.029973983764648, "policy_rejected_logp": -1060.826416015625, "ref_chosen_logp": -28.33078384399414, "ref_rejected_logp": -1045.50048828125, "chosen_reward": 1.530081033706665, "rejected_reward": -1.532597303390503, "time": 1765818383.8879364}
{"stage": "dpo", "step": 13440, "epoch": 210, "val_pref_acc": 1.0, "time": 1765818386.0229733}
{"stage": "dpo", "step": 13450, "epoch": 211, "train_loss": 0.04478263646364212, "policy_chosen_logp": -23.4150390625, "policy_rejected_logp": -1073.1932373046875, "ref_chosen_logp": -43.75707244873047, "ref_rejected_logp": -1061.359375, "chosen_reward": 2.034203290939331, "rejected_reward": -1.183380126953125, "time": 1765818386.4165978}
{"stage": "dpo", "step": 13500, "epoch": 211, "train_loss": 0.22987590938806535, "policy_chosen_logp": -25.577037811279297, "policy_rejected_logp": -1016.445068359375, "ref_chosen_logp": -39.61267852783203, "ref_rejected_logp": -987.1143798828125, "chosen_reward": 1.4035639762878418, "rejected_reward": -2.9330644607543945, "time": 1765818388.8564534}
{"stage": "dpo", "step": 13550, "epoch": 212, "train_loss": 0.21414715200662612, "policy_chosen_logp": -12.772579193115234, "policy_rejected_logp": -1117.329833984375, "ref_chosen_logp": -26.58832359313965, "ref_rejected_logp": -1106.375244140625, "chosen_reward": 1.3815745115280151, "rejected_reward": -1.0954697132110596, "time": 1765818391.3605227}
{"stage": "dpo", "step": 13600, "epoch": 213, "train_loss": 0.1469373369216919, "policy_chosen_logp": -16.39999008178711, "policy_rejected_logp": -1092.971435546875, "ref_chosen_logp": -29.1745548248291, "ref_rejected_logp": -1078.022216796875, "chosen_reward": 1.2774564027786255, "rejected_reward": -1.4949172735214233, "time": 1765818393.8584156}
{"stage": "dpo", "step": 13650, "epoch": 214, "train_loss": 0.08522588282823562, "policy_chosen_logp": -19.975194931030273, "policy_rejected_logp": -1015.5889282226562, "ref_chosen_logp": -40.613807678222656, "ref_rejected_logp": -996.1535034179688, "chosen_reward": 2.06386137008667, "rejected_reward": -1.9435454607009888, "time": 1765818396.3496463}
{"stage": "dpo", "step": 13700, "epoch": 215, "train_loss": 0.019171746075153352, "policy_chosen_logp": -21.66140365600586, "policy_rejected_logp": -1084.377197265625, "ref_chosen_logp": -39.877037048339844, "ref_rejected_logp": -1071.69091796875, "chosen_reward": 1.8215632438659668, "rejected_reward": -1.2686126232147217, "time": 1765818398.8520646}
{"stage": "dpo", "step": 13750, "epoch": 215, "train_loss": 0.23605959624052048, "policy_chosen_logp": -21.144622802734375, "policy_rejected_logp": -1047.843505859375, "ref_chosen_logp": -28.681888580322266, "ref_rejected_logp": -1034.4285888671875, "chosen_reward": 0.7537263631820679, "rejected_reward": -1.341496229171753, "time": 1765818401.3063166}
{"stage": "dpo", "step": 13760, "epoch": 215, "val_pref_acc": 1.0, "time": 1765818401.9314826}
{"stage": "dpo", "step": 13800, "epoch": 216, "train_loss": 0.19791684657335282, "policy_chosen_logp": -25.777080535888672, "policy_rejected_logp": -1140.174072265625, "ref_chosen_logp": -47.498199462890625, "ref_rejected_logp": -1133.672607421875, "chosen_reward": 2.172112226486206, "rejected_reward": -0.6501327753067017, "time": 1765818403.7893379}
{"stage": "dpo", "step": 13850, "epoch": 217, "train_loss": 0.11793236553668976, "policy_chosen_logp": -20.249744415283203, "policy_rejected_logp": -1074.843505859375, "ref_chosen_logp": -37.609134674072266, "ref_rejected_logp": -1051.250244140625, "chosen_reward": 1.7359390258789062, "rejected_reward": -2.359332323074341, "time": 1765818406.153347}
{"stage": "dpo", "step": 13900, "epoch": 218, "train_loss": 0.05543069958686828, "policy_chosen_logp": -11.865774154663086, "policy_rejected_logp": -1087.4622802734375, "ref_chosen_logp": -22.590864181518555, "ref_rejected_logp": -1055.4674072265625, "chosen_reward": 1.0725090503692627, "rejected_reward": -3.19948148727417, "time": 1765818408.6284142}
{"stage": "dpo", "step": 13950, "epoch": 218, "train_loss": 0.23164240926504134, "policy_chosen_logp": -16.49823570251465, "policy_rejected_logp": -1117.5433349609375, "ref_chosen_logp": -31.48858642578125, "ref_rejected_logp": -1088.288818359375, "chosen_reward": 1.4990350008010864, "rejected_reward": -2.9254441261291504, "time": 1765818410.725679}
{"stage": "dpo", "step": 14000, "epoch": 219, "train_loss": 0.22384213536977768, "policy_chosen_logp": -19.255855560302734, "policy_rejected_logp": -1039.428955078125, "ref_chosen_logp": -34.01755142211914, "ref_rejected_logp": -1016.5762939453125, "chosen_reward": 1.4761693477630615, "rejected_reward": -2.285273790359497, "time": 1765818412.7867122}
{"stage": "dpo", "step": 14050, "epoch": 220, "train_loss": 0.16916160136461258, "policy_chosen_logp": -17.989948272705078, "policy_rejected_logp": -1112.180419921875, "ref_chosen_logp": -35.90851593017578, "ref_rejected_logp": -1090.7056884765625, "chosen_reward": 1.7918566465377808, "rejected_reward": -2.1474761962890625, "time": 1765818415.1643372}
{"stage": "dpo", "step": 14080, "epoch": 220, "val_pref_acc": 1.0, "time": 1765818416.7591014}
{"stage": "dpo", "step": 14100, "epoch": 221, "train_loss": 0.09730593264102935, "policy_chosen_logp": -21.632781982421875, "policy_rejected_logp": -949.130615234375, "ref_chosen_logp": -42.496665954589844, "ref_rejected_logp": -925.5331420898438, "chosen_reward": 2.08638858795166, "rejected_reward": -2.359753370285034, "time": 1765818417.6155083}
{"stage": "dpo", "step": 14150, "epoch": 222, "train_loss": 0.027816784977912904, "policy_chosen_logp": -19.171810150146484, "policy_rejected_logp": -1079.25244140625, "ref_chosen_logp": -47.077980041503906, "ref_rejected_logp": -1075.3978271484375, "chosen_reward": 2.7906172275543213, "rejected_reward": -0.385458379983902, "time": 1765818420.1018844}
{"stage": "dpo", "step": 14200, "epoch": 222, "train_loss": 0.22596169233322144, "policy_chosen_logp": -17.083595275878906, "policy_rejected_logp": -1016.25341796875, "ref_chosen_logp": -39.850563049316406, "ref_rejected_logp": -1001.906982421875, "chosen_reward": 2.2766966819763184, "rejected_reward": -1.4346466064453125, "time": 1765818422.583864}
{"stage": "dpo", "step": 14250, "epoch": 223, "train_loss": 0.19277382403612137, "policy_chosen_logp": -22.427276611328125, "policy_rejected_logp": -1086.906982421875, "ref_chosen_logp": -41.665897369384766, "ref_rejected_logp": -1064.96728515625, "chosen_reward": 1.923862099647522, "rejected_reward": -2.193957567214966, "time": 1765818425.0553305}
{"stage": "dpo", "step": 14300, "epoch": 224, "train_loss": 0.1250546979904175, "policy_chosen_logp": -29.48581886291504, "policy_rejected_logp": -1083.96484375, "ref_chosen_logp": -43.157745361328125, "ref_rejected_logp": -1069.203125, "chosen_reward": 1.3671927452087402, "rejected_reward": -1.476161241531372, "time": 1765818427.6209095}
{"stage": "dpo", "step": 14350, "epoch": 225, "train_loss": 0.07179114937782288, "policy_chosen_logp": -23.457286834716797, "policy_rejected_logp": -1092.57373046875, "ref_chosen_logp": -43.36687469482422, "ref_rejected_logp": -1050.951416015625, "chosen_reward": 1.9909589290618896, "rejected_reward": -4.162227153778076, "time": 1765818430.0740683}
{"stage": "dpo", "step": 14400, "epoch": 225, "train_loss": 0.2368701294064522, "policy_chosen_logp": -19.63654327392578, "policy_rejected_logp": -1026.93798828125, "ref_chosen_logp": -40.891319274902344, "ref_rejected_logp": -1007.4580078125, "chosen_reward": 2.1254775524139404, "rejected_reward": -1.947998046875, "time": 1765818432.5382557}
{"stage": "dpo", "step": 14400, "epoch": 225, "val_pref_acc": 1.0, "time": 1765818432.6721685}
{"stage": "dpo", "step": 14450, "epoch": 226, "train_loss": 0.2344358065724373, "policy_chosen_logp": -10.251277923583984, "policy_rejected_logp": -1126.0244140625, "ref_chosen_logp": -17.894561767578125, "ref_rejected_logp": -1095.70751953125, "chosen_reward": 0.7643283605575562, "rejected_reward": -3.0316896438598633, "time": 1765818435.031849}
{"stage": "dpo", "step": 14500, "epoch": 227, "train_loss": 0.16982846647500993, "policy_chosen_logp": -10.823606491088867, "policy_rejected_logp": -1091.4066162109375, "ref_chosen_logp": -26.588134765625, "ref_rejected_logp": -1067.29443359375, "chosen_reward": 1.5764527320861816, "rejected_reward": -2.4112229347229004, "time": 1765818437.5271735}
{"stage": "dpo", "step": 14550, "epoch": 228, "train_loss": 0.10222703158855438, "policy_chosen_logp": -11.664006233215332, "policy_rejected_logp": -975.6890869140625, "ref_chosen_logp": -20.44168472290039, "ref_rejected_logp": -947.114990234375, "chosen_reward": 0.8777679204940796, "rejected_reward": -2.857409715652466, "time": 1765818439.8915746}
{"stage": "dpo", "step": 14600, "epoch": 229, "train_loss": 0.036618883907794955, "policy_chosen_logp": -19.84029769897461, "policy_rejected_logp": -1064.947265625, "ref_chosen_logp": -30.63483428955078, "ref_rejected_logp": -1035.031982421875, "chosen_reward": 1.0794538259506226, "rejected_reward": -2.9915223121643066, "time": 1765818442.198582}
{"stage": "dpo", "step": 14650, "epoch": 229, "train_loss": 0.22879688799381256, "policy_chosen_logp": -17.159860610961914, "policy_rejected_logp": -1030.1510009765625, "ref_chosen_logp": -36.62171936035156, "ref_rejected_logp": -1016.4385375976562, "chosen_reward": 1.9461859464645386, "rejected_reward": -1.3712478876113892, "time": 1765818444.6565337}
{"stage": "dpo", "step": 14700, "epoch": 230, "train_loss": 0.20774489641189575, "policy_chosen_logp": -24.096263885498047, "policy_rejected_logp": -1132.6612548828125, "ref_chosen_logp": -45.701812744140625, "ref_rejected_logp": -1108.047119140625, "chosen_reward": 2.1605546474456787, "rejected_reward": -2.461409091949463, "time": 1765818447.1209595}
{"stage": "dpo", "step": 14720, "epoch": 230, "val_pref_acc": 1.0, "time": 1765818448.2322617}
{"stage": "dpo", "step": 14750, "epoch": 231, "train_loss": 0.14160176783800124, "policy_chosen_logp": -28.274242401123047, "policy_rejected_logp": -1089.200927734375, "ref_chosen_logp": -49.38727569580078, "ref_rejected_logp": -1069.031494140625, "chosen_reward": 2.1113033294677734, "rejected_reward": -2.0169448852539062, "time": 1765818449.5822973}
{"stage": "dpo", "step": 14800, "epoch": 232, "train_loss": 0.07235746175050735, "policy_chosen_logp": -16.44338607788086, "policy_rejected_logp": -1172.218017578125, "ref_chosen_logp": -36.81224822998047, "ref_rejected_logp": -1160.9351806640625, "chosen_reward": 2.036886215209961, "rejected_reward": -1.1282837390899658, "time": 1765818452.0421555}
{"stage": "dpo", "step": 14850, "epoch": 233, "train_loss": 0.008704941272735595, "policy_chosen_logp": -23.959875106811523, "policy_rejected_logp": -1066.043701171875, "ref_chosen_logp": -31.33889389038086, "ref_rejected_logp": -1046.30615234375, "chosen_reward": 0.7379019260406494, "rejected_reward": -1.9737579822540283, "time": 1765818454.5091615}
{"stage": "dpo", "step": 14900, "epoch": 233, "train_loss": 0.23026437252759935, "policy_chosen_logp": -14.395021438598633, "policy_rejected_logp": -1034.99609375, "ref_chosen_logp": -29.065834045410156, "ref_rejected_logp": -1021.6629028320312, "chosen_reward": 1.4670813083648682, "rejected_reward": -1.33331298828125, "time": 1765818456.97283}
{"stage": "dpo", "step": 14950, "epoch": 234, "train_loss": 0.17821318179368972, "policy_chosen_logp": -13.083365440368652, "policy_rejected_logp": -1053.0540771484375, "ref_chosen_logp": -45.476341247558594, "ref_rejected_logp": -1050.7490234375, "chosen_reward": 3.239297866821289, "rejected_reward": -0.2304931879043579, "time": 1765818459.4268}
{"stage": "dpo", "step": 15000, "epoch": 235, "train_loss": 0.10899758577346802, "policy_chosen_logp": -27.353282928466797, "policy_rejected_logp": -1054.88330078125, "ref_chosen_logp": -41.49816131591797, "ref_rejected_logp": -1034.84033203125, "chosen_reward": 1.4144878387451172, "rejected_reward": -2.0042953491210938, "time": 1765818461.8774333}
{"stage": "dpo", "step": 15040, "epoch": 235, "val_pref_acc": 1.0, "time": 1765818464.026748}
{"stage": "dpo", "step": 15050, "epoch": 236, "train_loss": 0.04646060526371002, "policy_chosen_logp": -17.368728637695312, "policy_rejected_logp": -1064.435546875, "ref_chosen_logp": -43.08258819580078, "ref_rejected_logp": -1037.6781005859375, "chosen_reward": 2.5713863372802734, "rejected_reward": -2.6757521629333496, "time": 1765818464.42138}
{"stage": "dpo", "step": 15100, "epoch": 236, "train_loss": 0.22863734692335128, "policy_chosen_logp": -20.854690551757812, "policy_rejected_logp": -1108.310791015625, "ref_chosen_logp": -46.46687316894531, "ref_rejected_logp": -1092.293212890625, "chosen_reward": 2.56121826171875, "rejected_reward": -1.6017639636993408, "time": 1765818466.8502877}
{"stage": "dpo", "step": 15150, "epoch": 237, "train_loss": 0.21234752267599105, "policy_chosen_logp": -17.630401611328125, "policy_rejected_logp": -914.778564453125, "ref_chosen_logp": -37.88086700439453, "ref_rejected_logp": -898.1356811523438, "chosen_reward": 2.0250465869903564, "rejected_reward": -1.6642884016036987, "time": 1765818469.320993}
{"stage": "dpo", "step": 15200, "epoch": 238, "train_loss": 0.14484915196895598, "policy_chosen_logp": -17.833133697509766, "policy_rejected_logp": -1068.099365234375, "ref_chosen_logp": -31.55246353149414, "ref_rejected_logp": -1049.0859375, "chosen_reward": 1.371933102607727, "rejected_reward": -1.9013473987579346, "time": 1765818471.8250847}
{"stage": "dpo", "step": 15250, "epoch": 239, "train_loss": 0.08126058638095855, "policy_chosen_logp": -16.775524139404297, "policy_rejected_logp": -1079.090087890625, "ref_chosen_logp": -39.923484802246094, "ref_rejected_logp": -1056.882080078125, "chosen_reward": 2.314796209335327, "rejected_reward": -2.2207977771759033, "time": 1765818474.2988887}
{"stage": "dpo", "step": 15300, "epoch": 240, "train_loss": 0.017254748940467836, "policy_chosen_logp": -14.180768966674805, "policy_rejected_logp": -1125.275390625, "ref_chosen_logp": -33.68651580810547, "ref_rejected_logp": -1114.19189453125, "chosen_reward": 1.9505748748779297, "rejected_reward": -1.1083465814590454, "time": 1765818476.7615523}
{"stage": "dpo", "step": 15350, "epoch": 240, "train_loss": 0.2266043159365654, "policy_chosen_logp": -22.000343322753906, "policy_rejected_logp": -1038.2452392578125, "ref_chosen_logp": -39.426387786865234, "ref_rejected_logp": -1018.900390625, "chosen_reward": 1.742604374885559, "rejected_reward": -1.9344909191131592, "time": 1765818479.2176828}
{"stage": "dpo", "step": 15360, "epoch": 240, "val_pref_acc": 1.0, "time": 1765818479.8362536}
{"stage": "dpo", "step": 15400, "epoch": 241, "train_loss": 0.1857283315062523, "policy_chosen_logp": -15.647048950195312, "policy_rejected_logp": -1120.315673828125, "ref_chosen_logp": -30.615253448486328, "ref_rejected_logp": -1089.30712890625, "chosen_reward": 1.4968205690383911, "rejected_reward": -3.100846767425537, "time": 1765818481.7026176}
{"stage": "dpo", "step": 15450, "epoch": 242, "train_loss": 0.11804257184267045, "policy_chosen_logp": -18.39864158630371, "policy_rejected_logp": -1017.4734497070312, "ref_chosen_logp": -29.65979766845703, "ref_rejected_logp": -993.1182861328125, "chosen_reward": 1.1261155605316162, "rejected_reward": -2.4355101585388184, "time": 1765818484.0424473}
{"stage": "dpo", "step": 15500, "epoch": 243, "train_loss": 0.054279669523239135, "policy_chosen_logp": -31.980377197265625, "policy_rejected_logp": -1092.379638671875, "ref_chosen_logp": -43.27522277832031, "ref_rejected_logp": -1068.6693115234375, "chosen_reward": 1.12948477268219, "rejected_reward": -2.3710451126098633, "time": 1765818486.0499694}
{"stage": "dpo", "step": 15550, "epoch": 243, "train_loss": 0.2334642654657364, "policy_chosen_logp": -16.715621948242188, "policy_rejected_logp": -1040.78369140625, "ref_chosen_logp": -25.468326568603516, "ref_rejected_logp": -1010.3897705078125, "chosen_reward": 0.8752701282501221, "rejected_reward": -3.039393663406372, "time": 1765818488.5518267}
{"stage": "dpo", "step": 15600, "epoch": 244, "train_loss": 0.22115379571914673, "policy_chosen_logp": -17.655017852783203, "policy_rejected_logp": -964.9805908203125, "ref_chosen_logp": -37.3050537109375, "ref_rejected_logp": -951.2971801757812, "chosen_reward": 1.9650037288665771, "rejected_reward": -1.368342638015747, "time": 1765818491.0671933}
{"stage": "dpo", "step": 15650, "epoch": 245, "train_loss": 0.1614166894555092, "policy_chosen_logp": -22.380931854248047, "policy_rejected_logp": -1005.9034423828125, "ref_chosen_logp": -36.03986740112305, "ref_rejected_logp": -988.7506103515625, "chosen_reward": 1.3658936023712158, "rejected_reward": -1.7152817249298096, "time": 1765818492.527378}
{"stage": "dpo", "step": 15680, "epoch": 245, "val_pref_acc": 1.0, "time": 1765818494.112757}
{"stage": "dpo", "step": 15700, "epoch": 246, "train_loss": 0.09502382099628448, "policy_chosen_logp": -20.277729034423828, "policy_rejected_logp": -1053.032470703125, "ref_chosen_logp": -41.918724060058594, "ref_rejected_logp": -1037.970947265625, "chosen_reward": 2.164100170135498, "rejected_reward": -1.506160020828247, "time": 1765818494.9641063}
{"stage": "dpo", "step": 15750, "epoch": 247, "train_loss": 0.028113400638103483, "policy_chosen_logp": -28.705944061279297, "policy_rejected_logp": -1050.184814453125, "ref_chosen_logp": -56.13111114501953, "ref_rejected_logp": -1045.7850341796875, "chosen_reward": 2.74251651763916, "rejected_reward": -0.4399825930595398, "time": 1765818497.4398656}
{"stage": "dpo", "step": 15800, "epoch": 247, "train_loss": 0.22731589049100875, "policy_chosen_logp": -19.484159469604492, "policy_rejected_logp": -1126.80126953125, "ref_chosen_logp": -37.242706298828125, "ref_rejected_logp": -1113.2115478515625, "chosen_reward": 1.775854468345642, "rejected_reward": -1.3589751720428467, "time": 1765818499.9050188}
{"stage": "dpo", "step": 15850, "epoch": 248, "train_loss": 0.19077373236417772, "policy_chosen_logp": -13.350425720214844, "policy_rejected_logp": -1023.5648193359375, "ref_chosen_logp": -26.472957611083984, "ref_rejected_logp": -1000.8501586914062, "chosen_reward": 1.3122531175613403, "rejected_reward": -2.271472454071045, "time": 1765818502.3782544}
{"stage": "dpo", "step": 15900, "epoch": 249, "train_loss": 0.12455764085054398, "policy_chosen_logp": -19.521860122680664, "policy_rejected_logp": -1009.0830688476562, "ref_chosen_logp": -35.548179626464844, "ref_rejected_logp": -994.5086669921875, "chosen_reward": 1.6026320457458496, "rejected_reward": -1.4574371576309204, "time": 1765818504.855231}
{"stage": "dpo", "step": 15950, "epoch": 250, "train_loss": 0.06084622949361801, "policy_chosen_logp": -16.49915313720703, "policy_rejected_logp": -1141.248291015625, "ref_chosen_logp": -31.601543426513672, "ref_rejected_logp": -1123.238525390625, "chosen_reward": 1.5102388858795166, "rejected_reward": -1.800978183746338, "time": 1765818507.3182912}
{"stage": "dpo", "step": 16000, "epoch": 250, "train_loss": 0.22551991283893585, "policy_chosen_logp": -17.22519302368164, "policy_rejected_logp": -1022.1220092773438, "ref_chosen_logp": -34.038150787353516, "ref_rejected_logp": -994.0556030273438, "chosen_reward": 1.6812957525253296, "rejected_reward": -2.806640625, "time": 1765818509.8389423}
{"stage": "dpo", "step": 16000, "epoch": 250, "val_pref_acc": 1.0, "time": 1765818509.9676847}
{"stage": "dpo", "step": 16050, "epoch": 251, "train_loss": 0.22701601147651673, "policy_chosen_logp": -14.467851638793945, "policy_rejected_logp": -1021.1318969726562, "ref_chosen_logp": -27.312702178955078, "ref_rejected_logp": -997.6117553710938, "chosen_reward": 1.284485101699829, "rejected_reward": -2.3520126342773438, "time": 1765818512.353765}
{"stage": "dpo", "step": 16100, "epoch": 252, "train_loss": 0.16497501134872436, "policy_chosen_logp": -20.809677124023438, "policy_rejected_logp": -1043.5101318359375, "ref_chosen_logp": -33.32286071777344, "ref_rejected_logp": -1014.3515625, "chosen_reward": 1.251318097114563, "rejected_reward": -2.9158568382263184, "time": 1765818514.9668317}
{"stage": "dpo", "step": 16150, "epoch": 253, "train_loss": 0.09849236994981765, "policy_chosen_logp": -16.237205505371094, "policy_rejected_logp": -1030.250244140625, "ref_chosen_logp": -27.765300750732422, "ref_rejected_logp": -1006.3468627929688, "chosen_reward": 1.1528093814849854, "rejected_reward": -2.390345811843872, "time": 1765818517.5419023}
{"stage": "dpo", "step": 16200, "epoch": 254, "train_loss": 0.03701394855976105, "policy_chosen_logp": -12.433469772338867, "policy_rejected_logp": -1071.0693359375, "ref_chosen_logp": -26.29059410095215, "ref_rejected_logp": -1052.1065673828125, "chosen_reward": 1.3857123851776123, "rejected_reward": -1.896275520324707, "time": 1765818520.0264704}
{"stage": "dpo", "step": 16250, "epoch": 254, "train_loss": 0.23012747257947921, "policy_chosen_logp": -17.417011260986328, "policy_rejected_logp": -1088.362060546875, "ref_chosen_logp": -37.49669647216797, "ref_rejected_logp": -1071.62353515625, "chosen_reward": 2.0079689025878906, "rejected_reward": -1.673854112625122, "time": 1765818522.5137954}
{"stage": "dpo", "step": 16300, "epoch": 255, "train_loss": 0.2092176041007042, "policy_chosen_logp": -17.85879898071289, "policy_rejected_logp": -1026.7989501953125, "ref_chosen_logp": -34.939353942871094, "ref_rejected_logp": -1006.5443115234375, "chosen_reward": 1.7080557346343994, "rejected_reward": -2.025465488433838, "time": 1765818524.9697542}
{"stage": "dpo", "step": 16320, "epoch": 255, "val_pref_acc": 1.0, "time": 1765818526.0814404}
{"stage": "dpo", "step": 16350, "epoch": 256, "train_loss": 0.13501353532075883, "policy_chosen_logp": -11.920729637145996, "policy_rejected_logp": -1045.698974609375, "ref_chosen_logp": -23.049768447875977, "ref_rejected_logp": -1021.9013671875, "chosen_reward": 1.1129039525985718, "rejected_reward": -2.3797576427459717, "time": 1765818527.42409}
{"stage": "dpo", "step": 16400, "epoch": 257, "train_loss": 0.07308939635753632, "policy_chosen_logp": -25.527772903442383, "policy_rejected_logp": -1078.5555419921875, "ref_chosen_logp": -38.03751754760742, "ref_rejected_logp": -1068.67431640625, "chosen_reward": 1.2509746551513672, "rejected_reward": -0.9881241321563721, "time": 1765818529.9058416}
{"stage": "dpo", "step": 16450, "epoch": 258, "train_loss": 0.008575908839702606, "policy_chosen_logp": -17.636526107788086, "policy_rejected_logp": -1041.9840087890625, "ref_chosen_logp": -36.27058410644531, "ref_rejected_logp": -1023.484375, "chosen_reward": 1.863405704498291, "rejected_reward": -1.8499603271484375, "time": 1765818532.3741467}
{"stage": "dpo", "step": 16500, "epoch": 258, "train_loss": 0.22515590310096742, "policy_chosen_logp": -19.90825080871582, "policy_rejected_logp": -1022.780029296875, "ref_chosen_logp": -31.48191261291504, "ref_rejected_logp": -1011.0482788085938, "chosen_reward": 1.1573662757873535, "rejected_reward": -1.1731750965118408, "time": 1765818534.8615947}
{"stage": "dpo", "step": 16550, "epoch": 259, "train_loss": 0.16710607081651688, "policy_chosen_logp": -12.280563354492188, "policy_rejected_logp": -1024.721435546875, "ref_chosen_logp": -22.149002075195312, "ref_rejected_logp": -1008.498046875, "chosen_reward": 0.9868438839912415, "rejected_reward": -1.6223312616348267, "time": 1765818537.3336504}
{"stage": "dpo", "step": 16600, "epoch": 260, "train_loss": 0.10766734004020691, "policy_chosen_logp": -19.964611053466797, "policy_rejected_logp": -1013.47998046875, "ref_chosen_logp": -43.34341812133789, "ref_rejected_logp": -1009.7333374023438, "chosen_reward": 2.3378806114196777, "rejected_reward": -0.3746628165245056, "time": 1765818539.7871125}
{"stage": "dpo", "step": 16640, "epoch": 260, "val_pref_acc": 1.0, "time": 1765818541.8910437}
{"stage": "dpo", "step": 16650, "epoch": 261, "train_loss": 0.043863032460212704, "policy_chosen_logp": -16.611555099487305, "policy_rejected_logp": -1042.5166015625, "ref_chosen_logp": -30.487022399902344, "ref_rejected_logp": -1026.84130859375, "chosen_reward": 1.3875467777252197, "rejected_reward": -1.567524790763855, "time": 1765818542.28079}
{"stage": "dpo", "step": 16700, "epoch": 261, "train_loss": 0.23101560205221175, "policy_chosen_logp": -15.994588851928711, "policy_rejected_logp": -1019.201171875, "ref_chosen_logp": -26.827482223510742, "ref_rejected_logp": -996.7905883789062, "chosen_reward": 1.083289384841919, "rejected_reward": -2.241058349609375, "time": 1765818544.6667438}
{"stage": "dpo", "step": 16750, "epoch": 262, "train_loss": 0.21267636388540268, "policy_chosen_logp": -15.42516040802002, "policy_rejected_logp": -1056.337646484375, "ref_chosen_logp": -37.512542724609375, "ref_rejected_logp": -1033.8253173828125, "chosen_reward": 2.208738088607788, "rejected_reward": -2.2512269020080566, "time": 1765818547.1448345}
{"stage": "dpo", "step": 16800, "epoch": 263, "train_loss": 0.14550370037555693, "policy_chosen_logp": -20.194101333618164, "policy_rejected_logp": -1079.998046875, "ref_chosen_logp": -44.93523406982422, "ref_rejected_logp": -1064.720458984375, "chosen_reward": 2.4741134643554688, "rejected_reward": -1.5277512073516846, "time": 1765818549.618915}
{"stage": "dpo", "step": 16850, "epoch": 264, "train_loss": 0.0799283167719841, "policy_chosen_logp": -27.085357666015625, "policy_rejected_logp": -1033.7593994140625, "ref_chosen_logp": -49.84614562988281, "ref_rejected_logp": -1024.002197265625, "chosen_reward": 2.276078701019287, "rejected_reward": -0.9757125973701477, "time": 1765818552.1428423}
{"stage": "dpo", "step": 16900, "epoch": 265, "train_loss": 0.021465232372283937, "policy_chosen_logp": -19.0711669921875, "policy_rejected_logp": -965.57958984375, "ref_chosen_logp": -35.30329895019531, "ref_rejected_logp": -941.750732421875, "chosen_reward": 1.6232130527496338, "rejected_reward": -2.3828859329223633, "time": 1765818554.6363413}
{"stage": "dpo", "step": 16950, "epoch": 265, "train_loss": 0.2267781275510788, "policy_chosen_logp": -30.304838180541992, "policy_rejected_logp": -1032.374267578125, "ref_chosen_logp": -42.33137512207031, "ref_rejected_logp": -1006.2244873046875, "chosen_reward": 1.2026538848876953, "rejected_reward": -2.6149749755859375, "time": 1765818557.168699}
{"stage": "dpo", "step": 16960, "epoch": 265, "val_pref_acc": 1.0, "time": 1765818557.7827587}
{"stage": "dpo", "step": 17000, "epoch": 266, "train_loss": 0.1797904634475708, "policy_chosen_logp": -21.115516662597656, "policy_rejected_logp": -1056.136962890625, "ref_chosen_logp": -41.47403335571289, "ref_rejected_logp": -1035.862548828125, "chosen_reward": 2.0358517169952393, "rejected_reward": -2.0274429321289062, "time": 1765818559.661117}
{"stage": "dpo", "step": 17050, "epoch": 267, "train_loss": 0.11540438652038575, "policy_chosen_logp": -14.118480682373047, "policy_rejected_logp": -1093.510986328125, "ref_chosen_logp": -32.54228210449219, "ref_rejected_logp": -1068.1341552734375, "chosen_reward": 1.8423802852630615, "rejected_reward": -2.5376923084259033, "time": 1765818562.2120388}
{"stage": "dpo", "step": 17100, "epoch": 268, "train_loss": 0.05670735090970993, "policy_chosen_logp": -18.13360023498535, "policy_rejected_logp": -1015.4288330078125, "ref_chosen_logp": -37.28481674194336, "ref_rejected_logp": -986.0733032226562, "chosen_reward": 1.9151216745376587, "rejected_reward": -2.9355499744415283, "time": 1765818564.6976526}
{"stage": "dpo", "step": 17150, "epoch": 268, "train_loss": 0.22560882180929184, "policy_chosen_logp": -24.445907592773438, "policy_rejected_logp": -1045.1402587890625, "ref_chosen_logp": -36.871212005615234, "ref_rejected_logp": -1033.0570068359375, "chosen_reward": 1.2425305843353271, "rejected_reward": -1.2083313465118408, "time": 1765818567.1781063}
{"stage": "dpo", "step": 17200, "epoch": 269, "train_loss": 0.2192722824215889, "policy_chosen_logp": -18.45679473876953, "policy_rejected_logp": -1075.735595703125, "ref_chosen_logp": -44.11216735839844, "ref_rejected_logp": -1070.969970703125, "chosen_reward": 2.565537214279175, "rejected_reward": -0.47655946016311646, "time": 1765818569.656982}
{"stage": "dpo", "step": 17250, "epoch": 270, "train_loss": 0.15541900485754012, "policy_chosen_logp": -20.98845100402832, "policy_rejected_logp": -1134.238037109375, "ref_chosen_logp": -44.82722091674805, "ref_rejected_logp": -1122.743896484375, "chosen_reward": 2.3838768005371094, "rejected_reward": -1.1494109630584717, "time": 1765818572.1386368}
{"stage": "dpo", "step": 17280, "epoch": 270, "val_pref_acc": 1.0, "time": 1765818573.7461336}
{"stage": "dpo", "step": 17300, "epoch": 271, "train_loss": 0.08927185535430908, "policy_chosen_logp": -14.682064056396484, "policy_rejected_logp": -1106.16455078125, "ref_chosen_logp": -42.92321014404297, "ref_rejected_logp": -1100.994873046875, "chosen_reward": 2.8241147994995117, "rejected_reward": -0.5169678330421448, "time": 1765818574.607094}
{"stage": "dpo", "step": 17350, "epoch": 272, "train_loss": 0.02697729557752609, "policy_chosen_logp": -31.036334991455078, "policy_rejected_logp": -1021.9947509765625, "ref_chosen_logp": -52.02027893066406, "ref_rejected_logp": -1006.4442749023438, "chosen_reward": 2.0983948707580566, "rejected_reward": -1.555047631263733, "time": 1765818577.089038}
{"stage": "dpo", "step": 17400, "epoch": 272, "train_loss": 0.22686633020639418, "policy_chosen_logp": -18.073551177978516, "policy_rejected_logp": -1044.1998291015625, "ref_chosen_logp": -28.198503494262695, "ref_rejected_logp": -1012.47119140625, "chosen_reward": 1.0124952793121338, "rejected_reward": -3.1728639602661133, "time": 1765818579.564704}
{"stage": "dpo", "step": 17450, "epoch": 273, "train_loss": 0.19100308358669282, "policy_chosen_logp": -16.142902374267578, "policy_rejected_logp": -1147.9503173828125, "ref_chosen_logp": -31.55208396911621, "ref_rejected_logp": -1139.7548828125, "chosen_reward": 1.540918231010437, "rejected_reward": -0.8195434212684631, "time": 1765818582.0544589}
{"stage": "dpo", "step": 17500, "epoch": 274, "train_loss": 0.12697947829961775, "policy_chosen_logp": -17.2053165435791, "policy_rejected_logp": -1047.962158203125, "ref_chosen_logp": -24.93311309814453, "ref_rejected_logp": -1026.096923828125, "chosen_reward": 0.7727795243263245, "rejected_reward": -2.1865265369415283, "time": 1765818584.5038126}
{"stage": "dpo", "step": 17550, "epoch": 275, "train_loss": 0.06198449283838272, "policy_chosen_logp": -27.31964874267578, "policy_rejected_logp": -966.9237060546875, "ref_chosen_logp": -46.87605285644531, "ref_rejected_logp": -960.8536987304688, "chosen_reward": 1.9556405544281006, "rejected_reward": -0.6069992184638977, "time": 1765818586.8966062}
{"stage": "dpo", "step": 17600, "epoch": 275, "train_loss": 0.22214921623468398, "policy_chosen_logp": -21.144317626953125, "policy_rejected_logp": -1130.730224609375, "ref_chosen_logp": -41.179439544677734, "ref_rejected_logp": -1116.93896484375, "chosen_reward": 2.003512382507324, "rejected_reward": -1.3791320323944092, "time": 1765818589.3668833}
{"stage": "dpo", "step": 17600, "epoch": 275, "val_pref_acc": 1.0, "time": 1765818589.4958038}
{"stage": "dpo", "step": 17650, "epoch": 276, "train_loss": 0.2206855034828186, "policy_chosen_logp": -15.551839828491211, "policy_rejected_logp": -1032.553466796875, "ref_chosen_logp": -27.36288070678711, "ref_rejected_logp": -1007.61328125, "chosen_reward": 1.1811041831970215, "rejected_reward": -2.4940032958984375, "time": 1765818591.840958}
{"stage": "dpo", "step": 17700, "epoch": 277, "train_loss": 0.1639476352930069, "policy_chosen_logp": -16.049652099609375, "policy_rejected_logp": -1071.46044921875, "ref_chosen_logp": -30.832027435302734, "ref_rejected_logp": -1058.4256591796875, "chosen_reward": 1.478237509727478, "rejected_reward": -1.3034744262695312, "time": 1765818594.2920518}
{"stage": "dpo", "step": 17750, "epoch": 278, "train_loss": 0.10055039763450623, "policy_chosen_logp": -23.250625610351562, "policy_rejected_logp": -979.1640625, "ref_chosen_logp": -49.296356201171875, "ref_rejected_logp": -971.7089233398438, "chosen_reward": 2.6045730113983154, "rejected_reward": -0.7455230951309204, "time": 1765818596.7873116}
{"stage": "dpo", "step": 17800, "epoch": 279, "train_loss": 0.036848486065864564, "policy_chosen_logp": -19.446636199951172, "policy_rejected_logp": -1143.2943115234375, "ref_chosen_logp": -40.98773956298828, "ref_rejected_logp": -1117.6318359375, "chosen_reward": 2.1541104316711426, "rejected_reward": -2.566239833831787, "time": 1765818599.289752}
{"stage": "dpo", "step": 17850, "epoch": 279, "train_loss": 0.2234289103746414, "policy_chosen_logp": -16.331863403320312, "policy_rejected_logp": -996.3681640625, "ref_chosen_logp": -36.15972900390625, "ref_rejected_logp": -979.4156494140625, "chosen_reward": 1.9827864170074463, "rejected_reward": -1.695246934890747, "time": 1765818601.7782052}
{"stage": "dpo", "step": 17900, "epoch": 280, "train_loss": 0.1934657058119774, "policy_chosen_logp": -22.555782318115234, "policy_rejected_logp": -1062.598876953125, "ref_chosen_logp": -48.701568603515625, "ref_rejected_logp": -1050.9378662109375, "chosen_reward": 2.61457896232605, "rejected_reward": -1.1660934686660767, "time": 1765818604.3033092}
{"stage": "dpo", "step": 17920, "epoch": 280, "val_pref_acc": 1.0, "time": 1765818605.4307842}
{"stage": "dpo", "step": 17950, "epoch": 281, "train_loss": 0.13489462971687316, "policy_chosen_logp": -19.289907455444336, "policy_rejected_logp": -1034.95947265625, "ref_chosen_logp": -32.493194580078125, "ref_rejected_logp": -1025.293212890625, "chosen_reward": 1.3203284740447998, "rejected_reward": -0.9666275978088379, "time": 1765818606.8151617}
{"stage": "dpo", "step": 18000, "epoch": 282, "train_loss": 0.07363288581371308, "policy_chosen_logp": -11.400934219360352, "policy_rejected_logp": -1062.14013671875, "ref_chosen_logp": -32.3221549987793, "ref_rejected_logp": -1052.7451171875, "chosen_reward": 2.0921220779418945, "rejected_reward": -0.9395034909248352, "time": 1765818609.3462029}
{"stage": "dpo", "step": 18050, "epoch": 283, "train_loss": 0.008895685076713561, "policy_chosen_logp": -13.502178192138672, "policy_rejected_logp": -1169.8865966796875, "ref_chosen_logp": -26.87312889099121, "ref_rejected_logp": -1153.6502685546875, "chosen_reward": 1.337095022201538, "rejected_reward": -1.6236298084259033, "time": 1765818611.8340924}
{"stage": "dpo", "step": 18100, "epoch": 283, "train_loss": 0.22169073313474655, "policy_chosen_logp": -17.02564811706543, "policy_rejected_logp": -1098.9158935546875, "ref_chosen_logp": -36.1140022277832, "ref_rejected_logp": -1088.218017578125, "chosen_reward": 1.9088356494903564, "rejected_reward": -1.0697845220565796, "time": 1765818614.2945054}
{"stage": "dpo", "step": 18150, "epoch": 284, "train_loss": 0.17312539160251617, "policy_chosen_logp": -14.57266616821289, "policy_rejected_logp": -1046.99365234375, "ref_chosen_logp": -31.43509292602539, "ref_rejected_logp": -1034.020263671875, "chosen_reward": 1.686242699623108, "rejected_reward": -1.2973449230194092, "time": 1765818616.7019393}
{"stage": "dpo", "step": 18200, "epoch": 285, "train_loss": 0.10868648022413253, "policy_chosen_logp": -21.494949340820312, "policy_rejected_logp": -1055.4248046875, "ref_chosen_logp": -43.99790954589844, "ref_rejected_logp": -1042.1214599609375, "chosen_reward": 2.250296115875244, "rejected_reward": -1.3303390741348267, "time": 1765818619.1676185}
{"stage": "dpo", "step": 18240, "epoch": 285, "val_pref_acc": 1.0, "time": 1765818621.284828}
{"stage": "dpo", "step": 18250, "epoch": 286, "train_loss": 0.04459470599889755, "policy_chosen_logp": -17.07016372680664, "policy_rejected_logp": -1080.173583984375, "ref_chosen_logp": -25.857860565185547, "ref_rejected_logp": -1066.7213134765625, "chosen_reward": 0.8787697553634644, "rejected_reward": -1.3452270030975342, "time": 1765818621.68163}
{"stage": "dpo", "step": 18300, "epoch": 286, "train_loss": 0.22752406656742097, "policy_chosen_logp": -27.4188232421875, "policy_rejected_logp": -1011.4937133789062, "ref_chosen_logp": -40.75933837890625, "ref_rejected_logp": -986.5113525390625, "chosen_reward": 1.3340513706207275, "rejected_reward": -2.498239040374756, "time": 1765818624.1235085}
{"stage": "dpo", "step": 18350, "epoch": 287, "train_loss": 0.20531027257442475, "policy_chosen_logp": -18.53192901611328, "policy_rejected_logp": -969.7051391601562, "ref_chosen_logp": -42.49116516113281, "ref_rejected_logp": -961.7548828125, "chosen_reward": 2.395923614501953, "rejected_reward": -0.7950271368026733, "time": 1765818626.6103587}
{"stage": "dpo", "step": 18400, "epoch": 288, "train_loss": 0.14344408959150315, "policy_chosen_logp": -21.957630157470703, "policy_rejected_logp": -1068.4898681640625, "ref_chosen_logp": -38.451072692871094, "ref_rejected_logp": -1048.418701171875, "chosen_reward": 1.6493439674377441, "rejected_reward": -2.0071229934692383, "time": 1765818629.0730045}
{"stage": "dpo", "step": 18450, "epoch": 289, "train_loss": 0.08475372642278671, "policy_chosen_logp": -13.132369041442871, "policy_rejected_logp": -1014.777587890625, "ref_chosen_logp": -32.94263458251953, "ref_rejected_logp": -990.9950561523438, "chosen_reward": 1.9810268878936768, "rejected_reward": -2.3782577514648438, "time": 1765818631.452105}
{"stage": "dpo", "step": 18500, "epoch": 290, "train_loss": 0.017975314259529113, "policy_chosen_logp": -17.843990325927734, "policy_rejected_logp": -1139.147705078125, "ref_chosen_logp": -28.98291778564453, "ref_rejected_logp": -1112.97119140625, "chosen_reward": 1.113892674446106, "rejected_reward": -2.617661952972412, "time": 1765818633.9210646}
{"stage": "dpo", "step": 18550, "epoch": 290, "train_loss": 0.23076798945665358, "policy_chosen_logp": -11.942438125610352, "policy_rejected_logp": -1097.357421875, "ref_chosen_logp": -32.604576110839844, "ref_rejected_logp": -1069.8349609375, "chosen_reward": 2.066214084625244, "rejected_reward": -2.7522354125976562, "time": 1765818636.3853369}
{"stage": "dpo", "step": 18560, "epoch": 290, "val_pref_acc": 1.0, "time": 1765818637.0300698}
{"stage": "dpo", "step": 18600, "epoch": 291, "train_loss": 0.17777972012758256, "policy_chosen_logp": -20.247594833374023, "policy_rejected_logp": -1126.1156005859375, "ref_chosen_logp": -34.31067657470703, "ref_rejected_logp": -1107.7724609375, "chosen_reward": 1.4063080549240112, "rejected_reward": -1.834320068359375, "time": 1765818638.9096496}
{"stage": "dpo", "step": 18650, "epoch": 292, "train_loss": 0.11790115624666214, "policy_chosen_logp": -18.44171142578125, "policy_rejected_logp": -1026.0751953125, "ref_chosen_logp": -33.95570755004883, "ref_rejected_logp": -1018.5365600585938, "chosen_reward": 1.5513997077941895, "rejected_reward": -0.7538573741912842, "time": 1765818641.0822256}
{"stage": "dpo", "step": 18700, "epoch": 293, "train_loss": 0.05570403784513474, "policy_chosen_logp": -14.702529907226562, "policy_rejected_logp": -1133.296630859375, "ref_chosen_logp": -28.792606353759766, "ref_rejected_logp": -1110.6435546875, "chosen_reward": 1.4090077877044678, "rejected_reward": -2.2653045654296875, "time": 1765818643.5349648}
{"stage": "dpo", "step": 18750, "epoch": 293, "train_loss": 0.22529797166585921, "policy_chosen_logp": -22.26064682006836, "policy_rejected_logp": -1087.36962890625, "ref_chosen_logp": -40.66227722167969, "ref_rejected_logp": -1077.91259765625, "chosen_reward": 1.840162992477417, "rejected_reward": -0.945690929889679, "time": 1765818646.081275}
{"stage": "dpo", "step": 18800, "epoch": 294, "train_loss": 0.21494667261838912, "policy_chosen_logp": -15.973487854003906, "policy_rejected_logp": -1034.06201171875, "ref_chosen_logp": -36.17585754394531, "ref_rejected_logp": -1022.3425903320312, "chosen_reward": 2.0202369689941406, "rejected_reward": -1.1719329357147217, "time": 1765818648.5305185}
{"stage": "dpo", "step": 18850, "epoch": 295, "train_loss": 0.1501443076133728, "policy_chosen_logp": -20.191267013549805, "policy_rejected_logp": -1015.9844970703125, "ref_chosen_logp": -43.39802932739258, "ref_rejected_logp": -1011.6905517578125, "chosen_reward": 2.320676326751709, "rejected_reward": -0.4293960928916931, "time": 1765818651.0482986}
{"stage": "dpo", "step": 18880, "epoch": 295, "val_pref_acc": 1.0, "time": 1765818652.7198048}
{"stage": "dpo", "step": 18900, "epoch": 296, "train_loss": 0.09192170649766922, "policy_chosen_logp": -16.390398025512695, "policy_rejected_logp": -1160.656982421875, "ref_chosen_logp": -40.372520446777344, "ref_rejected_logp": -1154.476318359375, "chosen_reward": 2.398212432861328, "rejected_reward": -0.6180695295333862, "time": 1765818653.5839624}
{"stage": "dpo", "step": 18950, "epoch": 297, "train_loss": 0.02649253487586975, "policy_chosen_logp": -15.323994636535645, "policy_rejected_logp": -1032.5087890625, "ref_chosen_logp": -29.29928207397461, "ref_rejected_logp": -1018.12158203125, "chosen_reward": 1.397528886795044, "rejected_reward": -1.4387130737304688, "time": 1765818655.8171053}
{"stage": "dpo", "step": 19000, "epoch": 297, "train_loss": 0.22384221851825714, "policy_chosen_logp": -11.722445487976074, "policy_rejected_logp": -1005.2493286132812, "ref_chosen_logp": -21.62523651123047, "ref_rejected_logp": -976.5986938476562, "chosen_reward": 0.9902790188789368, "rejected_reward": -2.865065097808838, "time": 1765818658.220858}
{"stage": "dpo", "step": 19050, "epoch": 298, "train_loss": 0.1822433191537857, "policy_chosen_logp": -25.7852840423584, "policy_rejected_logp": -1012.7080078125, "ref_chosen_logp": -42.62721633911133, "ref_rejected_logp": -994.7883911132812, "chosen_reward": 1.6841931343078613, "rejected_reward": -1.791957139968872, "time": 1765818660.6839752}
{"stage": "dpo", "step": 19100, "epoch": 299, "train_loss": 0.12329934865236282, "policy_chosen_logp": -12.387847900390625, "policy_rejected_logp": -1140.5703125, "ref_chosen_logp": -25.478580474853516, "ref_rejected_logp": -1120.9278564453125, "chosen_reward": 1.3090732097625732, "rejected_reward": -1.964239478111267, "time": 1765818663.1695275}
{"stage": "dpo", "step": 19150, "epoch": 300, "train_loss": 0.06140942990779877, "policy_chosen_logp": -18.469871520996094, "policy_rejected_logp": -1050.4307861328125, "ref_chosen_logp": -38.19563674926758, "ref_rejected_logp": -1039.655029296875, "chosen_reward": 1.97257661819458, "rejected_reward": -1.0775803327560425, "time": 1765818665.6562266}
{"stage": "dpo", "step": 19200, "epoch": 300, "train_loss": 0.21911044001579286, "policy_chosen_logp": -17.40587615966797, "policy_rejected_logp": -1044.2237548828125, "ref_chosen_logp": -42.85187530517578, "ref_rejected_logp": -1039.9083251953125, "chosen_reward": 2.544600009918213, "rejected_reward": -0.4315398931503296, "time": 1765818668.1943905}
{"stage": "dpo", "step": 19200, "epoch": 300, "val_pref_acc": 1.0, "time": 1765818668.340493}
{"stage": "dpo", "step": 19250, "epoch": 301, "train_loss": 0.22199719160795212, "policy_chosen_logp": -14.342689514160156, "policy_rejected_logp": -1127.8564453125, "ref_chosen_logp": -35.475799560546875, "ref_rejected_logp": -1109.638427734375, "chosen_reward": 2.1133108139038086, "rejected_reward": -1.821801781654358, "time": 1765818670.701259}
{"stage": "dpo", "step": 19300, "epoch": 302, "train_loss": 0.15806072294712067, "policy_chosen_logp": -15.200470924377441, "policy_rejected_logp": -1042.383056640625, "ref_chosen_logp": -25.959579467773438, "ref_rejected_logp": -1022.1183471679688, "chosen_reward": 1.0759108066558838, "rejected_reward": -2.026467800140381, "time": 1765818673.17871}
{"stage": "dpo", "step": 19350, "epoch": 303, "train_loss": 0.09943540781736374, "policy_chosen_logp": -13.914883613586426, "policy_rejected_logp": -1071.0018310546875, "ref_chosen_logp": -28.590513229370117, "ref_rejected_logp": -1049.8343505859375, "chosen_reward": 1.4675630331039429, "rejected_reward": -2.116746425628662, "time": 1765818675.6513782}
{"stage": "dpo", "step": 19400, "epoch": 304, "train_loss": 0.03583064556121826, "policy_chosen_logp": -14.394590377807617, "policy_rejected_logp": -1020.5491943359375, "ref_chosen_logp": -28.19884490966797, "ref_rejected_logp": -1002.1880493164062, "chosen_reward": 1.3804253339767456, "rejected_reward": -1.8361191749572754, "time": 1765818678.1368139}
{"stage": "dpo", "step": 19450, "epoch": 304, "train_loss": 0.22267501354217528, "policy_chosen_logp": -23.80008888244629, "policy_rejected_logp": -1009.2832641601562, "ref_chosen_logp": -41.31002426147461, "ref_rejected_logp": -986.59423828125, "chosen_reward": 1.7509936094284058, "rejected_reward": -2.268895149230957, "time": 1765818680.6276016}
{"stage": "dpo", "step": 19500, "epoch": 305, "train_loss": 0.1967188996076584, "policy_chosen_logp": -16.275875091552734, "policy_rejected_logp": -1083.56005859375, "ref_chosen_logp": -33.65637969970703, "ref_rejected_logp": -1072.826171875, "chosen_reward": 1.7380505800247192, "rejected_reward": -1.073390245437622, "time": 1765818683.1080978}
{"stage": "dpo", "step": 19520, "epoch": 305, "val_pref_acc": 1.0, "time": 1765818684.2250333}
{"stage": "dpo", "step": 19550, "epoch": 306, "train_loss": 0.1306496700644493, "policy_chosen_logp": -15.076148986816406, "policy_rejected_logp": -1050.23046875, "ref_chosen_logp": -28.911733627319336, "ref_rejected_logp": -1033.74072265625, "chosen_reward": 1.3835585117340088, "rejected_reward": -1.6489777565002441, "time": 1765818685.5232897}
{"stage": "dpo", "step": 19600, "epoch": 307, "train_loss": 0.07245893746614457, "policy_chosen_logp": -20.94023323059082, "policy_rejected_logp": -962.4822387695312, "ref_chosen_logp": -37.129974365234375, "ref_rejected_logp": -939.0953979492188, "chosen_reward": 1.618973970413208, "rejected_reward": -2.338679552078247, "time": 1765818688.0502417}
{"stage": "dpo", "step": 19650, "epoch": 308, "train_loss": 0.008827820122241974, "policy_chosen_logp": -16.772077560424805, "policy_rejected_logp": -1075.224609375, "ref_chosen_logp": -39.52762222290039, "ref_rejected_logp": -1055.330322265625, "chosen_reward": 2.2755544185638428, "rejected_reward": -1.9894195795059204, "time": 1765818690.5580404}
{"stage": "dpo", "step": 19700, "epoch": 308, "train_loss": 0.22154665112495422, "policy_chosen_logp": -12.96177864074707, "policy_rejected_logp": -988.792724609375, "ref_chosen_logp": -31.532024383544922, "ref_rejected_logp": -964.914306640625, "chosen_reward": 1.8570244312286377, "rejected_reward": -2.387843370437622, "time": 1765818693.072195}
{"stage": "dpo", "step": 19750, "epoch": 309, "train_loss": 0.17269402146339416, "policy_chosen_logp": -17.223278045654297, "policy_rejected_logp": -1025.69677734375, "ref_chosen_logp": -43.66843795776367, "ref_rejected_logp": -1014.0618896484375, "chosen_reward": 2.6445162296295166, "rejected_reward": -1.1634873151779175, "time": 1765818695.5518563}
{"stage": "dpo", "step": 19800, "epoch": 310, "train_loss": 0.1056370496749878, "policy_chosen_logp": -6.444675445556641, "policy_rejected_logp": -945.931396484375, "ref_chosen_logp": -27.52760887145996, "ref_rejected_logp": -946.2323608398438, "chosen_reward": 2.1082935333251953, "rejected_reward": 0.03009796142578125, "time": 1765818698.062882}
{"stage": "dpo", "step": 19840, "epoch": 310, "val_pref_acc": 1.0, "time": 1765818700.1724255}
{"stage": "dpo", "step": 19850, "epoch": 311, "train_loss": 0.04405287116765976, "policy_chosen_logp": -17.24861717224121, "policy_rejected_logp": -1130.018310546875, "ref_chosen_logp": -30.12809181213379, "ref_rejected_logp": -1114.577392578125, "chosen_reward": 1.287947416305542, "rejected_reward": -1.5441009998321533, "time": 1765818700.5751882}
{"stage": "dpo", "step": 19900, "epoch": 311, "train_loss": 0.2197398093342781, "policy_chosen_logp": -16.03562355041504, "policy_rejected_logp": -1039.871826171875, "ref_chosen_logp": -32.88484573364258, "ref_rejected_logp": -1022.2931518554688, "chosen_reward": 1.684922218322754, "rejected_reward": -1.757869005203247, "time": 1765818703.0967388}
{"stage": "dpo", "step": 19950, "epoch": 312, "train_loss": 0.20435547709465027, "policy_chosen_logp": -11.929722785949707, "policy_rejected_logp": -1012.1940307617188, "ref_chosen_logp": -25.917097091674805, "ref_rejected_logp": -989.2478637695312, "chosen_reward": 1.3987376689910889, "rejected_reward": -2.294613838195801, "time": 1765818705.4697237}
{"stage": "dpo", "step": 20000, "epoch": 313, "train_loss": 0.14138709962368012, "policy_chosen_logp": -15.385799407958984, "policy_rejected_logp": -1074.2784423828125, "ref_chosen_logp": -32.830772399902344, "ref_rejected_logp": -1052.656982421875, "chosen_reward": 1.744497299194336, "rejected_reward": -2.1621382236480713, "time": 1765818708.0130312}
{"stage": "dpo", "step": 20050, "epoch": 314, "train_loss": 0.07776127070188522, "policy_chosen_logp": -21.617935180664062, "policy_rejected_logp": -979.9409790039062, "ref_chosen_logp": -37.637699127197266, "ref_rejected_logp": -953.1974487304688, "chosen_reward": 1.6019762754440308, "rejected_reward": -2.674355983734131, "time": 1765818710.5037885}
{"stage": "dpo", "step": 20100, "epoch": 315, "train_loss": 0.017111533284187318, "policy_chosen_logp": -15.694589614868164, "policy_rejected_logp": -968.894775390625, "ref_chosen_logp": -42.315460205078125, "ref_rejected_logp": -962.5541381835938, "chosen_reward": 2.6620872020721436, "rejected_reward": -0.6340576410293579, "time": 1765818712.9930632}
{"stage": "dpo", "step": 20150, "epoch": 315, "train_loss": 0.22170205414295197, "policy_chosen_logp": -21.073566436767578, "policy_rejected_logp": -1001.4161376953125, "ref_chosen_logp": -36.49871826171875, "ref_rejected_logp": -980.988525390625, "chosen_reward": 1.5425152778625488, "rejected_reward": -2.0427627563476562, "time": 1765818715.4901419}
{"stage": "dpo", "step": 20160, "epoch": 315, "val_pref_acc": 1.0, "time": 1765818716.1117609}
{"stage": "dpo", "step": 20200, "epoch": 316, "train_loss": 0.17406115144491197, "policy_chosen_logp": -20.636741638183594, "policy_rejected_logp": -1040.31787109375, "ref_chosen_logp": -30.956201553344727, "ref_rejected_logp": -1021.5416259765625, "chosen_reward": 1.0319459438323975, "rejected_reward": -1.8776261806488037, "time": 1765818717.5734103}
{"stage": "dpo", "step": 20250, "epoch": 317, "train_loss": 0.11297176301479339, "policy_chosen_logp": -22.907611846923828, "policy_rejected_logp": -1065.7901611328125, "ref_chosen_logp": -46.078128814697266, "ref_rejected_logp": -1053.4566650390625, "chosen_reward": 2.317051887512207, "rejected_reward": -1.2333557605743408, "time": 1765818719.9027712}
{"stage": "dpo", "step": 20300, "epoch": 318, "train_loss": 0.05508193612098694, "policy_chosen_logp": -18.42744255065918, "policy_rejected_logp": -1094.605224609375, "ref_chosen_logp": -36.3271484375, "ref_rejected_logp": -1078.89453125, "chosen_reward": 1.7899705171585083, "rejected_reward": -1.5710632801055908, "time": 1765818722.3867702}
{"stage": "dpo", "step": 20350, "epoch": 318, "train_loss": 0.21892379045486451, "policy_chosen_logp": -17.595895767211914, "policy_rejected_logp": -1115.849609375, "ref_chosen_logp": -45.09589385986328, "ref_rejected_logp": -1101.29638671875, "chosen_reward": 2.749999761581421, "rejected_reward": -1.455328345298767, "time": 1765818724.8880641}
{"stage": "dpo", "step": 20400, "epoch": 319, "train_loss": 0.21131213337183, "policy_chosen_logp": -17.61577606201172, "policy_rejected_logp": -1034.7838134765625, "ref_chosen_logp": -23.923763275146484, "ref_rejected_logp": -1015.3785400390625, "chosen_reward": 0.6307986974716187, "rejected_reward": -1.9405274391174316, "time": 1765818727.3745177}
{"stage": "dpo", "step": 20450, "epoch": 320, "train_loss": 0.1480568066239357, "policy_chosen_logp": -16.690296173095703, "policy_rejected_logp": -1023.8991088867188, "ref_chosen_logp": -39.24551773071289, "ref_rejected_logp": -1020.6561279296875, "chosen_reward": 2.2555222511291504, "rejected_reward": -0.32430270314216614, "time": 1765818729.8430748}
{"stage": "dpo", "step": 20480, "epoch": 320, "val_pref_acc": 1.0, "time": 1765818731.4609373}
{"stage": "dpo", "step": 20500, "epoch": 321, "train_loss": 0.09030716568231582, "policy_chosen_logp": -22.78374481201172, "policy_rejected_logp": -1024.915771484375, "ref_chosen_logp": -48.522003173828125, "ref_rejected_logp": -1015.724365234375, "chosen_reward": 2.5738260746002197, "rejected_reward": -0.9191421270370483, "time": 1765818732.315856}
{"stage": "dpo", "step": 20550, "epoch": 322, "train_loss": 0.02648445338010788, "policy_chosen_logp": -18.216020584106445, "policy_rejected_logp": -921.5484619140625, "ref_chosen_logp": -37.144344329833984, "ref_rejected_logp": -906.3751220703125, "chosen_reward": 1.8928325176239014, "rejected_reward": -1.517333984375, "time": 1765818734.813755}
{"stage": "dpo", "step": 20600, "epoch": 322, "train_loss": 0.2217124405503273, "policy_chosen_logp": -25.613815307617188, "policy_rejected_logp": -1123.555908203125, "ref_chosen_logp": -37.453407287597656, "ref_rejected_logp": -1104.2691650390625, "chosen_reward": 1.1839592456817627, "rejected_reward": -1.9286727905273438, "time": 1765818737.3560972}
{"stage": "dpo", "step": 20650, "epoch": 323, "train_loss": 0.18494587779045105, "policy_chosen_logp": -26.94426155090332, "policy_rejected_logp": -991.472900390625, "ref_chosen_logp": -45.557464599609375, "ref_rejected_logp": -974.4241943359375, "chosen_reward": 1.8613203763961792, "rejected_reward": -1.704869031906128, "time": 1765818739.8693287}
{"stage": "dpo", "step": 20700, "epoch": 324, "train_loss": 0.12306761682033539, "policy_chosen_logp": -16.2346134185791, "policy_rejected_logp": -1127.943115234375, "ref_chosen_logp": -27.523462295532227, "ref_rejected_logp": -1106.481689453125, "chosen_reward": 1.1288849115371704, "rejected_reward": -2.1461424827575684, "time": 1765818742.3439932}
{"stage": "dpo", "step": 20750, "epoch": 325, "train_loss": 0.06108526200056076, "policy_chosen_logp": -20.960662841796875, "policy_rejected_logp": -1146.084228515625, "ref_chosen_logp": -34.21558380126953, "ref_rejected_logp": -1122.559814453125, "chosen_reward": 1.325492024421692, "rejected_reward": -2.352435350418091, "time": 1765818744.8440218}
{"stage": "dpo", "step": 20800, "epoch": 325, "train_loss": 0.2184106731414795, "policy_chosen_logp": -17.477130889892578, "policy_rejected_logp": -969.36669921875, "ref_chosen_logp": -30.447769165039062, "ref_rejected_logp": -945.56005859375, "chosen_reward": 1.2970637083053589, "rejected_reward": -2.3806686401367188, "time": 1765818747.3246996}
{"stage": "dpo", "step": 20800, "epoch": 325, "val_pref_acc": 1.0, "time": 1765818747.4589694}
{"stage": "dpo", "step": 20850, "epoch": 326, "train_loss": 0.21713333159685136, "policy_chosen_logp": -17.107131958007812, "policy_rejected_logp": -1117.836181640625, "ref_chosen_logp": -43.138397216796875, "ref_rejected_logp": -1113.7177734375, "chosen_reward": 2.6031265258789062, "rejected_reward": -0.41184693574905396, "time": 1765818749.828446}
{"stage": "dpo", "step": 20900, "epoch": 327, "train_loss": 0.15425340682268143, "policy_chosen_logp": -11.261123657226562, "policy_rejected_logp": -1049.84716796875, "ref_chosen_logp": -35.18285369873047, "ref_rejected_logp": -1036.3216552734375, "chosen_reward": 2.3921730518341064, "rejected_reward": -1.3525513410568237, "time": 1765818752.3368323}
{"stage": "dpo", "step": 20950, "epoch": 328, "train_loss": 0.09571597874164581, "policy_chosen_logp": -16.406597137451172, "policy_rejected_logp": -976.818603515625, "ref_chosen_logp": -35.556129455566406, "ref_rejected_logp": -972.8533935546875, "chosen_reward": 1.914953351020813, "rejected_reward": -0.39652252197265625, "time": 1765818754.8443532}
{"stage": "dpo", "step": 21000, "epoch": 329, "train_loss": 0.034968817830085756, "policy_chosen_logp": -22.32223892211914, "policy_rejected_logp": -974.248291015625, "ref_chosen_logp": -35.13488006591797, "ref_rejected_logp": -950.6622924804688, "chosen_reward": 1.281264305114746, "rejected_reward": -2.358598470687866, "time": 1765818757.3259432}
{"stage": "dpo", "step": 21050, "epoch": 329, "train_loss": 0.21898970752954483, "policy_chosen_logp": -7.282510757446289, "policy_rejected_logp": -944.0274658203125, "ref_chosen_logp": -14.003607749938965, "ref_rejected_logp": -915.950927734375, "chosen_reward": 0.6721096634864807, "rejected_reward": -2.807647705078125, "time": 1765818759.8378232}
{"stage": "dpo", "step": 21100, "epoch": 330, "train_loss": 0.19445343285799027, "policy_chosen_logp": -15.287914276123047, "policy_rejected_logp": -1060.2073974609375, "ref_chosen_logp": -28.418874740600586, "ref_rejected_logp": -1040.9404296875, "chosen_reward": 1.313096046447754, "rejected_reward": -1.9266953468322754, "time": 1765818762.3384955}
{"stage": "dpo", "step": 21120, "epoch": 330, "val_pref_acc": 1.0, "time": 1765818763.466683}
{"stage": "dpo", "step": 21150, "epoch": 331, "train_loss": 0.13540657937526704, "policy_chosen_logp": -19.900487899780273, "policy_rejected_logp": -1101.8525390625, "ref_chosen_logp": -39.859527587890625, "ref_rejected_logp": -1082.0771484375, "chosen_reward": 1.9959042072296143, "rejected_reward": -1.9775466918945312, "time": 1765818764.8091397}
{"stage": "dpo", "step": 21200, "epoch": 332, "train_loss": 0.06702909380197525, "policy_chosen_logp": -16.81572723388672, "policy_rejected_logp": -1025.02587890625, "ref_chosen_logp": -31.283233642578125, "ref_rejected_logp": -1007.4049072265625, "chosen_reward": 1.4467504024505615, "rejected_reward": -1.7621002197265625, "time": 1765818767.284814}
{"stage": "dpo", "step": 21250, "epoch": 333, "train_loss": 0.008590400815010071, "policy_chosen_logp": -15.11962604522705, "policy_rejected_logp": -1077.5145263671875, "ref_chosen_logp": -30.543394088745117, "ref_rejected_logp": -1057.46630859375, "chosen_reward": 1.5423767566680908, "rejected_reward": -2.0048325061798096, "time": 1765818769.6738591}
{"stage": "dpo", "step": 21300, "epoch": 333, "train_loss": 0.22005099803209305, "policy_chosen_logp": -24.253440856933594, "policy_rejected_logp": -941.3803100585938, "ref_chosen_logp": -43.318115234375, "ref_rejected_logp": -933.496337890625, "chosen_reward": 1.9064675569534302, "rejected_reward": -0.7883957028388977, "time": 1765818772.180177}
{"stage": "dpo", "step": 21350, "epoch": 334, "train_loss": 0.17163343280553817, "policy_chosen_logp": -16.984214782714844, "policy_rejected_logp": -1001.4910888671875, "ref_chosen_logp": -26.407299041748047, "ref_rejected_logp": -979.6498413085938, "chosen_reward": 0.9423083066940308, "rejected_reward": -2.1841278076171875, "time": 1765818774.6702726}
{"stage": "dpo", "step": 21400, "epoch": 335, "train_loss": 0.10904547572135925, "policy_chosen_logp": -12.830833435058594, "policy_rejected_logp": -1092.290283203125, "ref_chosen_logp": -36.76762008666992, "ref_rejected_logp": -1080.115966796875, "chosen_reward": 2.393678665161133, "rejected_reward": -1.2174392938613892, "time": 1765818777.2273796}
{"stage": "dpo", "step": 21440, "epoch": 335, "val_pref_acc": 1.0, "time": 1765818779.367642}
{"stage": "dpo", "step": 21450, "epoch": 336, "train_loss": 0.04313901901245117, "policy_chosen_logp": -20.317584991455078, "policy_rejected_logp": -1034.9561767578125, "ref_chosen_logp": -39.55325698852539, "ref_rejected_logp": -1026.438720703125, "chosen_reward": 1.923567295074463, "rejected_reward": -0.8517486453056335, "time": 1765818779.7855494}
{"stage": "dpo", "step": 21500, "epoch": 336, "train_loss": 0.22125864386558533, "policy_chosen_logp": -17.489501953125, "policy_rejected_logp": -1019.880859375, "ref_chosen_logp": -29.0009822845459, "ref_rejected_logp": -1000.710205078125, "chosen_reward": 1.1511480808258057, "rejected_reward": -1.9170653820037842, "time": 1765818782.2548535}
{"stage": "dpo", "step": 21550, "epoch": 337, "train_loss": 0.2067822015285492, "policy_chosen_logp": -21.523670196533203, "policy_rejected_logp": -1131.923583984375, "ref_chosen_logp": -29.519060134887695, "ref_rejected_logp": -1104.7122802734375, "chosen_reward": 0.7995389699935913, "rejected_reward": -2.7211334705352783, "time": 1765818784.7492557}
{"stage": "dpo", "step": 21600, "epoch": 338, "train_loss": 0.1404980328679085, "policy_chosen_logp": -20.710119247436523, "policy_rejected_logp": -1142.1739501953125, "ref_chosen_logp": -35.25520324707031, "ref_rejected_logp": -1116.0048828125, "chosen_reward": 1.4545085430145264, "rejected_reward": -2.6169052124023438, "time": 1765818787.3277218}
{"stage": "dpo", "step": 21650, "epoch": 339, "train_loss": 0.07771253377199173, "policy_chosen_logp": -25.30113983154297, "policy_rejected_logp": -968.9998779296875, "ref_chosen_logp": -43.97908020019531, "ref_rejected_logp": -945.2595825195312, "chosen_reward": 1.8677940368652344, "rejected_reward": -2.3740310668945312, "time": 1765818789.8143032}
{"stage": "dpo", "step": 21700, "epoch": 340, "train_loss": 0.017516191601753234, "policy_chosen_logp": -25.48910903930664, "policy_rejected_logp": -1001.7215576171875, "ref_chosen_logp": -41.01183319091797, "ref_rejected_logp": -988.7814331054688, "chosen_reward": 1.552272081375122, "rejected_reward": -1.2940185070037842, "time": 1765818792.332268}
{"stage": "dpo", "step": 21750, "epoch": 340, "train_loss": 0.22079917907714844, "policy_chosen_logp": -18.043930053710938, "policy_rejected_logp": -1075.650146484375, "ref_chosen_logp": -38.623435974121094, "ref_rejected_logp": -1056.619384765625, "chosen_reward": 2.057950496673584, "rejected_reward": -1.9030747413635254, "time": 1765818794.8066776}
{"stage": "dpo", "step": 21760, "epoch": 340, "val_pref_acc": 1.0, "time": 1765818795.4353502}
{"stage": "dpo", "step": 21800, "epoch": 341, "train_loss": 0.17624780923128128, "policy_chosen_logp": -13.761531829833984, "policy_rejected_logp": -1081.3900146484375, "ref_chosen_logp": -35.342079162597656, "ref_rejected_logp": -1066.691650390625, "chosen_reward": 2.1580545902252197, "rejected_reward": -1.469834804534912, "time": 1765818797.2834322}
{"stage": "dpo", "step": 21850, "epoch": 342, "train_loss": 0.11284134536981583, "policy_chosen_logp": -23.123306274414062, "policy_rejected_logp": -1017.9586181640625, "ref_chosen_logp": -42.833518981933594, "ref_rejected_logp": -1003.9414672851562, "chosen_reward": 1.9710209369659424, "rejected_reward": -1.4017151594161987, "time": 1765818799.7518084}
{"stage": "dpo", "step": 21900, "epoch": 343, "train_loss": 0.05268211454153061, "policy_chosen_logp": -17.10629653930664, "policy_rejected_logp": -1011.1804809570312, "ref_chosen_logp": -27.960893630981445, "ref_rejected_logp": -994.1279296875, "chosen_reward": 1.0854597091674805, "rejected_reward": -1.7052505016326904, "time": 1765818802.2046452}
{"stage": "dpo", "step": 21950, "epoch": 343, "train_loss": 0.2186722883582115, "policy_chosen_logp": -19.348669052124023, "policy_rejected_logp": -1035.8837890625, "ref_chosen_logp": -42.583885192871094, "ref_rejected_logp": -1026.8936767578125, "chosen_reward": 2.3235220909118652, "rejected_reward": -0.8990051746368408, "time": 1765818804.680265}
{"stage": "dpo", "step": 22000, "epoch": 344, "train_loss": 0.20816338390111924, "policy_chosen_logp": -18.96580696105957, "policy_rejected_logp": -1103.97216796875, "ref_chosen_logp": -31.3089542388916, "ref_rejected_logp": -1084.3818359375, "chosen_reward": 1.2343146800994873, "rejected_reward": -1.9590318202972412, "time": 1765818807.1558826}
{"stage": "dpo", "step": 22050, "epoch": 345, "train_loss": 0.14855804145336152, "policy_chosen_logp": -12.714125633239746, "policy_rejected_logp": -1089.3505859375, "ref_chosen_logp": -31.939146041870117, "ref_rejected_logp": -1077.821533203125, "chosen_reward": 1.922502040863037, "rejected_reward": -1.1529006958007812, "time": 1765818809.6378088}
{"stage": "dpo", "step": 22080, "epoch": 345, "val_pref_acc": 1.0, "time": 1765818810.978091}
{"stage": "dpo", "step": 22100, "epoch": 346, "train_loss": 0.08703777879476547, "policy_chosen_logp": -15.098133087158203, "policy_rejected_logp": -1138.4326171875, "ref_chosen_logp": -26.073781967163086, "ref_rejected_logp": -1119.612060546875, "chosen_reward": 1.097564935684204, "rejected_reward": -1.8820374011993408, "time": 1765818811.8384311}
{"stage": "dpo", "step": 22150, "epoch": 347, "train_loss": 0.025452131927013396, "policy_chosen_logp": -11.119945526123047, "policy_rejected_logp": -1059.408203125, "ref_chosen_logp": -28.8913631439209, "ref_rejected_logp": -1045.144287109375, "chosen_reward": 1.777141809463501, "rejected_reward": -1.4264007806777954, "time": 1765818814.350419}
{"stage": "dpo", "step": 22200, "epoch": 347, "train_loss": 0.21856424540281297, "policy_chosen_logp": -13.170090675354004, "policy_rejected_logp": -1013.0714721679688, "ref_chosen_logp": -38.113014221191406, "ref_rejected_logp": -1007.87646484375, "chosen_reward": 2.494292736053467, "rejected_reward": -0.5194976329803467, "time": 1765818816.8299797}
{"stage": "dpo", "step": 22250, "epoch": 348, "train_loss": 0.18799359649419783, "policy_chosen_logp": -13.725360870361328, "policy_rejected_logp": -1067.60791015625, "ref_chosen_logp": -40.987762451171875, "ref_rejected_logp": -1068.5062255859375, "chosen_reward": 2.7262401580810547, "rejected_reward": 0.08981931209564209, "time": 1765818819.026976}
{"stage": "dpo", "step": 22300, "epoch": 349, "train_loss": 0.12145349323749542, "policy_chosen_logp": -18.433704376220703, "policy_rejected_logp": -1098.1834716796875, "ref_chosen_logp": -30.242298126220703, "ref_rejected_logp": -1090.570556640625, "chosen_reward": 1.1808595657348633, "rejected_reward": -0.7613006830215454, "time": 1765818821.4845715}
{"stage": "dpo", "step": 22350, "epoch": 350, "train_loss": 0.06303740739822387, "policy_chosen_logp": -13.239781379699707, "policy_rejected_logp": -1067.817138671875, "ref_chosen_logp": -31.93433952331543, "ref_rejected_logp": -1042.930908203125, "chosen_reward": 1.8694558143615723, "rejected_reward": -2.4886200428009033, "time": 1765818823.9458768}
{"stage": "dpo", "step": 22400, "epoch": 350, "train_loss": 0.22147371768951415, "policy_chosen_logp": -20.21810531616211, "policy_rejected_logp": -1040.7020263671875, "ref_chosen_logp": -30.6722469329834, "ref_rejected_logp": -1016.112060546875, "chosen_reward": 1.0454140901565552, "rejected_reward": -2.4589967727661133, "time": 1765818826.4853923}
{"stage": "dpo", "step": 22400, "epoch": 350, "val_pref_acc": 1.0, "time": 1765818826.6153915}
{"stage": "dpo", "step": 22450, "epoch": 351, "train_loss": 0.22124533623456955, "policy_chosen_logp": -15.171050071716309, "policy_rejected_logp": -1002.2880249023438, "ref_chosen_logp": -31.20781135559082, "ref_rejected_logp": -979.970947265625, "chosen_reward": 1.6036760807037354, "rejected_reward": -2.2317047119140625, "time": 1765818828.9895942}
{"stage": "dpo", "step": 22500, "epoch": 352, "train_loss": 0.15555565118789672, "policy_chosen_logp": -14.851900100708008, "policy_rejected_logp": -994.5208129882812, "ref_chosen_logp": -21.165504455566406, "ref_rejected_logp": -973.468994140625, "chosen_reward": 0.6313604116439819, "rejected_reward": -2.1051833629608154, "time": 1765818831.5575633}
{"stage": "dpo", "step": 22550, "epoch": 353, "train_loss": 0.09775642782449723, "policy_chosen_logp": -13.210729598999023, "policy_rejected_logp": -1050.0264892578125, "ref_chosen_logp": -23.168323516845703, "ref_rejected_logp": -1029.3739013671875, "chosen_reward": 0.9957592487335205, "rejected_reward": -2.065263271331787, "time": 1765818834.0153863}
{"stage": "dpo", "step": 22600, "epoch": 354, "train_loss": 0.0338668891787529, "policy_chosen_logp": -16.540802001953125, "policy_rejected_logp": -1125.80224609375, "ref_chosen_logp": -29.442977905273438, "ref_rejected_logp": -1104.750244140625, "chosen_reward": 1.2902177572250366, "rejected_reward": -2.105194091796875, "time": 1765818836.4867723}
{"stage": "dpo", "step": 22650, "epoch": 354, "train_loss": 0.220096632540226, "policy_chosen_logp": -19.84859275817871, "policy_rejected_logp": -1105.091552734375, "ref_chosen_logp": -29.372760772705078, "ref_rejected_logp": -1078.7421875, "chosen_reward": 0.9524167776107788, "rejected_reward": -2.634934902191162, "time": 1765818838.9337854}
{"stage": "dpo", "step": 22700, "epoch": 355, "train_loss": 0.194806307554245, "policy_chosen_logp": -23.20233154296875, "policy_rejected_logp": -1106.7811279296875, "ref_chosen_logp": -36.51403045654297, "ref_rejected_logp": -1089.513916015625, "chosen_reward": 1.331169843673706, "rejected_reward": -1.726715087890625, "time": 1765818841.3873196}
{"stage": "dpo", "step": 22720, "epoch": 355, "val_pref_acc": 1.0, "time": 1765818842.5057616}
{"stage": "dpo", "step": 22750, "epoch": 356, "train_loss": 0.13426026165485383, "policy_chosen_logp": -18.296981811523438, "policy_rejected_logp": -1032.065673828125, "ref_chosen_logp": -43.0830078125, "ref_rejected_logp": -1026.074462890625, "chosen_reward": 2.478602409362793, "rejected_reward": -0.59911048412323, "time": 1765818843.854106}
{"stage": "dpo", "step": 22800, "epoch": 357, "train_loss": 0.06943897634744645, "policy_chosen_logp": -16.323713302612305, "policy_rejected_logp": -1017.9843139648438, "ref_chosen_logp": -27.919933319091797, "ref_rejected_logp": -993.568115234375, "chosen_reward": 1.1596221923828125, "rejected_reward": -2.4416184425354004, "time": 1765818846.3183987}
{"stage": "dpo", "step": 22850, "epoch": 358, "train_loss": 0.00880751222372055, "policy_chosen_logp": -15.047967910766602, "policy_rejected_logp": -1025.4786376953125, "ref_chosen_logp": -38.88256072998047, "ref_rejected_logp": -1017.06103515625, "chosen_reward": 2.3834593296051025, "rejected_reward": -0.8417602181434631, "time": 1765818848.581019}
{"stage": "dpo", "step": 22900, "epoch": 358, "train_loss": 0.2192910733819008, "policy_chosen_logp": -26.11069107055664, "policy_rejected_logp": -1015.0968017578125, "ref_chosen_logp": -36.74209213256836, "ref_rejected_logp": -987.868408203125, "chosen_reward": 1.0631400346755981, "rejected_reward": -2.72283935546875, "time": 1765818850.855993}
{"stage": "dpo", "step": 22950, "epoch": 359, "train_loss": 0.16704140931367875, "policy_chosen_logp": -15.694658279418945, "policy_rejected_logp": -1083.369873046875, "ref_chosen_logp": -36.43408203125, "ref_rejected_logp": -1067.526611328125, "chosen_reward": 2.0739424228668213, "rejected_reward": -1.5843169689178467, "time": 1765818853.3058016}
{"stage": "dpo", "step": 23000, "epoch": 360, "train_loss": 0.10524568617343903, "policy_chosen_logp": -26.357131958007812, "policy_rejected_logp": -1017.1712036132812, "ref_chosen_logp": -46.92811965942383, "ref_rejected_logp": -1003.8331298828125, "chosen_reward": 2.057098865509033, "rejected_reward": -1.3338088989257812, "time": 1765818855.7807043}
{"stage": "dpo", "step": 23040, "epoch": 360, "val_pref_acc": 1.0, "time": 1765818857.8710344}
{"stage": "dpo", "step": 23050, "epoch": 361, "train_loss": 0.04361443549394608, "policy_chosen_logp": -32.378196716308594, "policy_rejected_logp": -1026.92919921875, "ref_chosen_logp": -44.35209655761719, "ref_rejected_logp": -997.126708984375, "chosen_reward": 1.1973905563354492, "rejected_reward": -2.9802536964416504, "time": 1765818858.2627578}
{"stage": "dpo", "step": 23100, "epoch": 361, "train_loss": 0.22363649040460587, "policy_chosen_logp": -22.764802932739258, "policy_rejected_logp": -1020.5768432617188, "ref_chosen_logp": -32.627723693847656, "ref_rejected_logp": -1008.2188720703125, "chosen_reward": 0.9862918853759766, "rejected_reward": -1.2357985973358154, "time": 1765818860.7036483}
{"stage": "dpo", "step": 23150, "epoch": 362, "train_loss": 0.20309176981449129, "policy_chosen_logp": -17.54046058654785, "policy_rejected_logp": -1069.837890625, "ref_chosen_logp": -32.786155700683594, "ref_rejected_logp": -1040.0445556640625, "chosen_reward": 1.5245695114135742, "rejected_reward": -2.9793334007263184, "time": 1765818863.1729865}
{"stage": "dpo", "step": 23200, "epoch": 363, "train_loss": 0.14256672978401183, "policy_chosen_logp": -12.495137214660645, "policy_rejected_logp": -992.8020629882812, "ref_chosen_logp": -24.231422424316406, "ref_rejected_logp": -982.6900634765625, "chosen_reward": 1.173628568649292, "rejected_reward": -1.0112015008926392, "time": 1765818865.664136}
{"stage": "dpo", "step": 23250, "epoch": 364, "train_loss": 0.07868203580379486, "policy_chosen_logp": -17.549787521362305, "policy_rejected_logp": -959.2913208007812, "ref_chosen_logp": -29.253795623779297, "ref_rejected_logp": -942.9276123046875, "chosen_reward": 1.1704007387161255, "rejected_reward": -1.6363708972930908, "time": 1765818868.182026}
{"stage": "dpo", "step": 23300, "epoch": 365, "train_loss": 0.016706581711769104, "policy_chosen_logp": -15.05616283416748, "policy_rejected_logp": -996.1752319335938, "ref_chosen_logp": -29.968994140625, "ref_rejected_logp": -982.0247802734375, "chosen_reward": 1.4912829399108887, "rejected_reward": -1.4150482416152954, "time": 1765818870.6743007}
{"stage": "dpo", "step": 23350, "epoch": 365, "train_loss": 0.2176199558377266, "policy_chosen_logp": -10.03190803527832, "policy_rejected_logp": -1117.2109375, "ref_chosen_logp": -25.4730281829834, "ref_rejected_logp": -1097.844970703125, "chosen_reward": 1.544111967086792, "rejected_reward": -1.9365875720977783, "time": 1765818873.219297}
{"stage": "dpo", "step": 23360, "epoch": 365, "val_pref_acc": 1.0, "time": 1765818873.8826778}
{"stage": "dpo", "step": 23400, "epoch": 366, "train_loss": 0.17553495556116105, "policy_chosen_logp": -18.030221939086914, "policy_rejected_logp": -1042.8734130859375, "ref_chosen_logp": -37.14339065551758, "ref_rejected_logp": -1030.0283203125, "chosen_reward": 1.9113168716430664, "rejected_reward": -1.2845138311386108, "time": 1765818875.7668881}
{"stage": "dpo", "step": 23450, "epoch": 367, "train_loss": 0.11172350585460662, "policy_chosen_logp": -16.213550567626953, "policy_rejected_logp": -1077.4677734375, "ref_chosen_logp": -42.092681884765625, "ref_rejected_logp": -1069.3511962890625, "chosen_reward": 2.5879130363464355, "rejected_reward": -0.8116653561592102, "time": 1765818878.26658}
{"stage": "dpo", "step": 23500, "epoch": 368, "train_loss": 0.05121664375066757, "policy_chosen_logp": -21.05421257019043, "policy_rejected_logp": -980.6048583984375, "ref_chosen_logp": -31.455127716064453, "ref_rejected_logp": -965.5870361328125, "chosen_reward": 1.0400915145874023, "rejected_reward": -1.5017791986465454, "time": 1765818880.733345}
{"stage": "dpo", "step": 23550, "epoch": 368, "train_loss": 0.21692845910787584, "policy_chosen_logp": -18.135282516479492, "policy_rejected_logp": -1016.7999877929688, "ref_chosen_logp": -38.0721435546875, "ref_rejected_logp": -1001.3785400390625, "chosen_reward": 1.9936861991882324, "rejected_reward": -1.5421478748321533, "time": 1765818883.202452}
{"stage": "dpo", "step": 23600, "epoch": 369, "train_loss": 0.20634220987558366, "policy_chosen_logp": -12.474748611450195, "policy_rejected_logp": -1025.608642578125, "ref_chosen_logp": -25.96542739868164, "ref_rejected_logp": -1016.9912109375, "chosen_reward": 1.3490676879882812, "rejected_reward": -0.8617386221885681, "time": 1765818885.6668499}
{"stage": "dpo", "step": 23650, "epoch": 370, "train_loss": 0.1522502675652504, "policy_chosen_logp": -19.120803833007812, "policy_rejected_logp": -1107.657958984375, "ref_chosen_logp": -29.276962280273438, "ref_rejected_logp": -1078.326904296875, "chosen_reward": 1.0156158208847046, "rejected_reward": -2.9330978393554688, "time": 1765818888.1955056}
{"stage": "dpo", "step": 23680, "epoch": 370, "val_pref_acc": 1.0, "time": 1765818889.8067007}
{"stage": "dpo", "step": 23700, "epoch": 371, "train_loss": 0.08571472376585007, "policy_chosen_logp": -17.586687088012695, "policy_rejected_logp": -1000.9929809570312, "ref_chosen_logp": -37.67081832885742, "ref_rejected_logp": -992.2957763671875, "chosen_reward": 2.008413314819336, "rejected_reward": -0.8697112798690796, "time": 1765818890.6792488}
{"stage": "dpo", "step": 23750, "epoch": 372, "train_loss": 0.025172718167304993, "policy_chosen_logp": -15.588491439819336, "policy_rejected_logp": -1105.593994140625, "ref_chosen_logp": -36.13758850097656, "ref_rejected_logp": -1091.8785400390625, "chosen_reward": 2.0549097061157227, "rejected_reward": -1.3715484142303467, "time": 1765818893.141418}
{"stage": "dpo", "step": 23800, "epoch": 372, "train_loss": 0.21780584275722503, "policy_chosen_logp": -19.433364868164062, "policy_rejected_logp": -1045.426025390625, "ref_chosen_logp": -40.07756805419922, "ref_rejected_logp": -1035.196044921875, "chosen_reward": 2.064420223236084, "rejected_reward": -1.0229889154434204, "time": 1765818895.6117995}
{"stage": "dpo", "step": 23850, "epoch": 373, "train_loss": 0.18269337505102157, "policy_chosen_logp": -19.18883514404297, "policy_rejected_logp": -1070.1353759765625, "ref_chosen_logp": -36.737831115722656, "ref_rejected_logp": -1059.939453125, "chosen_reward": 1.7548997402191162, "rejected_reward": -1.0196014642715454, "time": 1765818898.0920954}
{"stage": "dpo", "step": 23900, "epoch": 374, "train_loss": 0.12252164542675019, "policy_chosen_logp": -13.699421882629395, "policy_rejected_logp": -1157.416259765625, "ref_chosen_logp": -34.411712646484375, "ref_rejected_logp": -1150.878173828125, "chosen_reward": 2.0712289810180664, "rejected_reward": -0.6538116931915283, "time": 1765818900.5782447}
{"stage": "dpo", "step": 23950, "epoch": 375, "train_loss": 0.06129990637302399, "policy_chosen_logp": -17.46010971069336, "policy_rejected_logp": -1148.7459716796875, "ref_chosen_logp": -35.101951599121094, "ref_rejected_logp": -1135.51318359375, "chosen_reward": 1.7641842365264893, "rejected_reward": -1.3232696056365967, "time": 1765818903.0804398}
{"stage": "dpo", "step": 24000, "epoch": 375, "train_loss": 0.21762622475624085, "policy_chosen_logp": -17.399208068847656, "policy_rejected_logp": -978.6665649414062, "ref_chosen_logp": -33.134395599365234, "ref_rejected_logp": -967.1343383789062, "chosen_reward": 1.5735187530517578, "rejected_reward": -1.153222680091858, "time": 1765818905.5601735}
{"stage": "dpo", "step": 24000, "epoch": 375, "val_pref_acc": 1.0, "time": 1765818905.6902695}
{"stage": "dpo", "step": 24050, "epoch": 376, "train_loss": 0.21871817260980606, "policy_chosen_logp": -15.534610748291016, "policy_rejected_logp": -1099.7978515625, "ref_chosen_logp": -27.938013076782227, "ref_rejected_logp": -1075.888916015625, "chosen_reward": 1.2403401136398315, "rejected_reward": -2.390896797180176, "time": 1765818908.048352}
{"stage": "dpo", "step": 24100, "epoch": 377, "train_loss": 0.15435868382453918, "policy_chosen_logp": -15.171517372131348, "policy_rejected_logp": -1092.98583984375, "ref_chosen_logp": -28.05124282836914, "ref_rejected_logp": -1072.797119140625, "chosen_reward": 1.2879725694656372, "rejected_reward": -2.0188629627227783, "time": 1765818910.5599756}
{"stage": "dpo", "step": 24150, "epoch": 378, "train_loss": 0.09746237099170685, "policy_chosen_logp": -26.918569564819336, "policy_rejected_logp": -918.7103271484375, "ref_chosen_logp": -37.08935546875, "ref_rejected_logp": -895.45556640625, "chosen_reward": 1.0170786380767822, "rejected_reward": -2.3254716396331787, "time": 1765818913.107584}
{"stage": "dpo", "step": 24200, "epoch": 379, "train_loss": 0.034540577828884124, "policy_chosen_logp": -21.716079711914062, "policy_rejected_logp": -1056.3739013671875, "ref_chosen_logp": -33.35688018798828, "ref_rejected_logp": -1034.93798828125, "chosen_reward": 1.1640801429748535, "rejected_reward": -2.143589973449707, "time": 1765818915.5982766}
{"stage": "dpo", "step": 24250, "epoch": 379, "train_loss": 0.21619614958763123, "policy_chosen_logp": -22.028865814208984, "policy_rejected_logp": -1020.880859375, "ref_chosen_logp": -31.918981552124023, "ref_rejected_logp": -1000.18701171875, "chosen_reward": 0.9890115261077881, "rejected_reward": -2.0693817138671875, "time": 1765818918.0420597}
{"stage": "dpo", "step": 24300, "epoch": 380, "train_loss": 0.18929860442876817, "policy_chosen_logp": -19.240449905395508, "policy_rejected_logp": -1006.77685546875, "ref_chosen_logp": -36.637916564941406, "ref_rejected_logp": -993.1271362304688, "chosen_reward": 1.7397470474243164, "rejected_reward": -1.364976406097412, "time": 1765818920.4848075}
{"stage": "dpo", "step": 24320, "epoch": 380, "val_pref_acc": 1.0, "time": 1765818921.5953476}
{"stage": "dpo", "step": 24350, "epoch": 381, "train_loss": 0.12938842296600342, "policy_chosen_logp": -16.138381958007812, "policy_rejected_logp": -1021.8610229492188, "ref_chosen_logp": -28.798770904541016, "ref_rejected_logp": -999.8218994140625, "chosen_reward": 1.2660388946533203, "rejected_reward": -2.203915596008301, "time": 1765818922.9349227}
{"stage": "dpo", "step": 24400, "epoch": 382, "train_loss": 0.06822072237730026, "policy_chosen_logp": -18.6107177734375, "policy_rejected_logp": -1051.705078125, "ref_chosen_logp": -32.283775329589844, "ref_rejected_logp": -1034.9228515625, "chosen_reward": 1.3673055171966553, "rejected_reward": -1.6782164573669434, "time": 1765818924.9668882}
{"stage": "dpo", "step": 24450, "epoch": 383, "train_loss": 0.009086798429489135, "policy_chosen_logp": -13.303815841674805, "policy_rejected_logp": -1003.8980712890625, "ref_chosen_logp": -40.83668518066406, "ref_rejected_logp": -991.1373901367188, "chosen_reward": 2.753286838531494, "rejected_reward": -1.27606201171875, "time": 1765818927.393601}
{"stage": "dpo", "step": 24500, "epoch": 383, "train_loss": 0.21694548845291137, "policy_chosen_logp": -20.027896881103516, "policy_rejected_logp": -1096.4051513671875, "ref_chosen_logp": -39.60862350463867, "ref_rejected_logp": -1089.796142578125, "chosen_reward": 1.958072543144226, "rejected_reward": -0.6609084606170654, "time": 1765818929.7522156}
{"stage": "dpo", "step": 24550, "epoch": 384, "train_loss": 0.16270114243030548, "policy_chosen_logp": -23.50946044921875, "policy_rejected_logp": -994.311767578125, "ref_chosen_logp": -46.57412338256836, "ref_rejected_logp": -985.5259399414062, "chosen_reward": 2.3064661026000977, "rejected_reward": -0.878582775592804, "time": 1765818932.1129048}
{"stage": "dpo", "step": 24600, "epoch": 385, "train_loss": 0.10552435427904129, "policy_chosen_logp": -19.29309844970703, "policy_rejected_logp": -1136.609375, "ref_chosen_logp": -36.881412506103516, "ref_rejected_logp": -1124.1182861328125, "chosen_reward": 1.758831262588501, "rejected_reward": -1.2491180896759033, "time": 1765818934.2034059}
{"stage": "dpo", "step": 24640, "epoch": 385, "val_pref_acc": 1.0, "time": 1765818936.2912161}
{"stage": "dpo", "step": 24650, "epoch": 386, "train_loss": 0.043188502490520475, "policy_chosen_logp": -13.15968132019043, "policy_rejected_logp": -1073.6806640625, "ref_chosen_logp": -28.201078414916992, "ref_rejected_logp": -1053.998291015625, "chosen_reward": 1.50413978099823, "rejected_reward": -1.9682313203811646, "time": 1765818936.679647}
{"stage": "dpo", "step": 24700, "epoch": 386, "train_loss": 0.2136917930841446, "policy_chosen_logp": -14.271636962890625, "policy_rejected_logp": -1022.4786376953125, "ref_chosen_logp": -34.97454071044922, "ref_rejected_logp": -1005.2595825195312, "chosen_reward": 2.0702905654907227, "rejected_reward": -1.72190260887146, "time": 1765818939.1236446}
{"stage": "dpo", "step": 24750, "epoch": 387, "train_loss": 0.19849192917346956, "policy_chosen_logp": -30.188501358032227, "policy_rejected_logp": -916.0783081054688, "ref_chosen_logp": -43.82244110107422, "ref_rejected_logp": -894.3927001953125, "chosen_reward": 1.3633939027786255, "rejected_reward": -2.168562173843384, "time": 1765818941.5796053}
{"stage": "dpo", "step": 24800, "epoch": 388, "train_loss": 0.13821967005729674, "policy_chosen_logp": -15.90342903137207, "policy_rejected_logp": -1041.0836181640625, "ref_chosen_logp": -34.2232551574707, "ref_rejected_logp": -1026.756591796875, "chosen_reward": 1.8319823741912842, "rejected_reward": -1.4327073097229004, "time": 1765818944.0519283}
{"stage": "dpo", "step": 24850, "epoch": 389, "train_loss": 0.07840089082717895, "policy_chosen_logp": -17.81967544555664, "policy_rejected_logp": -990.193603515625, "ref_chosen_logp": -41.01679229736328, "ref_rejected_logp": -982.1362915039062, "chosen_reward": 2.319711685180664, "rejected_reward": -0.8057342767715454, "time": 1765818946.5244586}
{"stage": "dpo", "step": 24900, "epoch": 390, "train_loss": 0.016684639751911163, "policy_chosen_logp": -17.24331283569336, "policy_rejected_logp": -1057.253662109375, "ref_chosen_logp": -33.856117248535156, "ref_rejected_logp": -1043.92626953125, "chosen_reward": 1.6612802743911743, "rejected_reward": -1.3327453136444092, "time": 1765818948.6279578}
{"stage": "dpo", "step": 24950, "epoch": 390, "train_loss": 0.2127199524641037, "policy_chosen_logp": -22.85629653930664, "policy_rejected_logp": -1033.9837646484375, "ref_chosen_logp": -35.571746826171875, "ref_rejected_logp": -1016.2074584960938, "chosen_reward": 1.2715449333190918, "rejected_reward": -1.777632236480713, "time": 1765818951.1412172}
{"stage": "dpo", "step": 24960, "epoch": 390, "val_pref_acc": 1.0, "time": 1765818951.7689972}
{"stage": "dpo", "step": 25000, "epoch": 391, "train_loss": 0.17424452513456345, "policy_chosen_logp": -32.08074951171875, "policy_rejected_logp": -1081.5989990234375, "ref_chosen_logp": -49.06806945800781, "ref_rejected_logp": -1074.540771484375, "chosen_reward": 1.6987318992614746, "rejected_reward": -0.7058120965957642, "time": 1765818953.347918}
{"stage": "dpo", "step": 25050, "epoch": 392, "train_loss": 0.11453314632177353, "policy_chosen_logp": -13.018632888793945, "policy_rejected_logp": -946.0576171875, "ref_chosen_logp": -32.60791778564453, "ref_rejected_logp": -929.1611938476562, "chosen_reward": 1.9589284658432007, "rejected_reward": -1.689640760421753, "time": 1765818955.815471}
{"stage": "dpo", "step": 25100, "epoch": 393, "train_loss": 0.051899473965168, "policy_chosen_logp": -30.617841720581055, "policy_rejected_logp": -978.234619140625, "ref_chosen_logp": -44.75611877441406, "ref_rejected_logp": -961.3146362304688, "chosen_reward": 1.413827657699585, "rejected_reward": -1.6919951438903809, "time": 1765818958.2592623}
{"stage": "dpo", "step": 25150, "epoch": 393, "train_loss": 0.21416155189275743, "policy_chosen_logp": -22.32583236694336, "policy_rejected_logp": -1045.624267578125, "ref_chosen_logp": -34.3702507019043, "ref_rejected_logp": -1021.8697509765625, "chosen_reward": 1.2044416666030884, "rejected_reward": -2.3754379749298096, "time": 1765818960.7727475}
{"stage": "dpo", "step": 25200, "epoch": 394, "train_loss": 0.20665131747722626, "policy_chosen_logp": -21.45550537109375, "policy_rejected_logp": -1097.5712890625, "ref_chosen_logp": -40.05304718017578, "ref_rejected_logp": -1076.5966796875, "chosen_reward": 1.8597540855407715, "rejected_reward": -2.097460985183716, "time": 1765818963.2510104}
{"stage": "dpo", "step": 25250, "epoch": 395, "train_loss": 0.15005643367767335, "policy_chosen_logp": -19.20418930053711, "policy_rejected_logp": -1079.558349609375, "ref_chosen_logp": -29.729333877563477, "ref_rejected_logp": -1059.98974609375, "chosen_reward": 1.0525145530700684, "rejected_reward": -1.9568513631820679, "time": 1765818965.7298038}
{"stage": "dpo", "step": 25280, "epoch": 395, "val_pref_acc": 1.0, "time": 1765818967.3279321}
{"stage": "dpo", "step": 25300, "epoch": 396, "train_loss": 0.08575903534889222, "policy_chosen_logp": -8.841222763061523, "policy_rejected_logp": -1123.290771484375, "ref_chosen_logp": -24.784278869628906, "ref_rejected_logp": -1107.8798828125, "chosen_reward": 1.5943055152893066, "rejected_reward": -1.5410797595977783, "time": 1765818968.1948812}
{"stage": "dpo", "step": 25350, "epoch": 397, "train_loss": 0.025650660693645477, "policy_chosen_logp": -12.714946746826172, "policy_rejected_logp": -1061.98583984375, "ref_chosen_logp": -37.158599853515625, "ref_rejected_logp": -1063.2508544921875, "chosen_reward": 2.4443657398223877, "rejected_reward": 0.1265014410018921, "time": 1765818970.4752953}
{"stage": "dpo", "step": 25400, "epoch": 397, "train_loss": 0.2141835382580757, "policy_chosen_logp": -18.464038848876953, "policy_rejected_logp": -949.72119140625, "ref_chosen_logp": -37.067359924316406, "ref_rejected_logp": -934.3228759765625, "chosen_reward": 1.8603318929672241, "rejected_reward": -1.539829969406128, "time": 1765818972.9091191}
{"stage": "dpo", "step": 25450, "epoch": 398, "train_loss": 0.18304915726184845, "policy_chosen_logp": -23.0767822265625, "policy_rejected_logp": -1077.8118896484375, "ref_chosen_logp": -48.69867706298828, "ref_rejected_logp": -1064.333740234375, "chosen_reward": 2.5621891021728516, "rejected_reward": -1.3478102684020996, "time": 1765818975.3949873}
{"stage": "dpo", "step": 25500, "epoch": 399, "train_loss": 0.11917953908443452, "policy_chosen_logp": -12.521829605102539, "policy_rejected_logp": -1066.7474365234375, "ref_chosen_logp": -23.042476654052734, "ref_rejected_logp": -1048.45654296875, "chosen_reward": 1.0520647764205933, "rejected_reward": -1.8290863037109375, "time": 1765818977.8989282}
{"stage": "dpo", "step": 25550, "epoch": 400, "train_loss": 0.06068871259689331, "policy_chosen_logp": -19.1895751953125, "policy_rejected_logp": -1174.53857421875, "ref_chosen_logp": -31.196533203125, "ref_rejected_logp": -1148.771728515625, "chosen_reward": 1.2006958723068237, "rejected_reward": -2.576687812805176, "time": 1765818980.320715}
{"stage": "dpo", "step": 25600, "epoch": 400, "train_loss": 0.21835592031478882, "policy_chosen_logp": -25.26642608642578, "policy_rejected_logp": -983.480712890625, "ref_chosen_logp": -36.916046142578125, "ref_rejected_logp": -960.234130859375, "chosen_reward": 1.164961814880371, "rejected_reward": -2.324658155441284, "time": 1765818982.4628606}
{"stage": "dpo", "step": 25600, "epoch": 400, "val_pref_acc": 1.0, "time": 1765818982.5936065}
{"stage": "dpo", "step": 25650, "epoch": 401, "train_loss": 0.21924013137817383, "policy_chosen_logp": -13.275633811950684, "policy_rejected_logp": -1090.02490234375, "ref_chosen_logp": -24.382442474365234, "ref_rejected_logp": -1062.74755859375, "chosen_reward": 1.1106810569763184, "rejected_reward": -2.7277374267578125, "time": 1765818984.9556386}
{"stage": "dpo", "step": 25700, "epoch": 402, "train_loss": 0.15658974796533584, "policy_chosen_logp": -20.077342987060547, "policy_rejected_logp": -1089.357666015625, "ref_chosen_logp": -38.46235656738281, "ref_rejected_logp": -1074.89208984375, "chosen_reward": 1.8385009765625, "rejected_reward": -1.446557641029358, "time": 1765818987.1144211}
{"stage": "dpo", "step": 25750, "epoch": 403, "train_loss": 0.0955401036143303, "policy_chosen_logp": -17.16643524169922, "policy_rejected_logp": -1002.3114013671875, "ref_chosen_logp": -29.640300750732422, "ref_rejected_logp": -980.8826904296875, "chosen_reward": 1.2473864555358887, "rejected_reward": -2.142869710922241, "time": 1765818989.5762494}
{"stage": "dpo", "step": 25800, "epoch": 404, "train_loss": 0.03502147316932678, "policy_chosen_logp": -9.764659881591797, "policy_rejected_logp": -1140.04443359375, "ref_chosen_logp": -31.16143798828125, "ref_rejected_logp": -1117.33056640625, "chosen_reward": 2.1396777629852295, "rejected_reward": -2.2713990211486816, "time": 1765818992.076135}
{"stage": "dpo", "step": 25850, "epoch": 404, "train_loss": 0.2140781620144844, "policy_chosen_logp": -16.0478515625, "policy_rejected_logp": -1000.5482788085938, "ref_chosen_logp": -29.903636932373047, "ref_rejected_logp": -977.7632446289062, "chosen_reward": 1.3855783939361572, "rejected_reward": -2.2785048484802246, "time": 1765818994.5511088}
{"stage": "dpo", "step": 25900, "epoch": 405, "train_loss": 0.18811832576990128, "policy_chosen_logp": -23.96019744873047, "policy_rejected_logp": -1060.739990234375, "ref_chosen_logp": -40.81058120727539, "ref_rejected_logp": -1042.981689453125, "chosen_reward": 1.6850385665893555, "rejected_reward": -1.775822401046753, "time": 1765818997.0267804}
{"stage": "dpo", "step": 25920, "epoch": 405, "val_pref_acc": 1.0, "time": 1765818998.1629717}
{"stage": "dpo", "step": 25950, "epoch": 406, "train_loss": 0.12766122817993164, "policy_chosen_logp": -19.227645874023438, "policy_rejected_logp": -1047.74072265625, "ref_chosen_logp": -35.01595687866211, "ref_rejected_logp": -1025.19091796875, "chosen_reward": 1.5788309574127197, "rejected_reward": -2.2549819946289062, "time": 1765818999.539402}
{"stage": "dpo", "step": 26000, "epoch": 407, "train_loss": 0.0680501902103424, "policy_chosen_logp": -16.049753189086914, "policy_rejected_logp": -1033.551513671875, "ref_chosen_logp": -26.5943603515625, "ref_rejected_logp": -1014.0125732421875, "chosen_reward": 1.0544607639312744, "rejected_reward": -1.9538896083831787, "time": 1765819002.0772707}
{"stage": "dpo", "step": 26050, "epoch": 408, "train_loss": 0.00871849000453949, "policy_chosen_logp": -19.102014541625977, "policy_rejected_logp": -1110.0439453125, "ref_chosen_logp": -42.846214294433594, "ref_rejected_logp": -1103.81396484375, "chosen_reward": 2.374420166015625, "rejected_reward": -0.6230102181434631, "time": 1765819004.6307473}
{"stage": "dpo", "step": 26100, "epoch": 408, "train_loss": 0.21375945806503296, "policy_chosen_logp": -18.316753387451172, "policy_rejected_logp": -1085.0616455078125, "ref_chosen_logp": -28.429645538330078, "ref_rejected_logp": -1057.738525390625, "chosen_reward": 1.0112888813018799, "rejected_reward": -2.732318162918091, "time": 1765819007.2800374}
{"stage": "dpo", "step": 26150, "epoch": 409, "train_loss": 0.16919450998306274, "policy_chosen_logp": -11.038585662841797, "policy_rejected_logp": -1030.801025390625, "ref_chosen_logp": -29.36577796936035, "ref_rejected_logp": -1021.2515869140625, "chosen_reward": 1.832719326019287, "rejected_reward": -0.9549347162246704, "time": 1765819009.8840861}
{"stage": "dpo", "step": 26200, "epoch": 410, "train_loss": 0.10316255569458008, "policy_chosen_logp": -15.661968231201172, "policy_rejected_logp": -1099.20556640625, "ref_chosen_logp": -39.428375244140625, "ref_rejected_logp": -1086.2625732421875, "chosen_reward": 2.3766403198242188, "rejected_reward": -1.2942962646484375, "time": 1765819012.4631863}
{"stage": "dpo", "step": 26240, "epoch": 410, "val_pref_acc": 1.0, "time": 1765819014.6077366}
{"stage": "dpo", "step": 26250, "epoch": 411, "train_loss": 0.04419570654630661, "policy_chosen_logp": -15.393345832824707, "policy_rejected_logp": -1012.1151733398438, "ref_chosen_logp": -22.400882720947266, "ref_rejected_logp": -989.27490234375, "chosen_reward": 0.7007535696029663, "rejected_reward": -2.2840301990509033, "time": 1765819015.013521}
{"stage": "dpo", "step": 26300, "epoch": 411, "train_loss": 0.21531707614660264, "policy_chosen_logp": -4.621424198150635, "policy_rejected_logp": -1071.790283203125, "ref_chosen_logp": -21.850299835205078, "ref_rejected_logp": -1059.750244140625, "chosen_reward": 1.722887635231018, "rejected_reward": -1.2040085792541504, "time": 1765819017.4732947}
{"stage": "dpo", "step": 26350, "epoch": 412, "train_loss": 0.19696201562881469, "policy_chosen_logp": -14.345266342163086, "policy_rejected_logp": -984.1298828125, "ref_chosen_logp": -33.18124771118164, "ref_rejected_logp": -964.5364379882812, "chosen_reward": 1.88359797000885, "rejected_reward": -1.95933997631073, "time": 1765819019.9366064}
{"stage": "dpo", "step": 26400, "epoch": 413, "train_loss": 0.1362579745054245, "policy_chosen_logp": -16.97577667236328, "policy_rejected_logp": -1073.48193359375, "ref_chosen_logp": -39.596736907958984, "ref_rejected_logp": -1061.8515625, "chosen_reward": 2.262096405029297, "rejected_reward": -1.1630401611328125, "time": 1765819022.407711}
{"stage": "dpo", "step": 26450, "epoch": 414, "train_loss": 0.07914381593465805, "policy_chosen_logp": -17.793148040771484, "policy_rejected_logp": -1001.6204833984375, "ref_chosen_logp": -33.50376892089844, "ref_rejected_logp": -991.7415771484375, "chosen_reward": 1.5710620880126953, "rejected_reward": -0.987892210483551, "time": 1765819024.7837713}
{"stage": "dpo", "step": 26500, "epoch": 415, "train_loss": 0.017553108930587768, "policy_chosen_logp": -17.559921264648438, "policy_rejected_logp": -1009.5751953125, "ref_chosen_logp": -40.05276107788086, "ref_rejected_logp": -993.2359008789062, "chosen_reward": 2.249283790588379, "rejected_reward": -1.6339311599731445, "time": 1765819026.7945023}
{"stage": "dpo", "step": 26550, "epoch": 415, "train_loss": 0.21437296897172928, "policy_chosen_logp": -17.256723403930664, "policy_rejected_logp": -1037.31201171875, "ref_chosen_logp": -27.350370407104492, "ref_rejected_logp": -1016.33251953125, "chosen_reward": 1.0093646049499512, "rejected_reward": -2.097952127456665, "time": 1765819029.2652147}
{"stage": "dpo", "step": 26560, "epoch": 415, "val_pref_acc": 1.0, "time": 1765819029.8889163}
{"stage": "dpo", "step": 26600, "epoch": 416, "train_loss": 0.17489805102348327, "policy_chosen_logp": -17.75156021118164, "policy_rejected_logp": -1037.468017578125, "ref_chosen_logp": -33.308837890625, "ref_rejected_logp": -1021.53759765625, "chosen_reward": 1.5557277202606201, "rejected_reward": -1.5930373668670654, "time": 1765819031.7198403}
{"stage": "dpo", "step": 26650, "epoch": 417, "train_loss": 0.11130749702453613, "policy_chosen_logp": -15.25857925415039, "policy_rejected_logp": -944.9090576171875, "ref_chosen_logp": -24.99863052368164, "ref_rejected_logp": -925.652099609375, "chosen_reward": 0.9740053415298462, "rejected_reward": -1.9256973266601562, "time": 1765819034.1802046}
{"stage": "dpo", "step": 26700, "epoch": 418, "train_loss": 0.05046950340270996, "policy_chosen_logp": -22.163471221923828, "policy_rejected_logp": -962.1614990234375, "ref_chosen_logp": -48.75963592529297, "ref_rejected_logp": -959.415283203125, "chosen_reward": 2.659616470336914, "rejected_reward": -0.2746184468269348, "time": 1765819036.5397515}
{"stage": "dpo", "step": 26750, "epoch": 418, "train_loss": 0.2116931676864624, "policy_chosen_logp": -13.091331481933594, "policy_rejected_logp": -1069.289306640625, "ref_chosen_logp": -41.31633758544922, "ref_rejected_logp": -1062.68212890625, "chosen_reward": 2.822500705718994, "rejected_reward": -0.6607162952423096, "time": 1765819038.8452308}
{"stage": "dpo", "step": 26800, "epoch": 419, "train_loss": 0.20388977855443954, "policy_chosen_logp": -15.29286003112793, "policy_rejected_logp": -1079.8408203125, "ref_chosen_logp": -30.714292526245117, "ref_rejected_logp": -1065.28662109375, "chosen_reward": 1.5421433448791504, "rejected_reward": -1.4554290771484375, "time": 1765819040.9229145}
{"stage": "dpo", "step": 26850, "epoch": 420, "train_loss": 0.14505737900733948, "policy_chosen_logp": -22.47962188720703, "policy_rejected_logp": -1090.791259765625, "ref_chosen_logp": -26.682270050048828, "ref_rejected_logp": -1062.438232421875, "chosen_reward": 0.4202648401260376, "rejected_reward": -2.8353028297424316, "time": 1765819043.3895385}
{"stage": "dpo", "step": 26880, "epoch": 420, "val_pref_acc": 1.0, "time": 1765819045.0151837}
{"stage": "dpo", "step": 26900, "epoch": 421, "train_loss": 0.0855912908911705, "policy_chosen_logp": -12.519498825073242, "policy_rejected_logp": -1115.713623046875, "ref_chosen_logp": -43.81096649169922, "ref_rejected_logp": -1107.4189453125, "chosen_reward": 3.1291470527648926, "rejected_reward": -0.8294768929481506, "time": 1765819045.8654785}
{"stage": "dpo", "step": 26950, "epoch": 422, "train_loss": 0.027273846566677095, "policy_chosen_logp": -27.213153839111328, "policy_rejected_logp": -1067.6280517578125, "ref_chosen_logp": -40.78923034667969, "ref_rejected_logp": -1045.079833984375, "chosen_reward": 1.3576077222824097, "rejected_reward": -2.2548110485076904, "time": 1765819048.4126012}
{"stage": "dpo", "step": 27000, "epoch": 422, "train_loss": 0.21848142951726912, "policy_chosen_logp": -18.8536376953125, "policy_rejected_logp": -1064.6337890625, "ref_chosen_logp": -34.550537109375, "ref_rejected_logp": -1051.80517578125, "chosen_reward": 1.5696899890899658, "rejected_reward": -1.2828660011291504, "time": 1765819050.9349682}
{"stage": "dpo", "step": 27050, "epoch": 423, "train_loss": 0.1841815233230591, "policy_chosen_logp": -24.216720581054688, "policy_rejected_logp": -1073.7047119140625, "ref_chosen_logp": -59.94541931152344, "ref_rejected_logp": -1072.94091796875, "chosen_reward": 3.5728702545166016, "rejected_reward": -0.0763900876045227, "time": 1765819053.453168}
{"stage": "dpo", "step": 27100, "epoch": 424, "train_loss": 0.11940155774354935, "policy_chosen_logp": -23.624677658081055, "policy_rejected_logp": -1087.03564453125, "ref_chosen_logp": -39.97515869140625, "ref_rejected_logp": -1067.3603515625, "chosen_reward": 1.6350477933883667, "rejected_reward": -1.9675323963165283, "time": 1765819055.9847353}
{"stage": "dpo", "step": 27150, "epoch": 425, "train_loss": 0.05890305578708649, "policy_chosen_logp": -23.188480377197266, "policy_rejected_logp": -1040.1326904296875, "ref_chosen_logp": -39.34947204589844, "ref_rejected_logp": -1033.75, "chosen_reward": 1.6160991191864014, "rejected_reward": -0.6382598876953125, "time": 1765819058.469315}
{"stage": "dpo", "step": 27200, "epoch": 425, "train_loss": 0.21872076988220215, "policy_chosen_logp": -21.573511123657227, "policy_rejected_logp": -1033.3223876953125, "ref_chosen_logp": -41.778900146484375, "ref_rejected_logp": -1014.4912109375, "chosen_reward": 2.0205390453338623, "rejected_reward": -1.883123755455017, "time": 1765819060.9482903}
{"stage": "dpo", "step": 27200, "epoch": 425, "val_pref_acc": 1.0, "time": 1765819061.078845}
{"stage": "dpo", "step": 27250, "epoch": 426, "train_loss": 0.21315714567899705, "policy_chosen_logp": -27.761085510253906, "policy_rejected_logp": -1055.5985107421875, "ref_chosen_logp": -37.99135208129883, "ref_rejected_logp": -1033.38671875, "chosen_reward": 1.023026943206787, "rejected_reward": -2.22119140625, "time": 1765819063.412132}
{"stage": "dpo", "step": 27300, "epoch": 427, "train_loss": 0.15524245768785477, "policy_chosen_logp": -15.283077239990234, "policy_rejected_logp": -1159.2503662109375, "ref_chosen_logp": -22.775218963623047, "ref_rejected_logp": -1137.447509765625, "chosen_reward": 0.7492141723632812, "rejected_reward": -2.1802978515625, "time": 1765819065.8724744}
{"stage": "dpo", "step": 27350, "epoch": 428, "train_loss": 0.09308300703763962, "policy_chosen_logp": -21.352928161621094, "policy_rejected_logp": -944.6165161132812, "ref_chosen_logp": -34.21949768066406, "ref_rejected_logp": -923.148681640625, "chosen_reward": 1.2866569757461548, "rejected_reward": -2.1467833518981934, "time": 1765819068.3892992}
{"stage": "dpo", "step": 27400, "epoch": 429, "train_loss": 0.03355366200208664, "policy_chosen_logp": -18.949390411376953, "policy_rejected_logp": -1104.751708984375, "ref_chosen_logp": -41.660526275634766, "ref_rejected_logp": -1093.200439453125, "chosen_reward": 2.271113395690918, "rejected_reward": -1.1551315784454346, "time": 1765819070.8713396}
{"stage": "dpo", "step": 27450, "epoch": 429, "train_loss": 0.2195843130350113, "policy_chosen_logp": -19.04220962524414, "policy_rejected_logp": -957.1052856445312, "ref_chosen_logp": -37.23438262939453, "ref_rejected_logp": -945.06201171875, "chosen_reward": 1.8192172050476074, "rejected_reward": -1.2043273448944092, "time": 1765819073.233805}
{"stage": "dpo", "step": 27500, "epoch": 430, "train_loss": 0.18700844854116438, "policy_chosen_logp": -18.047700881958008, "policy_rejected_logp": -988.8475341796875, "ref_chosen_logp": -30.550662994384766, "ref_rejected_logp": -974.509521484375, "chosen_reward": 1.2502963542938232, "rejected_reward": -1.4338043928146362, "time": 1765819075.7191503}
{"stage": "dpo", "step": 27520, "epoch": 430, "val_pref_acc": 1.0, "time": 1765819076.7960005}
{"stage": "dpo", "step": 27550, "epoch": 431, "train_loss": 0.12780054420232773, "policy_chosen_logp": -11.312063217163086, "policy_rejected_logp": -1004.9326171875, "ref_chosen_logp": -25.57976722717285, "ref_rejected_logp": -985.7467041015625, "chosen_reward": 1.4267703294754028, "rejected_reward": -1.9185928106307983, "time": 1765819078.1429908}
{"stage": "dpo", "step": 27600, "epoch": 432, "train_loss": 0.06775953948497772, "policy_chosen_logp": -19.3631591796875, "policy_rejected_logp": -1025.42236328125, "ref_chosen_logp": -39.09513854980469, "ref_rejected_logp": -1014.5750732421875, "chosen_reward": 1.9731981754302979, "rejected_reward": -1.084730625152588, "time": 1765819080.6074336}
{"stage": "dpo", "step": 27650, "epoch": 433, "train_loss": 0.008814048171043396, "policy_chosen_logp": -15.972587585449219, "policy_rejected_logp": -1065.912109375, "ref_chosen_logp": -41.417415618896484, "ref_rejected_logp": -1062.363525390625, "chosen_reward": 2.544482707977295, "rejected_reward": -0.35484617948532104, "time": 1765819082.9422672}
{"stage": "dpo", "step": 27700, "epoch": 433, "train_loss": 0.21596647351980208, "policy_chosen_logp": -19.594924926757812, "policy_rejected_logp": -1108.4364013671875, "ref_chosen_logp": -33.7126350402832, "ref_rejected_logp": -1085.5728759765625, "chosen_reward": 1.4117708206176758, "rejected_reward": -2.2863571643829346, "time": 1765819085.398253}
{"stage": "dpo", "step": 27750, "epoch": 434, "train_loss": 0.1636747193336487, "policy_chosen_logp": -19.71274757385254, "policy_rejected_logp": -1120.27880859375, "ref_chosen_logp": -30.934078216552734, "ref_rejected_logp": -1090.73583984375, "chosen_reward": 1.1221331357955933, "rejected_reward": -2.954298496246338, "time": 1765819087.8728344}
{"stage": "dpo", "step": 27800, "epoch": 435, "train_loss": 0.10465010732412339, "policy_chosen_logp": -18.977333068847656, "policy_rejected_logp": -1037.3385009765625, "ref_chosen_logp": -40.50446319580078, "ref_rejected_logp": -1025.03857421875, "chosen_reward": 2.152712821960449, "rejected_reward": -1.229986548423767, "time": 1765819090.3420863}
{"stage": "dpo", "step": 27840, "epoch": 435, "val_pref_acc": 1.0, "time": 1765819092.4392326}
{"stage": "dpo", "step": 27850, "epoch": 436, "train_loss": 0.04139789938926697, "policy_chosen_logp": -18.571203231811523, "policy_rejected_logp": -1060.177001953125, "ref_chosen_logp": -45.20153045654297, "ref_rejected_logp": -1054.40478515625, "chosen_reward": 2.6630325317382812, "rejected_reward": -0.5772262811660767, "time": 1765819092.8272407}
{"stage": "dpo", "step": 27900, "epoch": 436, "train_loss": 0.20919861018657684, "policy_chosen_logp": -23.21026611328125, "policy_rejected_logp": -1056.974609375, "ref_chosen_logp": -26.26214599609375, "ref_rejected_logp": -1032.027587890625, "chosen_reward": 0.3051880896091461, "rejected_reward": -2.494711399078369, "time": 1765819095.3616652}
{"stage": "dpo", "step": 27950, "epoch": 437, "train_loss": 0.19838987588882445, "policy_chosen_logp": -18.734708786010742, "policy_rejected_logp": -1029.5628662109375, "ref_chosen_logp": -31.018922805786133, "ref_rejected_logp": -1019.9913330078125, "chosen_reward": 1.2284214496612549, "rejected_reward": -0.9571472406387329, "time": 1765819097.9471376}
{"stage": "dpo", "step": 28000, "epoch": 438, "train_loss": 0.13761649787425995, "policy_chosen_logp": -18.612836837768555, "policy_rejected_logp": -1031.65234375, "ref_chosen_logp": -32.3171501159668, "ref_rejected_logp": -1001.3153686523438, "chosen_reward": 1.3704315423965454, "rejected_reward": -3.033700704574585, "time": 1765819100.4928565}
{"stage": "dpo", "step": 28050, "epoch": 439, "train_loss": 0.0767650055885315, "policy_chosen_logp": -21.674068450927734, "policy_rejected_logp": -1155.100341796875, "ref_chosen_logp": -34.67565155029297, "ref_rejected_logp": -1139.9024658203125, "chosen_reward": 1.3001583814620972, "rejected_reward": -1.5197876691818237, "time": 1765819102.9701302}
{"stage": "dpo", "step": 28100, "epoch": 440, "train_loss": 0.016480181515216828, "policy_chosen_logp": -15.663691520690918, "policy_rejected_logp": -1128.715576171875, "ref_chosen_logp": -35.57008361816406, "ref_rejected_logp": -1112.50634765625, "chosen_reward": 1.990639090538025, "rejected_reward": -1.6209319829940796, "time": 1765819104.956013}
{"stage": "dpo", "step": 28150, "epoch": 440, "train_loss": 0.2145807749032974, "policy_chosen_logp": -18.977718353271484, "policy_rejected_logp": -994.97412109375, "ref_chosen_logp": -40.60160827636719, "ref_rejected_logp": -987.7081298828125, "chosen_reward": 2.162388801574707, "rejected_reward": -0.7265975475311279, "time": 1765819107.422459}
{"stage": "dpo", "step": 28160, "epoch": 440, "val_pref_acc": 1.0, "time": 1765819108.0632915}
{"stage": "dpo", "step": 28200, "epoch": 441, "train_loss": 0.17420856654644012, "policy_chosen_logp": -16.83107566833496, "policy_rejected_logp": -992.1187744140625, "ref_chosen_logp": -37.2376823425293, "ref_rejected_logp": -974.1796875, "chosen_reward": 2.0406606197357178, "rejected_reward": -1.793910264968872, "time": 1765819109.6895678}
{"stage": "dpo", "step": 28250, "epoch": 442, "train_loss": 0.11068878382444382, "policy_chosen_logp": -15.945252418518066, "policy_rejected_logp": -1110.8385009765625, "ref_chosen_logp": -32.5749626159668, "ref_rejected_logp": -1096.37890625, "chosen_reward": 1.662971019744873, "rejected_reward": -1.4459609985351562, "time": 1765819112.157893}
{"stage": "dpo", "step": 28300, "epoch": 443, "train_loss": 0.051024901866912845, "policy_chosen_logp": -25.860483169555664, "policy_rejected_logp": -924.0064697265625, "ref_chosen_logp": -39.33721160888672, "ref_rejected_logp": -904.7633666992188, "chosen_reward": 1.3476725816726685, "rejected_reward": -1.9243149757385254, "time": 1765819114.6493504}
{"stage": "dpo", "step": 28350, "epoch": 443, "train_loss": 0.21349771410226823, "policy_chosen_logp": -20.954757690429688, "policy_rejected_logp": -1098.9830322265625, "ref_chosen_logp": -38.14715576171875, "ref_rejected_logp": -1081.463134765625, "chosen_reward": 1.719239592552185, "rejected_reward": -1.7519867420196533, "time": 1765819117.1315691}
{"stage": "dpo", "step": 28400, "epoch": 444, "train_loss": 0.20564302951097488, "policy_chosen_logp": -18.34524154663086, "policy_rejected_logp": -1092.10400390625, "ref_chosen_logp": -35.8586311340332, "ref_rejected_logp": -1078.004150390625, "chosen_reward": 1.7513388395309448, "rejected_reward": -1.4099838733673096, "time": 1765819119.5697408}
{"stage": "dpo", "step": 28450, "epoch": 445, "train_loss": 0.14455115050077438, "policy_chosen_logp": -19.908098220825195, "policy_rejected_logp": -1075.1337890625, "ref_chosen_logp": -33.827449798583984, "ref_rejected_logp": -1054.0576171875, "chosen_reward": 1.391935110092163, "rejected_reward": -2.107621669769287, "time": 1765819122.0446806}
{"stage": "dpo", "step": 28480, "epoch": 445, "val_pref_acc": 1.0, "time": 1765819123.6591353}
{"stage": "dpo", "step": 28500, "epoch": 446, "train_loss": 0.08536520391702652, "policy_chosen_logp": -17.28984832763672, "policy_rejected_logp": -1137.30322265625, "ref_chosen_logp": -28.225513458251953, "ref_rejected_logp": -1123.6793212890625, "chosen_reward": 1.0935665369033813, "rejected_reward": -1.3623931407928467, "time": 1765819124.5189857}
{"stage": "dpo", "step": 28550, "epoch": 447, "train_loss": 0.027849211990833282, "policy_chosen_logp": -20.24929428100586, "policy_rejected_logp": -1079.123046875, "ref_chosen_logp": -38.31979751586914, "ref_rejected_logp": -1074.07177734375, "chosen_reward": 1.8070504665374756, "rejected_reward": -0.5051315426826477, "time": 1765819127.0036333}
{"stage": "dpo", "step": 28600, "epoch": 447, "train_loss": 0.21773344844579698, "policy_chosen_logp": -20.111988067626953, "policy_rejected_logp": -1000.31298828125, "ref_chosen_logp": -31.221059799194336, "ref_rejected_logp": -978.8935546875, "chosen_reward": 1.1109073162078857, "rejected_reward": -2.1419403553009033, "time": 1765819129.377007}
{"stage": "dpo", "step": 28650, "epoch": 448, "train_loss": 0.17962006866931915, "policy_chosen_logp": -11.861595153808594, "policy_rejected_logp": -1085.2481689453125, "ref_chosen_logp": -39.618553161621094, "ref_rejected_logp": -1090.73095703125, "chosen_reward": 2.775695562362671, "rejected_reward": 0.5482696890830994, "time": 1765819131.8432283}
{"stage": "dpo", "step": 28700, "epoch": 449, "train_loss": 0.11908351212739944, "policy_chosen_logp": -17.213924407958984, "policy_rejected_logp": -928.8250122070312, "ref_chosen_logp": -31.214908599853516, "ref_rejected_logp": -906.7688598632812, "chosen_reward": 1.4000983238220215, "rejected_reward": -2.205613851547241, "time": 1765819134.3226116}
{"stage": "dpo", "step": 28750, "epoch": 450, "train_loss": 0.058607898354530334, "policy_chosen_logp": -21.477310180664062, "policy_rejected_logp": -1080.5457763671875, "ref_chosen_logp": -27.704803466796875, "ref_rejected_logp": -1063.460205078125, "chosen_reward": 0.6227493286132812, "rejected_reward": -1.7085633277893066, "time": 1765819136.8344223}
{"stage": "dpo", "step": 28800, "epoch": 450, "train_loss": 0.21159620046615601, "policy_chosen_logp": -18.10517120361328, "policy_rejected_logp": -980.0875244140625, "ref_chosen_logp": -32.059051513671875, "ref_rejected_logp": -962.4218139648438, "chosen_reward": 1.3953877687454224, "rejected_reward": -1.766575574874878, "time": 1765819139.3451343}
{"stage": "dpo", "step": 28800, "epoch": 450, "val_pref_acc": 1.0, "time": 1765819139.4770439}
{"stage": "dpo", "step": 28850, "epoch": 451, "train_loss": 0.2126900941133499, "policy_chosen_logp": -13.962206840515137, "policy_rejected_logp": -1038.0540771484375, "ref_chosen_logp": -38.23054122924805, "ref_rejected_logp": -1021.9091796875, "chosen_reward": 2.4268336296081543, "rejected_reward": -1.6144882440567017, "time": 1765819141.8281362}
{"stage": "dpo", "step": 28900, "epoch": 452, "train_loss": 0.15336983472108842, "policy_chosen_logp": -24.98654556274414, "policy_rejected_logp": -1187.92431640625, "ref_chosen_logp": -41.997169494628906, "ref_rejected_logp": -1158.95556640625, "chosen_reward": 1.7010624408721924, "rejected_reward": -2.896881103515625, "time": 1765819144.3549902}
{"stage": "dpo", "step": 28950, "epoch": 453, "train_loss": 0.09456452399492264, "policy_chosen_logp": -17.365825653076172, "policy_rejected_logp": -1056.9508056640625, "ref_chosen_logp": -29.70577621459961, "ref_rejected_logp": -1040.2867431640625, "chosen_reward": 1.2339950799942017, "rejected_reward": -1.666406273841858, "time": 1765819146.8483207}
{"stage": "dpo", "step": 29000, "epoch": 454, "train_loss": 0.03503841608762741, "policy_chosen_logp": -10.0875244140625, "policy_rejected_logp": -1013.7840576171875, "ref_chosen_logp": -23.55130386352539, "ref_rejected_logp": -994.1199340820312, "chosen_reward": 1.3463780879974365, "rejected_reward": -1.9664093255996704, "time": 1765819149.3425403}
{"stage": "dpo", "step": 29050, "epoch": 454, "train_loss": 0.2140567770600319, "policy_chosen_logp": -14.246453285217285, "policy_rejected_logp": -1007.7151489257812, "ref_chosen_logp": -25.154220581054688, "ref_rejected_logp": -987.6984252929688, "chosen_reward": 1.0907766819000244, "rejected_reward": -2.0016722679138184, "time": 1765819151.3671536}
{"stage": "dpo", "step": 29100, "epoch": 455, "train_loss": 0.1861830922961235, "policy_chosen_logp": -16.419124603271484, "policy_rejected_logp": -1084.779052734375, "ref_chosen_logp": -31.8699951171875, "ref_rejected_logp": -1063.452392578125, "chosen_reward": 1.5450869798660278, "rejected_reward": -2.132678270339966, "time": 1765819152.6586676}
{"stage": "dpo", "step": 29120, "epoch": 455, "val_pref_acc": 1.0, "time": 1765819153.334546}
{"stage": "dpo", "step": 29150, "epoch": 456, "train_loss": 0.12969765454530716, "policy_chosen_logp": -16.054719924926758, "policy_rejected_logp": -1189.012939453125, "ref_chosen_logp": -31.61206817626953, "ref_rejected_logp": -1165.0784912109375, "chosen_reward": 1.5557349920272827, "rejected_reward": -2.3934600353240967, "time": 1765819154.649123}
{"stage": "dpo", "step": 29200, "epoch": 457, "train_loss": 0.06755041807889939, "policy_chosen_logp": -16.21063232421875, "policy_rejected_logp": -965.9069213867188, "ref_chosen_logp": -31.74694061279297, "ref_rejected_logp": -952.5338134765625, "chosen_reward": 1.5536307096481323, "rejected_reward": -1.337310791015625, "time": 1765819157.0882096}
{"stage": "dpo", "step": 29250, "epoch": 458, "train_loss": 0.008456810414791106, "policy_chosen_logp": -17.324268341064453, "policy_rejected_logp": -991.15966796875, "ref_chosen_logp": -32.218387603759766, "ref_rejected_logp": -970.3102416992188, "chosen_reward": 1.4894118309020996, "rejected_reward": -2.084944248199463, "time": 1765819159.1707015}
{"stage": "dpo", "step": 29300, "epoch": 458, "train_loss": 0.21295109808444976, "policy_chosen_logp": -29.615705490112305, "policy_rejected_logp": -1042.26513671875, "ref_chosen_logp": -38.07951354980469, "ref_rejected_logp": -1022.787841796875, "chosen_reward": 0.8463809490203857, "rejected_reward": -1.9477295875549316, "time": 1765819161.3362317}
{"stage": "dpo", "step": 29350, "epoch": 459, "train_loss": 0.16226252615451814, "policy_chosen_logp": -17.709312438964844, "policy_rejected_logp": -1067.622802734375, "ref_chosen_logp": -43.280723571777344, "ref_rejected_logp": -1061.3828125, "chosen_reward": 2.557141065597534, "rejected_reward": -0.6240050792694092, "time": 1765819163.6745431}
{"stage": "dpo", "step": 29400, "epoch": 460, "train_loss": 0.10171965330839157, "policy_chosen_logp": -17.13621711730957, "policy_rejected_logp": -1048.1348876953125, "ref_chosen_logp": -33.229408264160156, "ref_rejected_logp": -1029.164306640625, "chosen_reward": 1.6093189716339111, "rejected_reward": -1.897049069404602, "time": 1765819165.9293792}
{"stage": "dpo", "step": 29440, "epoch": 460, "val_pref_acc": 1.0, "time": 1765819167.8360682}
{"stage": "dpo", "step": 29450, "epoch": 461, "train_loss": 0.04149413883686066, "policy_chosen_logp": -19.677997589111328, "policy_rejected_logp": -1039.689453125, "ref_chosen_logp": -32.587493896484375, "ref_rejected_logp": -1018.21728515625, "chosen_reward": 1.2909497022628784, "rejected_reward": -2.1472244262695312, "time": 1765819168.1622844}
{"stage": "dpo", "step": 29500, "epoch": 461, "train_loss": 0.21287648171186446, "policy_chosen_logp": -23.501392364501953, "policy_rejected_logp": -989.4151611328125, "ref_chosen_logp": -54.80716323852539, "ref_rejected_logp": -992.4432373046875, "chosen_reward": 3.1305770874023438, "rejected_reward": 0.3028060793876648, "time": 1765819170.2009006}
{"stage": "dpo", "step": 29550, "epoch": 462, "train_loss": 0.19384769797325135, "policy_chosen_logp": -20.311840057373047, "policy_rejected_logp": -1079.5, "ref_chosen_logp": -33.1009635925293, "ref_rejected_logp": -1062.4014892578125, "chosen_reward": 1.2789123058319092, "rejected_reward": -1.709852695465088, "time": 1765819172.348533}
{"stage": "dpo", "step": 29600, "epoch": 463, "train_loss": 0.1372967940568924, "policy_chosen_logp": -20.25926971435547, "policy_rejected_logp": -1092.6798095703125, "ref_chosen_logp": -34.81544876098633, "ref_rejected_logp": -1064.5357666015625, "chosen_reward": 1.455618143081665, "rejected_reward": -2.8144044876098633, "time": 1765819174.2188654}
{"stage": "dpo", "step": 29650, "epoch": 464, "train_loss": 0.07588343858718873, "policy_chosen_logp": -17.9505615234375, "policy_rejected_logp": -1155.650390625, "ref_chosen_logp": -41.66666793823242, "ref_rejected_logp": -1150.522705078125, "chosen_reward": 2.371610641479492, "rejected_reward": -0.5127609372138977, "time": 1765819176.3046362}
{"stage": "dpo", "step": 29700, "epoch": 465, "train_loss": 0.016815227866172792, "policy_chosen_logp": -14.833937644958496, "policy_rejected_logp": -1125.021240234375, "ref_chosen_logp": -30.250244140625, "ref_rejected_logp": -1113.7421875, "chosen_reward": 1.541630744934082, "rejected_reward": -1.1279128789901733, "time": 1765819178.4214776}
{"stage": "dpo", "step": 29750, "epoch": 465, "train_loss": 0.21374164581298827, "policy_chosen_logp": -16.700054168701172, "policy_rejected_logp": -1063.42041015625, "ref_chosen_logp": -32.046878814697266, "ref_rejected_logp": -1046.1824951171875, "chosen_reward": 1.5346825122833252, "rejected_reward": -1.7237991094589233, "time": 1765819180.4126966}
{"stage": "dpo", "step": 29760, "epoch": 465, "val_pref_acc": 1.0, "time": 1765819180.7363925}
{"stage": "dpo", "step": 29800, "epoch": 466, "train_loss": 0.1694464147090912, "policy_chosen_logp": -14.27875804901123, "policy_rejected_logp": -1061.3394775390625, "ref_chosen_logp": -20.942590713500977, "ref_rejected_logp": -1031.411865234375, "chosen_reward": 0.6663831472396851, "rejected_reward": -2.992758274078369, "time": 1765819182.043731}
{"stage": "dpo", "step": 29850, "epoch": 467, "train_loss": 0.11087988197803497, "policy_chosen_logp": -18.712177276611328, "policy_rejected_logp": -1054.5631103515625, "ref_chosen_logp": -41.70512390136719, "ref_rejected_logp": -1042.570068359375, "chosen_reward": 2.2992944717407227, "rejected_reward": -1.199304223060608, "time": 1765819183.2271523}
{"stage": "dpo", "step": 29900, "epoch": 468, "train_loss": 0.051477617025375365, "policy_chosen_logp": -12.754839897155762, "policy_rejected_logp": -1106.96728515625, "ref_chosen_logp": -20.730836868286133, "ref_rejected_logp": -1081.505615234375, "chosen_reward": 0.7975996732711792, "rejected_reward": -2.546170234680176, "time": 1765819185.1774204}
{"stage": "dpo", "step": 29950, "epoch": 468, "train_loss": 0.21156641215085983, "policy_chosen_logp": -22.208145141601562, "policy_rejected_logp": -1111.32958984375, "ref_chosen_logp": -28.123435974121094, "ref_rejected_logp": -1085.16259765625, "chosen_reward": 0.591529130935669, "rejected_reward": -2.6166930198669434, "time": 1765819186.6936018}
{"stage": "dpo", "step": 30000, "epoch": 469, "train_loss": 0.20082178503274917, "policy_chosen_logp": -13.446711540222168, "policy_rejected_logp": -1010.7652587890625, "ref_chosen_logp": -43.4062385559082, "ref_rejected_logp": -1003.7330322265625, "chosen_reward": 2.99595308303833, "rejected_reward": -0.7032211422920227, "time": 1765819188.1638663}
{"stage": "dpo", "step": 30050, "epoch": 470, "train_loss": 0.14225874722003937, "policy_chosen_logp": -12.787903785705566, "policy_rejected_logp": -1134.06982421875, "ref_chosen_logp": -30.776103973388672, "ref_rejected_logp": -1121.94775390625, "chosen_reward": 1.7988201379776, "rejected_reward": -1.2121918201446533, "time": 1765819189.3260307}
{"stage": "dpo", "step": 30080, "epoch": 470, "val_pref_acc": 1.0, "time": 1765819190.7799783}
{"stage": "dpo", "step": 30100, "epoch": 471, "train_loss": 0.08550108879804612, "policy_chosen_logp": -12.67016315460205, "policy_rejected_logp": -1109.274169921875, "ref_chosen_logp": -26.214542388916016, "ref_rejected_logp": -1085.482666015625, "chosen_reward": 1.3544378280639648, "rejected_reward": -2.379141330718994, "time": 1765819191.3364904}
{"stage": "dpo", "step": 30150, "epoch": 472, "train_loss": 0.02578766077756882, "policy_chosen_logp": -17.705352783203125, "policy_rejected_logp": -995.94189453125, "ref_chosen_logp": -45.242313385009766, "ref_rejected_logp": -986.5120849609375, "chosen_reward": 2.7536962032318115, "rejected_reward": -0.9429794549942017, "time": 1765819192.9973543}
{"stage": "dpo", "step": 30200, "epoch": 472, "train_loss": 0.21237706899642944, "policy_chosen_logp": -14.7695894241333, "policy_rejected_logp": -1027.674560546875, "ref_chosen_logp": -24.854175567626953, "ref_rejected_logp": -1007.6577758789062, "chosen_reward": 1.0084587335586548, "rejected_reward": -2.001678466796875, "time": 1765819194.8786376}
{"stage": "dpo", "step": 30250, "epoch": 473, "train_loss": 0.1789912450313568, "policy_chosen_logp": -20.184513092041016, "policy_rejected_logp": -1006.037841796875, "ref_chosen_logp": -40.27787399291992, "ref_rejected_logp": -992.1646118164062, "chosen_reward": 2.009335994720459, "rejected_reward": -1.3873200416564941, "time": 1765819196.4159153}
{"stage": "dpo", "step": 30300, "epoch": 474, "train_loss": 0.11799351662397385, "policy_chosen_logp": -17.540016174316406, "policy_rejected_logp": -1098.23291015625, "ref_chosen_logp": -35.99131774902344, "ref_rejected_logp": -1090.369873046875, "chosen_reward": 1.845130443572998, "rejected_reward": -0.7863067388534546, "time": 1765819198.4108508}
{"stage": "dpo", "step": 30350, "epoch": 475, "train_loss": 0.061445530652999875, "policy_chosen_logp": -14.309213638305664, "policy_rejected_logp": -1076.281494140625, "ref_chosen_logp": -35.84288024902344, "ref_rejected_logp": -1055.2864990234375, "chosen_reward": 2.1533665657043457, "rejected_reward": -2.0994935035705566, "time": 1765819200.9096842}
{"stage": "dpo", "step": 30400, "epoch": 475, "train_loss": 0.21282921433448793, "policy_chosen_logp": -21.55321502685547, "policy_rejected_logp": -1100.577880859375, "ref_chosen_logp": -36.016075134277344, "ref_rejected_logp": -1082.399658203125, "chosen_reward": 1.4462859630584717, "rejected_reward": -1.8178131580352783, "time": 1765819203.3926306}
{"stage": "dpo", "step": 30400, "epoch": 475, "val_pref_acc": 1.0, "time": 1765819203.522057}
{"stage": "dpo", "step": 30450, "epoch": 476, "train_loss": 0.2106138387322426, "policy_chosen_logp": -19.565284729003906, "policy_rejected_logp": -1114.8883056640625, "ref_chosen_logp": -36.62302017211914, "ref_rejected_logp": -1100.02880859375, "chosen_reward": 1.7057735919952393, "rejected_reward": -1.4859482049942017, "time": 1765819205.8679192}
{"stage": "dpo", "step": 30500, "epoch": 477, "train_loss": 0.1551113948225975, "policy_chosen_logp": -19.532691955566406, "policy_rejected_logp": -988.2762451171875, "ref_chosen_logp": -33.413307189941406, "ref_rejected_logp": -963.038330078125, "chosen_reward": 1.3880614042282104, "rejected_reward": -2.5237932205200195, "time": 1765819208.3441308}
{"stage": "dpo", "step": 30550, "epoch": 478, "train_loss": 0.09356950551271438, "policy_chosen_logp": -19.485408782958984, "policy_rejected_logp": -1040.866943359375, "ref_chosen_logp": -33.951656341552734, "ref_rejected_logp": -1024.740234375, "chosen_reward": 1.446624755859375, "rejected_reward": -1.6126587390899658, "time": 1765819210.8376338}
{"stage": "dpo", "step": 30600, "epoch": 479, "train_loss": 0.03406115502119064, "policy_chosen_logp": -22.98616600036621, "policy_rejected_logp": -1042.864501953125, "ref_chosen_logp": -42.879486083984375, "ref_rejected_logp": -1023.6148681640625, "chosen_reward": 1.9893321990966797, "rejected_reward": -1.9249558448791504, "time": 1765819213.3597136}
{"stage": "dpo", "step": 30650, "epoch": 479, "train_loss": 0.21118555933237076, "policy_chosen_logp": -24.44972801208496, "policy_rejected_logp": -1048.517578125, "ref_chosen_logp": -49.921417236328125, "ref_rejected_logp": -1041.4615478515625, "chosen_reward": 2.5471692085266113, "rejected_reward": -0.7056061029434204, "time": 1765819215.8416631}
{"stage": "dpo", "step": 30700, "epoch": 480, "train_loss": 0.18378910571336746, "policy_chosen_logp": -21.22376823425293, "policy_rejected_logp": -1017.8970336914062, "ref_chosen_logp": -45.946590423583984, "ref_rejected_logp": -1015.074462890625, "chosen_reward": 2.4722824096679688, "rejected_reward": -0.2822631597518921, "time": 1765819218.024583}
{"stage": "dpo", "step": 30720, "epoch": 480, "val_pref_acc": 1.0, "time": 1765819219.0526626}
{"stage": "dpo", "step": 30750, "epoch": 481, "train_loss": 0.12763968378305435, "policy_chosen_logp": -15.919831275939941, "policy_rejected_logp": -1131.2088623046875, "ref_chosen_logp": -35.06272888183594, "ref_rejected_logp": -1117.54052734375, "chosen_reward": 1.914289951324463, "rejected_reward": -1.3668274879455566, "time": 1765819220.311216}
{"stage": "dpo", "step": 30800, "epoch": 482, "train_loss": 0.0681804957985878, "policy_chosen_logp": -13.59406852722168, "policy_rejected_logp": -1035.6580810546875, "ref_chosen_logp": -32.423912048339844, "ref_rejected_logp": -1021.5221557617188, "chosen_reward": 1.8829841613769531, "rejected_reward": -1.413588047027588, "time": 1765819222.6180882}
{"stage": "dpo", "step": 30850, "epoch": 483, "train_loss": 0.008391646146774292, "policy_chosen_logp": -16.75267219543457, "policy_rejected_logp": -1071.2991943359375, "ref_chosen_logp": -37.34280014038086, "ref_rejected_logp": -1062.364990234375, "chosen_reward": 2.0590128898620605, "rejected_reward": -0.8934234380722046, "time": 1765819224.6073778}
{"stage": "dpo", "step": 30900, "epoch": 483, "train_loss": 0.21217163532972336, "policy_chosen_logp": -17.318471908569336, "policy_rejected_logp": -1059.1005859375, "ref_chosen_logp": -38.073974609375, "ref_rejected_logp": -1046.6754150390625, "chosen_reward": 2.075550079345703, "rejected_reward": -1.2425169944763184, "time": 1765819226.3924932}
{"stage": "dpo", "step": 30950, "epoch": 484, "train_loss": 0.15998969733715057, "policy_chosen_logp": -18.645814895629883, "policy_rejected_logp": -949.75927734375, "ref_chosen_logp": -32.728675842285156, "ref_rejected_logp": -932.9622802734375, "chosen_reward": 1.408286213874817, "rejected_reward": -1.6796921491622925, "time": 1765819227.8569713}
{"stage": "dpo", "step": 31000, "epoch": 485, "train_loss": 0.09964215159416198, "policy_chosen_logp": -17.268356323242188, "policy_rejected_logp": -1058.5657958984375, "ref_chosen_logp": -33.21982955932617, "ref_rejected_logp": -1046.3013916015625, "chosen_reward": 1.5951472520828247, "rejected_reward": -1.2264388799667358, "time": 1765819229.4765155}
{"stage": "dpo", "step": 31040, "epoch": 485, "val_pref_acc": 1.0, "time": 1765819230.7325056}
{"stage": "dpo", "step": 31050, "epoch": 486, "train_loss": 0.04167305797338486, "policy_chosen_logp": -12.43095588684082, "policy_rejected_logp": -1064.018798828125, "ref_chosen_logp": -30.305246353149414, "ref_rejected_logp": -1052.098876953125, "chosen_reward": 1.7874289751052856, "rejected_reward": -1.1920028924942017, "time": 1765819230.926877}
{"stage": "dpo", "step": 31100, "epoch": 486, "train_loss": 0.21005899608135223, "policy_chosen_logp": -14.119729042053223, "policy_rejected_logp": -1024.16552734375, "ref_chosen_logp": -31.560527801513672, "ref_rejected_logp": -1011.2903442382812, "chosen_reward": 1.744079828262329, "rejected_reward": -1.2875243425369263, "time": 1765819232.2861373}
{"stage": "dpo", "step": 31150, "epoch": 487, "train_loss": 0.19396685898303986, "policy_chosen_logp": -15.859275817871094, "policy_rejected_logp": -1046.750244140625, "ref_chosen_logp": -44.576560974121094, "ref_rejected_logp": -1036.280029296875, "chosen_reward": 2.8717284202575684, "rejected_reward": -1.047021508216858, "time": 1765819233.7669184}
{"stage": "dpo", "step": 31200, "epoch": 488, "train_loss": 0.1342647722363472, "policy_chosen_logp": -22.829296112060547, "policy_rejected_logp": -921.966552734375, "ref_chosen_logp": -34.04364013671875, "ref_rejected_logp": -901.0966186523438, "chosen_reward": 1.1214344501495361, "rejected_reward": -2.086996555328369, "time": 1765819235.9702587}
{"stage": "dpo", "step": 31250, "epoch": 489, "train_loss": 0.07731478035449982, "policy_chosen_logp": -18.512115478515625, "policy_rejected_logp": -1036.2564697265625, "ref_chosen_logp": -30.208724975585938, "ref_rejected_logp": -1011.2172241210938, "chosen_reward": 1.1696609258651733, "rejected_reward": -2.5039262771606445, "time": 1765819238.2199817}
{"stage": "dpo", "step": 31300, "epoch": 490, "train_loss": 0.016804098188877105, "policy_chosen_logp": -18.172334671020508, "policy_rejected_logp": -1014.5908203125, "ref_chosen_logp": -37.44349670410156, "ref_rejected_logp": -999.5037231445312, "chosen_reward": 1.9271161556243896, "rejected_reward": -1.5087097883224487, "time": 1765819240.1745753}
{"stage": "dpo", "step": 31350, "epoch": 490, "train_loss": 0.21499839365482332, "policy_chosen_logp": -9.390981674194336, "policy_rejected_logp": -997.658203125, "ref_chosen_logp": -30.4029541015625, "ref_rejected_logp": -985.7169799804688, "chosen_reward": 2.1011972427368164, "rejected_reward": -1.1941208839416504, "time": 1765819242.1458504}
{"stage": "dpo", "step": 31360, "epoch": 490, "val_pref_acc": 1.0, "time": 1765819242.6346447}
{"stage": "dpo", "step": 31400, "epoch": 491, "train_loss": 0.1706351038813591, "policy_chosen_logp": -16.619247436523438, "policy_rejected_logp": -1103.987060546875, "ref_chosen_logp": -25.218406677246094, "ref_rejected_logp": -1071.8917236328125, "chosen_reward": 0.8599159717559814, "rejected_reward": -3.2095367908477783, "time": 1765819244.1025496}
{"stage": "dpo", "step": 31450, "epoch": 492, "train_loss": 0.11043937295675278, "policy_chosen_logp": -19.497718811035156, "policy_rejected_logp": -1036.705078125, "ref_chosen_logp": -41.90483856201172, "ref_rejected_logp": -1031.4561767578125, "chosen_reward": 2.2407119274139404, "rejected_reward": -0.524884045124054, "time": 1765819245.2783031}
{"stage": "dpo", "step": 31500, "epoch": 493, "train_loss": 0.05249210476875305, "policy_chosen_logp": -15.246025085449219, "policy_rejected_logp": -1134.052490234375, "ref_chosen_logp": -34.9955940246582, "ref_rejected_logp": -1117.390869140625, "chosen_reward": 1.974956750869751, "rejected_reward": -1.6661713123321533, "time": 1765819247.1515641}
{"stage": "dpo", "step": 31550, "epoch": 493, "train_loss": 0.21442225098609924, "policy_chosen_logp": -14.33010482788086, "policy_rejected_logp": -977.0576171875, "ref_chosen_logp": -33.53371810913086, "ref_rejected_logp": -967.2990112304688, "chosen_reward": 1.9203615188598633, "rejected_reward": -0.9758591055870056, "time": 1765819249.5425727}
{"stage": "dpo", "step": 31600, "epoch": 494, "train_loss": 0.20674185663461686, "policy_chosen_logp": -17.116928100585938, "policy_rejected_logp": -1170.202880859375, "ref_chosen_logp": -45.203033447265625, "ref_rejected_logp": -1156.386962890625, "chosen_reward": 2.808610439300537, "rejected_reward": -1.3815979957580566, "time": 1765819251.9387245}
{"stage": "dpo", "step": 31650, "epoch": 495, "train_loss": 0.14432003289461137, "policy_chosen_logp": -26.20499038696289, "policy_rejected_logp": -1120.1995849609375, "ref_chosen_logp": -38.84617614746094, "ref_rejected_logp": -1100.90771484375, "chosen_reward": 1.2641185522079468, "rejected_reward": -1.9291794300079346, "time": 1765819254.4332829}
{"stage": "dpo", "step": 31680, "epoch": 495, "val_pref_acc": 1.0, "time": 1765819256.051119}
{"stage": "dpo", "step": 31700, "epoch": 496, "train_loss": 0.08509952336549759, "policy_chosen_logp": -7.8518524169921875, "policy_rejected_logp": -1115.9644775390625, "ref_chosen_logp": -20.23853874206543, "ref_rejected_logp": -1092.896728515625, "chosen_reward": 1.2386685609817505, "rejected_reward": -2.3067703247070312, "time": 1765819256.9239185}
{"stage": "dpo", "step": 31750, "epoch": 497, "train_loss": 0.0257912540435791, "policy_chosen_logp": -26.888168334960938, "policy_rejected_logp": -1062.3662109375, "ref_chosen_logp": -48.28083038330078, "ref_rejected_logp": -1049.7777099609375, "chosen_reward": 2.1392664909362793, "rejected_reward": -1.2588592767715454, "time": 1765819258.5815423}
{"stage": "dpo", "step": 31800, "epoch": 497, "train_loss": 0.21076999694108964, "policy_chosen_logp": -22.124446868896484, "policy_rejected_logp": -1074.21240234375, "ref_chosen_logp": -40.8629035949707, "ref_rejected_logp": -1064.0159912109375, "chosen_reward": 1.8738455772399902, "rejected_reward": -1.0196350812911987, "time": 1765819260.4412763}
{"stage": "dpo", "step": 31850, "epoch": 498, "train_loss": 0.178146390914917, "policy_chosen_logp": -14.762582778930664, "policy_rejected_logp": -955.8713989257812, "ref_chosen_logp": -30.451950073242188, "ref_rejected_logp": -938.0244140625, "chosen_reward": 1.5689367055892944, "rejected_reward": -1.7847001552581787, "time": 1765819262.6573799}
{"stage": "dpo", "step": 31900, "epoch": 499, "train_loss": 0.11790233671665191, "policy_chosen_logp": -9.25901985168457, "policy_rejected_logp": -977.219970703125, "ref_chosen_logp": -31.547775268554688, "ref_rejected_logp": -966.48681640625, "chosen_reward": 2.2288753986358643, "rejected_reward": -1.0733094215393066, "time": 1765819265.149494}
{"stage": "dpo", "step": 31950, "epoch": 500, "train_loss": 0.06017748385667801, "policy_chosen_logp": -28.558401107788086, "policy_rejected_logp": -996.14990234375, "ref_chosen_logp": -42.50933074951172, "ref_rejected_logp": -977.25537109375, "chosen_reward": 1.3950926065444946, "rejected_reward": -1.8894531726837158, "time": 1765819267.6309676}
{"stage": "dpo", "step": 32000, "epoch": 500, "train_loss": 0.21026335507631302, "policy_chosen_logp": -18.726055145263672, "policy_rejected_logp": -1049.25927734375, "ref_chosen_logp": -32.90965270996094, "ref_rejected_logp": -1031.8924560546875, "chosen_reward": 1.4183599948883057, "rejected_reward": -1.7366806268692017, "time": 1765819270.1237035}
{"stage": "dpo", "step": 32000, "epoch": 500, "val_pref_acc": 1.0, "time": 1765819270.2519557}
{"stage": "dpo", "step": 32050, "epoch": 501, "train_loss": 0.21090454071760179, "policy_chosen_logp": -11.537174224853516, "policy_rejected_logp": -1017.8482666015625, "ref_chosen_logp": -24.107135772705078, "ref_rejected_logp": -994.1223754882812, "chosen_reward": 1.2569961547851562, "rejected_reward": -2.3725922107696533, "time": 1765819272.575738}
{"stage": "dpo", "step": 32100, "epoch": 502, "train_loss": 0.15182126581668853, "policy_chosen_logp": -15.135316848754883, "policy_rejected_logp": -1110.886962890625, "ref_chosen_logp": -28.501628875732422, "ref_rejected_logp": -1089.2724609375, "chosen_reward": 1.3366310596466064, "rejected_reward": -2.161451816558838, "time": 1765819275.0481288}
{"stage": "dpo", "step": 32150, "epoch": 503, "train_loss": 0.09148990333080292, "policy_chosen_logp": -17.953935623168945, "policy_rejected_logp": -1052.9664306640625, "ref_chosen_logp": -39.086090087890625, "ref_rejected_logp": -1039.5850830078125, "chosen_reward": 2.113215684890747, "rejected_reward": -1.338140845298767, "time": 1765819277.525065}
{"stage": "dpo", "step": 32200, "epoch": 504, "train_loss": 0.03366813063621521, "policy_chosen_logp": -24.2899112701416, "policy_rejected_logp": -1027.968017578125, "ref_chosen_logp": -41.924522399902344, "ref_rejected_logp": -1006.598388671875, "chosen_reward": 1.7634613513946533, "rejected_reward": -2.1369521617889404, "time": 1765819279.987472}
{"stage": "dpo", "step": 32250, "epoch": 504, "train_loss": 0.2090733504295349, "policy_chosen_logp": -21.091350555419922, "policy_rejected_logp": -1072.957275390625, "ref_chosen_logp": -31.665037155151367, "ref_rejected_logp": -1051.41357421875, "chosen_reward": 1.0573688745498657, "rejected_reward": -2.1543731689453125, "time": 1765819282.459025}
{"stage": "dpo", "step": 32300, "epoch": 505, "train_loss": 0.1852865472435951, "policy_chosen_logp": -25.616371154785156, "policy_rejected_logp": -1033.73388671875, "ref_chosen_logp": -43.34205627441406, "ref_rejected_logp": -1022.021728515625, "chosen_reward": 1.772568702697754, "rejected_reward": -1.1712204217910767, "time": 1765819284.9528773}
{"stage": "dpo", "step": 32320, "epoch": 505, "val_pref_acc": 1.0, "time": 1765819286.078472}
{"stage": "dpo", "step": 32350, "epoch": 506, "train_loss": 0.12693403273820877, "policy_chosen_logp": -26.583045959472656, "policy_rejected_logp": -1079.3153076171875, "ref_chosen_logp": -34.879364013671875, "ref_rejected_logp": -1061.989501953125, "chosen_reward": 0.8296321630477905, "rejected_reward": -1.7325867414474487, "time": 1765819287.4270523}
{"stage": "dpo", "step": 32400, "epoch": 507, "train_loss": 0.06850487440824508, "policy_chosen_logp": -23.630992889404297, "policy_rejected_logp": -1005.0408935546875, "ref_chosen_logp": -41.79487991333008, "ref_rejected_logp": -995.2906494140625, "chosen_reward": 1.8163888454437256, "rejected_reward": -0.9750243425369263, "time": 1765819289.9419086}
{"stage": "dpo", "step": 32450, "epoch": 508, "train_loss": 0.008390543758869171, "policy_chosen_logp": -22.415250778198242, "policy_rejected_logp": -940.3123779296875, "ref_chosen_logp": -43.84899139404297, "ref_rejected_logp": -925.0372314453125, "chosen_reward": 2.143374443054199, "rejected_reward": -1.5275115966796875, "time": 1765819292.0431166}
{"stage": "dpo", "step": 32500, "epoch": 508, "train_loss": 0.21201220780611038, "policy_chosen_logp": -23.798809051513672, "policy_rejected_logp": -924.163818359375, "ref_chosen_logp": -35.0613899230957, "ref_rejected_logp": -899.4677734375, "chosen_reward": 1.126258373260498, "rejected_reward": -2.4696044921875, "time": 1765819294.532798}
{"stage": "dpo", "step": 32550, "epoch": 509, "train_loss": 0.160184665620327, "policy_chosen_logp": -14.996288299560547, "policy_rejected_logp": -1033.884765625, "ref_chosen_logp": -36.95940399169922, "ref_rejected_logp": -1030.0296630859375, "chosen_reward": 2.1963117122650146, "rejected_reward": -0.3855133056640625, "time": 1765819297.035444}
{"stage": "dpo", "step": 32600, "epoch": 510, "train_loss": 0.1035029348731041, "policy_chosen_logp": -18.591703414916992, "policy_rejected_logp": -1014.3299560546875, "ref_chosen_logp": -32.53767395019531, "ref_rejected_logp": -999.6778564453125, "chosen_reward": 1.394596815109253, "rejected_reward": -1.4652116298675537, "time": 1765819299.5085154}
{"stage": "dpo", "step": 32640, "epoch": 510, "val_pref_acc": 1.0, "time": 1765819301.6436143}
{"stage": "dpo", "step": 32650, "epoch": 511, "train_loss": 0.04351886481046677, "policy_chosen_logp": -26.91710662841797, "policy_rejected_logp": -1103.23974609375, "ref_chosen_logp": -41.922332763671875, "ref_rejected_logp": -1081.607666015625, "chosen_reward": 1.5005223751068115, "rejected_reward": -2.1632096767425537, "time": 1765819302.0465543}
{"stage": "dpo", "step": 32700, "epoch": 511, "train_loss": 0.21304129421710968, "policy_chosen_logp": -19.180526733398438, "policy_rejected_logp": -1031.2564697265625, "ref_chosen_logp": -38.81195831298828, "ref_rejected_logp": -1016.6668701171875, "chosen_reward": 1.9631434679031372, "rejected_reward": -1.4589630365371704, "time": 1765819304.5165079}
{"stage": "dpo", "step": 32750, "epoch": 512, "train_loss": 0.1935738953948021, "policy_chosen_logp": -14.730725288391113, "policy_rejected_logp": -1131.395751953125, "ref_chosen_logp": -42.02030563354492, "ref_rejected_logp": -1135.00341796875, "chosen_reward": 2.7289581298828125, "rejected_reward": 0.3607681393623352, "time": 1765819307.0069637}
{"stage": "dpo", "step": 32800, "epoch": 513, "train_loss": 0.13368867814540863, "policy_chosen_logp": -10.57581901550293, "policy_rejected_logp": -1034.38818359375, "ref_chosen_logp": -23.95107078552246, "ref_rejected_logp": -1019.6678466796875, "chosen_reward": 1.3375253677368164, "rejected_reward": -1.4720337390899658, "time": 1765819309.487036}
{"stage": "dpo", "step": 32850, "epoch": 514, "train_loss": 0.07700362741947174, "policy_chosen_logp": -10.901691436767578, "policy_rejected_logp": -1075.661376953125, "ref_chosen_logp": -27.767013549804688, "ref_rejected_logp": -1067.40087890625, "chosen_reward": 1.6865322589874268, "rejected_reward": -0.8260513544082642, "time": 1765819311.8046405}
{"stage": "dpo", "step": 32900, "epoch": 515, "train_loss": 0.016623941361904145, "policy_chosen_logp": -8.381237030029297, "policy_rejected_logp": -1040.9822998046875, "ref_chosen_logp": -19.58875274658203, "ref_rejected_logp": -1018.9778442382812, "chosen_reward": 1.1207516193389893, "rejected_reward": -2.2004501819610596, "time": 1765819314.273867}
{"stage": "dpo", "step": 32950, "epoch": 515, "train_loss": 0.21348742991685868, "policy_chosen_logp": -24.68196678161621, "policy_rejected_logp": -947.5968017578125, "ref_chosen_logp": -39.26664733886719, "ref_rejected_logp": -927.540283203125, "chosen_reward": 1.4584684371948242, "rejected_reward": -2.0056562423706055, "time": 1765819316.7448976}
{"stage": "dpo", "step": 32960, "epoch": 515, "val_pref_acc": 1.0, "time": 1765819317.3639905}
{"stage": "dpo", "step": 33000, "epoch": 516, "train_loss": 0.16947800040245056, "policy_chosen_logp": -15.385536193847656, "policy_rejected_logp": -1027.6953125, "ref_chosen_logp": -33.211421966552734, "ref_rejected_logp": -1010.4317626953125, "chosen_reward": 1.7825887203216553, "rejected_reward": -1.7263611555099487, "time": 1765819319.1951647}
{"stage": "dpo", "step": 33050, "epoch": 517, "train_loss": 0.11021273106336593, "policy_chosen_logp": -15.100086212158203, "policy_rejected_logp": -1091.9476318359375, "ref_chosen_logp": -39.01124954223633, "ref_rejected_logp": -1082.09814453125, "chosen_reward": 2.3911166191101074, "rejected_reward": -0.9849411249160767, "time": 1765819321.6566367}
{"stage": "dpo", "step": 33100, "epoch": 518, "train_loss": 0.049607923328876494, "policy_chosen_logp": -19.25739860534668, "policy_rejected_logp": -1115.617919921875, "ref_chosen_logp": -31.004215240478516, "ref_rejected_logp": -1093.5560302734375, "chosen_reward": 1.1746816635131836, "rejected_reward": -2.206185817718506, "time": 1765819324.1262674}
{"stage": "dpo", "step": 33150, "epoch": 518, "train_loss": 0.20805005550384523, "policy_chosen_logp": -20.853044509887695, "policy_rejected_logp": -966.5615234375, "ref_chosen_logp": -35.67193603515625, "ref_rejected_logp": -946.85693359375, "chosen_reward": 1.481889247894287, "rejected_reward": -1.970458984375, "time": 1765819326.583561}
{"stage": "dpo", "step": 33200, "epoch": 519, "train_loss": 0.20176928192377092, "policy_chosen_logp": -28.72830581665039, "policy_rejected_logp": -995.3942260742188, "ref_chosen_logp": -49.39064025878906, "ref_rejected_logp": -980.5635375976562, "chosen_reward": 2.0662336349487305, "rejected_reward": -1.4830673933029175, "time": 1765819329.0200837}
{"stage": "dpo", "step": 33250, "epoch": 520, "train_loss": 0.14615741074085237, "policy_chosen_logp": -21.666704177856445, "policy_rejected_logp": -910.6571655273438, "ref_chosen_logp": -36.605873107910156, "ref_rejected_logp": -892.1890869140625, "chosen_reward": 1.4939167499542236, "rejected_reward": -1.8468093872070312, "time": 1765819331.5219648}
{"stage": "dpo", "step": 33280, "epoch": 520, "val_pref_acc": 1.0, "time": 1765819333.0295954}
{"stage": "dpo", "step": 33300, "epoch": 521, "train_loss": 0.08479762285947799, "policy_chosen_logp": -13.950647354125977, "policy_rejected_logp": -1042.249755859375, "ref_chosen_logp": -31.818408966064453, "ref_rejected_logp": -1032.35498046875, "chosen_reward": 1.786776065826416, "rejected_reward": -0.9894683957099915, "time": 1765819333.8932865}
{"stage": "dpo", "step": 33350, "epoch": 522, "train_loss": 0.02486644923686981, "policy_chosen_logp": -18.839954376220703, "policy_rejected_logp": -1032.06494140625, "ref_chosen_logp": -36.84178161621094, "ref_rejected_logp": -1018.968994140625, "chosen_reward": 1.800182819366455, "rejected_reward": -1.309594750404358, "time": 1765819336.4005895}
{"stage": "dpo", "step": 33400, "epoch": 522, "train_loss": 0.21386710077524185, "policy_chosen_logp": -19.500591278076172, "policy_rejected_logp": -948.140380859375, "ref_chosen_logp": -28.975360870361328, "ref_rejected_logp": -926.3387451171875, "chosen_reward": 0.947476863861084, "rejected_reward": -2.180163621902466, "time": 1765819338.903409}
{"stage": "dpo", "step": 33450, "epoch": 523, "train_loss": 0.17666224896907806, "policy_chosen_logp": -12.241584777832031, "policy_rejected_logp": -1140.3319091796875, "ref_chosen_logp": -24.667339324951172, "ref_rejected_logp": -1125.294189453125, "chosen_reward": 1.2425756454467773, "rejected_reward": -1.5037765502929688, "time": 1765819341.4134781}
{"stage": "dpo", "step": 33500, "epoch": 524, "train_loss": 0.11792979747056961, "policy_chosen_logp": -20.27208709716797, "policy_rejected_logp": -1035.779052734375, "ref_chosen_logp": -38.4164924621582, "ref_rejected_logp": -1020.513427734375, "chosen_reward": 1.8144404888153076, "rejected_reward": -1.5265655517578125, "time": 1765819343.9316711}
{"stage": "dpo", "step": 33550, "epoch": 525, "train_loss": 0.05927900612354278, "policy_chosen_logp": -20.094636917114258, "policy_rejected_logp": -1041.926513671875, "ref_chosen_logp": -32.182762145996094, "ref_rejected_logp": -1022.5416259765625, "chosen_reward": 1.2088124752044678, "rejected_reward": -1.9384856224060059, "time": 1765819346.4383109}
{"stage": "dpo", "step": 33600, "epoch": 525, "train_loss": 0.20913056403398514, "policy_chosen_logp": -18.34058952331543, "policy_rejected_logp": -1090.9228515625, "ref_chosen_logp": -39.96825408935547, "ref_rejected_logp": -1079.780029296875, "chosen_reward": 2.162766456604004, "rejected_reward": -1.1142791509628296, "time": 1765819348.939132}
{"stage": "dpo", "step": 33600, "epoch": 525, "val_pref_acc": 1.0, "time": 1765819349.0686314}
{"stage": "dpo", "step": 33650, "epoch": 526, "train_loss": 0.21097459077835082, "policy_chosen_logp": -18.796804428100586, "policy_rejected_logp": -1099.550537109375, "ref_chosen_logp": -44.19563674926758, "ref_rejected_logp": -1092.075439453125, "chosen_reward": 2.5398833751678467, "rejected_reward": -0.7475204467773438, "time": 1765819351.4063427}
{"stage": "dpo", "step": 33700, "epoch": 527, "train_loss": 0.15291689842939377, "policy_chosen_logp": -10.42257308959961, "policy_rejected_logp": -1061.138427734375, "ref_chosen_logp": -22.893356323242188, "ref_rejected_logp": -1041.77099609375, "chosen_reward": 1.2470784187316895, "rejected_reward": -1.9367386102676392, "time": 1765819353.8787818}
{"stage": "dpo", "step": 33750, "epoch": 528, "train_loss": 0.09250696480274201, "policy_chosen_logp": -20.732563018798828, "policy_rejected_logp": -1063.15576171875, "ref_chosen_logp": -30.67316436767578, "ref_rejected_logp": -1033.621337890625, "chosen_reward": 0.9940603971481323, "rejected_reward": -2.953444004058838, "time": 1765819356.3426256}
{"stage": "dpo", "step": 33800, "epoch": 529, "train_loss": 0.03392480045557022, "policy_chosen_logp": -19.927143096923828, "policy_rejected_logp": -1056.6175537109375, "ref_chosen_logp": -32.61791229248047, "ref_rejected_logp": -1034.634765625, "chosen_reward": 1.269076943397522, "rejected_reward": -2.1982834339141846, "time": 1765819358.8181584}
{"stage": "dpo", "step": 33850, "epoch": 529, "train_loss": 0.21096669912338256, "policy_chosen_logp": -19.223773956298828, "policy_rejected_logp": -1013.9764404296875, "ref_chosen_logp": -25.098987579345703, "ref_rejected_logp": -993.5184326171875, "chosen_reward": 0.5875216126441956, "rejected_reward": -2.045804023742676, "time": 1765819361.2839427}
{"stage": "dpo", "step": 33900, "epoch": 530, "train_loss": 0.18418982416391372, "policy_chosen_logp": -11.665130615234375, "policy_rejected_logp": -1088.554931640625, "ref_chosen_logp": -36.24700927734375, "ref_rejected_logp": -1081.2935791015625, "chosen_reward": 2.458188056945801, "rejected_reward": -0.7261368036270142, "time": 1765819363.7444868}
{"stage": "dpo", "step": 33920, "epoch": 530, "val_pref_acc": 1.0, "time": 1765819364.8601246}
{"stage": "dpo", "step": 33950, "epoch": 531, "train_loss": 0.12643381595611572, "policy_chosen_logp": -17.945873260498047, "policy_rejected_logp": -978.5277099609375, "ref_chosen_logp": -27.30217933654785, "ref_rejected_logp": -958.3197021484375, "chosen_reward": 0.9356305599212646, "rejected_reward": -2.020803928375244, "time": 1765819366.2054548}
{"stage": "dpo", "step": 34000, "epoch": 532, "train_loss": 0.06729357570409775, "policy_chosen_logp": -15.977117538452148, "policy_rejected_logp": -1013.6358642578125, "ref_chosen_logp": -29.755149841308594, "ref_rejected_logp": -994.4852294921875, "chosen_reward": 1.377803087234497, "rejected_reward": -1.915055751800537, "time": 1765819368.417588}
{"stage": "dpo", "step": 34050, "epoch": 533, "train_loss": 0.008520035445690155, "policy_chosen_logp": -25.05306053161621, "policy_rejected_logp": -1134.23681640625, "ref_chosen_logp": -48.98759460449219, "ref_rejected_logp": -1125.9208984375, "chosen_reward": 2.393453598022461, "rejected_reward": -0.8315888047218323, "time": 1765819370.8876283}
{"stage": "dpo", "step": 34100, "epoch": 533, "train_loss": 0.21261242419481277, "policy_chosen_logp": -20.259212493896484, "policy_rejected_logp": -1012.128662109375, "ref_chosen_logp": -39.20553970336914, "ref_rejected_logp": -995.895263671875, "chosen_reward": 1.8946325778961182, "rejected_reward": -1.62334144115448, "time": 1765819373.3627996}
{"stage": "dpo", "step": 34150, "epoch": 534, "train_loss": 0.1609366711974144, "policy_chosen_logp": -17.37889862060547, "policy_rejected_logp": -967.4702758789062, "ref_chosen_logp": -33.43579864501953, "ref_rejected_logp": -951.78173828125, "chosen_reward": 1.6056897640228271, "rejected_reward": -1.5688552856445312, "time": 1765819375.8443468}
{"stage": "dpo", "step": 34200, "epoch": 535, "train_loss": 0.10046799570322036, "policy_chosen_logp": -19.053586959838867, "policy_rejected_logp": -960.1544189453125, "ref_chosen_logp": -31.365713119506836, "ref_rejected_logp": -941.5162963867188, "chosen_reward": 1.2312124967575073, "rejected_reward": -1.8638153076171875, "time": 1765819378.3625822}
{"stage": "dpo", "step": 34240, "epoch": 535, "val_pref_acc": 1.0, "time": 1765819380.5157752}
{"stage": "dpo", "step": 34250, "epoch": 536, "train_loss": 0.042380552589893344, "policy_chosen_logp": -19.929340362548828, "policy_rejected_logp": -1021.2648315429688, "ref_chosen_logp": -35.421302795410156, "ref_rejected_logp": -1008.2472534179688, "chosen_reward": 1.549196481704712, "rejected_reward": -1.3017578125, "time": 1765819380.912504}
{"stage": "dpo", "step": 34300, "epoch": 536, "train_loss": 0.21156845808029176, "policy_chosen_logp": -26.144689559936523, "policy_rejected_logp": -1045.326416015625, "ref_chosen_logp": -40.33460235595703, "ref_rejected_logp": -1028.921875, "chosen_reward": 1.4189913272857666, "rejected_reward": -1.640451192855835, "time": 1765819383.398761}
{"stage": "dpo", "step": 34350, "epoch": 537, "train_loss": 0.19629001915454863, "policy_chosen_logp": -16.761470794677734, "policy_rejected_logp": -1105.046875, "ref_chosen_logp": -30.565805435180664, "ref_rejected_logp": -1084.706298828125, "chosen_reward": 1.3804336786270142, "rejected_reward": -2.0340728759765625, "time": 1765819385.8856893}
{"stage": "dpo", "step": 34400, "epoch": 538, "train_loss": 0.13425560683012008, "policy_chosen_logp": -23.056673049926758, "policy_rejected_logp": -1064.7177734375, "ref_chosen_logp": -42.357032775878906, "ref_rejected_logp": -1049.165771484375, "chosen_reward": 1.9300355911254883, "rejected_reward": -1.5552048683166504, "time": 1765819388.3547776}
{"stage": "dpo", "step": 34450, "epoch": 539, "train_loss": 0.07574602276086807, "policy_chosen_logp": -23.802227020263672, "policy_rejected_logp": -1045.947021484375, "ref_chosen_logp": -28.282005310058594, "ref_rejected_logp": -1020.0057983398438, "chosen_reward": 0.44797781109809875, "rejected_reward": -2.5941224098205566, "time": 1765819390.8320177}
{"stage": "dpo", "step": 34500, "epoch": 540, "train_loss": 0.016866285502910614, "policy_chosen_logp": -23.32436752319336, "policy_rejected_logp": -1102.04052734375, "ref_chosen_logp": -44.411407470703125, "ref_rejected_logp": -1089.314697265625, "chosen_reward": 2.108703851699829, "rejected_reward": -1.2725830078125, "time": 1765819393.0145051}
{"stage": "dpo", "step": 34550, "epoch": 540, "train_loss": 0.2113289412856102, "policy_chosen_logp": -12.991830825805664, "policy_rejected_logp": -929.5313720703125, "ref_chosen_logp": -28.44141387939453, "ref_rejected_logp": -913.2269897460938, "chosen_reward": 1.5449583530426025, "rejected_reward": -1.630438208580017, "time": 1765819394.660581}
{"stage": "dpo", "step": 34560, "epoch": 540, "val_pref_acc": 1.0, "time": 1765819395.2791579}
{"stage": "dpo", "step": 34600, "epoch": 541, "train_loss": 0.1681741803884506, "policy_chosen_logp": -17.535316467285156, "policy_rejected_logp": -1106.7889404296875, "ref_chosen_logp": -32.092308044433594, "ref_rejected_logp": -1090.615966796875, "chosen_reward": 1.4556992053985596, "rejected_reward": -1.6172974109649658, "time": 1765819397.1266448}
{"stage": "dpo", "step": 34650, "epoch": 542, "train_loss": 0.10848479807376861, "policy_chosen_logp": -11.093152046203613, "policy_rejected_logp": -1020.9424438476562, "ref_chosen_logp": -19.372631072998047, "ref_rejected_logp": -993.4285278320312, "chosen_reward": 0.8279479146003723, "rejected_reward": -2.751387119293213, "time": 1765819399.609928}
{"stage": "dpo", "step": 34700, "epoch": 543, "train_loss": 0.050946674942970276, "policy_chosen_logp": -19.503767013549805, "policy_rejected_logp": -1118.74462890625, "ref_chosen_logp": -50.666893005371094, "ref_rejected_logp": -1118.7177734375, "chosen_reward": 3.1163127422332764, "rejected_reward": -0.0026871562004089355, "time": 1765819402.097514}
{"stage": "dpo", "step": 34750, "epoch": 543, "train_loss": 0.20926376909017563, "policy_chosen_logp": -13.294368743896484, "policy_rejected_logp": -1063.421142578125, "ref_chosen_logp": -29.033349990844727, "ref_rejected_logp": -1041.980712890625, "chosen_reward": 1.5738979578018188, "rejected_reward": -2.144038200378418, "time": 1765819404.2736742}
{"stage": "dpo", "step": 34800, "epoch": 544, "train_loss": 0.19957850843667985, "policy_chosen_logp": -18.910505294799805, "policy_rejected_logp": -1047.6495361328125, "ref_chosen_logp": -43.68129348754883, "ref_rejected_logp": -1044.8984375, "chosen_reward": 2.477078914642334, "rejected_reward": -0.27510374784469604, "time": 1765819406.7448843}
{"stage": "dpo", "step": 34850, "epoch": 545, "train_loss": 0.14349137961864472, "policy_chosen_logp": -17.181346893310547, "policy_rejected_logp": -1113.05712890625, "ref_chosen_logp": -30.147850036621094, "ref_rejected_logp": -1088.8603515625, "chosen_reward": 1.2966505289077759, "rejected_reward": -2.4196977615356445, "time": 1765819409.098276}
{"stage": "dpo", "step": 34880, "epoch": 545, "val_pref_acc": 1.0, "time": 1765819410.7071154}
{"stage": "dpo", "step": 34900, "epoch": 546, "train_loss": 0.0849218451976776, "policy_chosen_logp": -18.249366760253906, "policy_rejected_logp": -1021.3782958984375, "ref_chosen_logp": -37.432167053222656, "ref_rejected_logp": -1014.9957275390625, "chosen_reward": 1.918280005455017, "rejected_reward": -0.6382538080215454, "time": 1765819411.565387}
{"stage": "dpo", "step": 34950, "epoch": 547, "train_loss": 0.02465567797422409, "policy_chosen_logp": -16.987834930419922, "policy_rejected_logp": -987.9013671875, "ref_chosen_logp": -32.84621047973633, "ref_rejected_logp": -969.3463134765625, "chosen_reward": 1.585837721824646, "rejected_reward": -1.8555039167404175, "time": 1765819413.9902468}
{"stage": "dpo", "step": 35000, "epoch": 547, "train_loss": 0.2112233704328537, "policy_chosen_logp": -21.64041519165039, "policy_rejected_logp": -1147.83154296875, "ref_chosen_logp": -39.20635223388672, "ref_rejected_logp": -1135.81787109375, "chosen_reward": 1.7565937042236328, "rejected_reward": -1.2013611793518066, "time": 1765819416.4588304}
{"stage": "dpo", "step": 35050, "epoch": 548, "train_loss": 0.17554844975471495, "policy_chosen_logp": -17.523887634277344, "policy_rejected_logp": -1030.770263671875, "ref_chosen_logp": -48.15674591064453, "ref_rejected_logp": -1031.2493896484375, "chosen_reward": 3.0632858276367188, "rejected_reward": 0.0479126013815403, "time": 1765819418.9361825}
{"stage": "dpo", "step": 35100, "epoch": 549, "train_loss": 0.11721337735652923, "policy_chosen_logp": -21.832168579101562, "policy_rejected_logp": -1036.1961669921875, "ref_chosen_logp": -33.366905212402344, "ref_rejected_logp": -1013.8698120117188, "chosen_reward": 1.1534734964370728, "rejected_reward": -2.2326340675354004, "time": 1765819421.407655}
{"stage": "dpo", "step": 35150, "epoch": 550, "train_loss": 0.05891622394323349, "policy_chosen_logp": -27.156837463378906, "policy_rejected_logp": -979.8046264648438, "ref_chosen_logp": -38.28607177734375, "ref_rejected_logp": -962.0382690429688, "chosen_reward": 1.1129236221313477, "rejected_reward": -1.776637315750122, "time": 1765819423.8906758}
{"stage": "dpo", "step": 35200, "epoch": 550, "train_loss": 0.21052359730005266, "policy_chosen_logp": -17.308761596679688, "policy_rejected_logp": -1114.41552734375, "ref_chosen_logp": -32.07935333251953, "ref_rejected_logp": -1099.0115966796875, "chosen_reward": 1.4770593643188477, "rejected_reward": -1.5403945446014404, "time": 1765819426.3578882}
{"stage": "dpo", "step": 35200, "epoch": 550, "val_pref_acc": 1.0, "time": 1765819426.4872518}
{"stage": "dpo", "step": 35250, "epoch": 551, "train_loss": 0.2091743355989456, "policy_chosen_logp": -13.647680282592773, "policy_rejected_logp": -1114.3590087890625, "ref_chosen_logp": -33.13056564331055, "ref_rejected_logp": -1104.931640625, "chosen_reward": 1.9482886791229248, "rejected_reward": -0.9427444934844971, "time": 1765819428.821037}
{"stage": "dpo", "step": 35300, "epoch": 552, "train_loss": 0.15058980643749237, "policy_chosen_logp": -19.617515563964844, "policy_rejected_logp": -1067.033935546875, "ref_chosen_logp": -36.178226470947266, "ref_rejected_logp": -1052.3671875, "chosen_reward": 1.656071424484253, "rejected_reward": -1.4666671752929688, "time": 1765819431.3271987}
{"stage": "dpo", "step": 35350, "epoch": 553, "train_loss": 0.09137194067239761, "policy_chosen_logp": -18.383543014526367, "policy_rejected_logp": -1009.6561889648438, "ref_chosen_logp": -36.29051971435547, "ref_rejected_logp": -994.787109375, "chosen_reward": 1.790697693824768, "rejected_reward": -1.4869126081466675, "time": 1765819433.792851}
{"stage": "dpo", "step": 35400, "epoch": 554, "train_loss": 0.03324771523475647, "policy_chosen_logp": -15.881267547607422, "policy_rejected_logp": -1057.2548828125, "ref_chosen_logp": -32.40788650512695, "ref_rejected_logp": -1040.60009765625, "chosen_reward": 1.6526620388031006, "rejected_reward": -1.6654800176620483, "time": 1765819436.2534142}
{"stage": "dpo", "step": 35450, "epoch": 554, "train_loss": 0.21054145991802214, "policy_chosen_logp": -19.7534122467041, "policy_rejected_logp": -1020.04296875, "ref_chosen_logp": -44.04200744628906, "ref_rejected_logp": -1009.9539794921875, "chosen_reward": 2.428859233856201, "rejected_reward": -1.00890052318573, "time": 1765819438.727095}
{"stage": "dpo", "step": 35500, "epoch": 555, "train_loss": 0.1831481310725212, "policy_chosen_logp": -17.28331184387207, "policy_rejected_logp": -990.357421875, "ref_chosen_logp": -36.632484436035156, "ref_rejected_logp": -981.285888671875, "chosen_reward": 1.9349174499511719, "rejected_reward": -0.9071547985076904, "time": 1765819441.1993098}
{"stage": "dpo", "step": 35520, "epoch": 555, "val_pref_acc": 1.0, "time": 1765819442.3186727}
{"stage": "dpo", "step": 35550, "epoch": 556, "train_loss": 0.12668108493089675, "policy_chosen_logp": -16.85020637512207, "policy_rejected_logp": -1093.267578125, "ref_chosen_logp": -34.415061950683594, "ref_rejected_logp": -1077.3021240234375, "chosen_reward": 1.756485939025879, "rejected_reward": -1.5965485572814941, "time": 1765819443.6742895}
{"stage": "dpo", "step": 35600, "epoch": 557, "train_loss": 0.0674860081076622, "policy_chosen_logp": -17.279525756835938, "policy_rejected_logp": -950.5335693359375, "ref_chosen_logp": -34.9567756652832, "ref_rejected_logp": -932.577392578125, "chosen_reward": 1.7677249908447266, "rejected_reward": -1.7956206798553467, "time": 1765819446.1723952}
{"stage": "dpo", "step": 35650, "epoch": 558, "train_loss": 0.00874893605709076, "policy_chosen_logp": -20.3414306640625, "policy_rejected_logp": -1063.30615234375, "ref_chosen_logp": -32.94184875488281, "ref_rejected_logp": -1046.135009765625, "chosen_reward": 1.2600417137145996, "rejected_reward": -1.7171142101287842, "time": 1765819448.6707668}
{"stage": "dpo", "step": 35700, "epoch": 558, "train_loss": 0.2100340709090233, "policy_chosen_logp": -19.50082778930664, "policy_rejected_logp": -1014.257568359375, "ref_chosen_logp": -31.53792953491211, "ref_rejected_logp": -997.6961669921875, "chosen_reward": 1.2037100791931152, "rejected_reward": -1.656143307685852, "time": 1765819451.1315196}
{"stage": "dpo", "step": 35750, "epoch": 559, "train_loss": 0.15891192853450775, "policy_chosen_logp": -22.40499496459961, "policy_rejected_logp": -1081.681884765625, "ref_chosen_logp": -31.62008285522461, "ref_rejected_logp": -1050.719970703125, "chosen_reward": 0.9215087294578552, "rejected_reward": -3.0961899757385254, "time": 1765819453.5943825}
{"stage": "dpo", "step": 35800, "epoch": 560, "train_loss": 0.09965220510959626, "policy_chosen_logp": -20.018089294433594, "policy_rejected_logp": -1048.41796875, "ref_chosen_logp": -29.22378921508789, "ref_rejected_logp": -1030.6153564453125, "chosen_reward": 0.9205700755119324, "rejected_reward": -1.7802550792694092, "time": 1765819456.0596025}
{"stage": "dpo", "step": 35840, "epoch": 560, "val_pref_acc": 1.0, "time": 1765819458.154999}
{"stage": "dpo", "step": 35850, "epoch": 561, "train_loss": 0.04236969590187073, "policy_chosen_logp": -14.538935661315918, "policy_rejected_logp": -1035.185302734375, "ref_chosen_logp": -35.78215408325195, "ref_rejected_logp": -1032.88818359375, "chosen_reward": 2.124321937561035, "rejected_reward": -0.22973021864891052, "time": 1765819458.5509875}
{"stage": "dpo", "step": 35900, "epoch": 561, "train_loss": 0.2081218382716179, "policy_chosen_logp": -19.582395553588867, "policy_rejected_logp": -1044.20751953125, "ref_chosen_logp": -33.37881088256836, "ref_rejected_logp": -1021.9149780273438, "chosen_reward": 1.3796417713165283, "rejected_reward": -2.229261875152588, "time": 1765819460.9838922}
{"stage": "dpo", "step": 35950, "epoch": 562, "train_loss": 0.19219304740428925, "policy_chosen_logp": -18.26991081237793, "policy_rejected_logp": -1023.5042724609375, "ref_chosen_logp": -41.4884033203125, "ref_rejected_logp": -1014.7284545898438, "chosen_reward": 2.3218493461608887, "rejected_reward": -0.8775787949562073, "time": 1765819463.475012}
{"stage": "dpo", "step": 36000, "epoch": 563, "train_loss": 0.13702019304037094, "policy_chosen_logp": -18.00979995727539, "policy_rejected_logp": -962.767578125, "ref_chosen_logp": -31.268310546875, "ref_rejected_logp": -945.7525634765625, "chosen_reward": 1.325851321220398, "rejected_reward": -1.7014985084533691, "time": 1765819465.9596689}
{"stage": "dpo", "step": 36050, "epoch": 564, "train_loss": 0.07607933908700942, "policy_chosen_logp": -15.256628036499023, "policy_rejected_logp": -1100.6358642578125, "ref_chosen_logp": -32.46894454956055, "ref_rejected_logp": -1086.8704833984375, "chosen_reward": 1.7212318181991577, "rejected_reward": -1.3765381574630737, "time": 1765819468.4597068}
{"stage": "dpo", "step": 36100, "epoch": 565, "train_loss": 0.0166729861497879, "policy_chosen_logp": -15.670963287353516, "policy_rejected_logp": -1077.672119140625, "ref_chosen_logp": -37.96406555175781, "ref_rejected_logp": -1072.513671875, "chosen_reward": 2.2293102741241455, "rejected_reward": -0.5158401727676392, "time": 1765819470.938904}
{"stage": "dpo", "step": 36150, "epoch": 565, "train_loss": 0.2109505471587181, "policy_chosen_logp": -20.112751007080078, "policy_rejected_logp": -993.4066772460938, "ref_chosen_logp": -41.59561538696289, "ref_rejected_logp": -983.22998046875, "chosen_reward": 2.148286819458008, "rejected_reward": -1.0176727771759033, "time": 1765819473.4339359}
{"stage": "dpo", "step": 36160, "epoch": 565, "val_pref_acc": 1.0, "time": 1765819474.0589483}
{"stage": "dpo", "step": 36200, "epoch": 566, "train_loss": 0.16622663348913191, "policy_chosen_logp": -12.323974609375, "policy_rejected_logp": -1021.1690673828125, "ref_chosen_logp": -18.603120803833008, "ref_rejected_logp": -992.5870971679688, "chosen_reward": 0.627914547920227, "rejected_reward": -2.8582000732421875, "time": 1765819475.9149103}
{"stage": "dpo", "step": 36250, "epoch": 567, "train_loss": 0.10774564653635026, "policy_chosen_logp": -14.873347282409668, "policy_rejected_logp": -1049.896484375, "ref_chosen_logp": -25.447093963623047, "ref_rejected_logp": -1028.93896484375, "chosen_reward": 1.0573745965957642, "rejected_reward": -2.0957443714141846, "time": 1765819478.4062474}
{"stage": "dpo", "step": 36300, "epoch": 568, "train_loss": 0.05013045817613602, "policy_chosen_logp": -18.25387954711914, "policy_rejected_logp": -1117.34619140625, "ref_chosen_logp": -46.29499435424805, "ref_rejected_logp": -1109.7618408203125, "chosen_reward": 2.8041117191314697, "rejected_reward": -0.7584228515625, "time": 1765819480.8986564}
{"stage": "dpo", "step": 36350, "epoch": 568, "train_loss": 0.20896118491888047, "policy_chosen_logp": -15.374089241027832, "policy_rejected_logp": -1076.427734375, "ref_chosen_logp": -34.61540603637695, "ref_rejected_logp": -1058.807861328125, "chosen_reward": 1.924131989479065, "rejected_reward": -1.7620058059692383, "time": 1765819483.373418}
{"stage": "dpo", "step": 36400, "epoch": 569, "train_loss": 0.2029249557852745, "policy_chosen_logp": -18.43550682067871, "policy_rejected_logp": -925.7294921875, "ref_chosen_logp": -33.91176986694336, "ref_rejected_logp": -902.6304931640625, "chosen_reward": 1.5476263761520386, "rejected_reward": -2.3099000453948975, "time": 1765819485.8144789}
{"stage": "dpo", "step": 36450, "epoch": 570, "train_loss": 0.14226579666137695, "policy_chosen_logp": -14.202496528625488, "policy_rejected_logp": -1057.897216796875, "ref_chosen_logp": -43.449771881103516, "ref_rejected_logp": -1058.6402587890625, "chosen_reward": 2.924727439880371, "rejected_reward": 0.07430876791477203, "time": 1765819488.271056}
{"stage": "dpo", "step": 36480, "epoch": 570, "val_pref_acc": 1.0, "time": 1765819489.571141}
{"stage": "dpo", "step": 36500, "epoch": 571, "train_loss": 0.08300681978464126, "policy_chosen_logp": -13.385305404663086, "policy_rejected_logp": -967.3587646484375, "ref_chosen_logp": -35.90464782714844, "ref_rejected_logp": -960.2885131835938, "chosen_reward": 2.251934051513672, "rejected_reward": -0.7070205807685852, "time": 1765819490.4133372}
{"stage": "dpo", "step": 36550, "epoch": 572, "train_loss": 0.025973308980464935, "policy_chosen_logp": -13.447678565979004, "policy_rejected_logp": -1064.385498046875, "ref_chosen_logp": -29.17706298828125, "ref_rejected_logp": -1044.065673828125, "chosen_reward": 1.5729384422302246, "rejected_reward": -2.0319716930389404, "time": 1765819492.8958883}
{"stage": "dpo", "step": 36600, "epoch": 572, "train_loss": 0.20983029246330262, "policy_chosen_logp": -14.424238204956055, "policy_rejected_logp": -1045.0469970703125, "ref_chosen_logp": -28.092185974121094, "ref_rejected_logp": -1024.190185546875, "chosen_reward": 1.3667948246002197, "rejected_reward": -2.085676670074463, "time": 1765819495.3557076}
{"stage": "dpo", "step": 36650, "epoch": 573, "train_loss": 0.17505835890769958, "policy_chosen_logp": -13.009465217590332, "policy_rejected_logp": -1118.043701171875, "ref_chosen_logp": -29.744739532470703, "ref_rejected_logp": -1100.004150390625, "chosen_reward": 1.673527717590332, "rejected_reward": -1.803959608078003, "time": 1765819497.8164206}
{"stage": "dpo", "step": 36700, "epoch": 574, "train_loss": 0.11794736713171006, "policy_chosen_logp": -15.372421264648438, "policy_rejected_logp": -1014.443603515625, "ref_chosen_logp": -22.75994110107422, "ref_rejected_logp": -993.9963989257812, "chosen_reward": 0.738752007484436, "rejected_reward": -2.044720411300659, "time": 1765819500.2160945}
{"stage": "dpo", "step": 36750, "epoch": 575, "train_loss": 0.05835335075855255, "policy_chosen_logp": -10.623937606811523, "policy_rejected_logp": -977.066162109375, "ref_chosen_logp": -24.757028579711914, "ref_rejected_logp": -963.0667724609375, "chosen_reward": 1.4133089780807495, "rejected_reward": -1.399932861328125, "time": 1765819502.679101}
{"stage": "dpo", "step": 36800, "epoch": 575, "train_loss": 0.2098111292719841, "policy_chosen_logp": -33.5704460144043, "policy_rejected_logp": -1053.1998291015625, "ref_chosen_logp": -54.047508239746094, "ref_rejected_logp": -1039.4326171875, "chosen_reward": 2.04770565032959, "rejected_reward": -1.376718282699585, "time": 1765819505.1399765}
{"stage": "dpo", "step": 36800, "epoch": 575, "val_pref_acc": 1.0, "time": 1765819505.2686567}
{"stage": "dpo", "step": 36850, "epoch": 576, "train_loss": 0.20961226642131806, "policy_chosen_logp": -18.5924129486084, "policy_rejected_logp": -1013.5230712890625, "ref_chosen_logp": -40.05076599121094, "ref_rejected_logp": -1000.6146240234375, "chosen_reward": 2.1458353996276855, "rejected_reward": -1.2908446788787842, "time": 1765819507.6315}
{"stage": "dpo", "step": 36900, "epoch": 577, "train_loss": 0.15115984469652177, "policy_chosen_logp": -23.647438049316406, "policy_rejected_logp": -982.9736328125, "ref_chosen_logp": -36.66359329223633, "ref_rejected_logp": -965.8762817382812, "chosen_reward": 1.3016154766082764, "rejected_reward": -1.7097320556640625, "time": 1765819510.144611}
{"stage": "dpo", "step": 36950, "epoch": 578, "train_loss": 0.09111552506685257, "policy_chosen_logp": -19.049240112304688, "policy_rejected_logp": -976.9357299804688, "ref_chosen_logp": -40.5075798034668, "ref_rejected_logp": -966.4955444335938, "chosen_reward": 2.145833969116211, "rejected_reward": -1.0440139770507812, "time": 1765819512.647552}
{"stage": "dpo", "step": 37000, "epoch": 579, "train_loss": 0.033125299811363224, "policy_chosen_logp": -14.309820175170898, "policy_rejected_logp": -1097.9443359375, "ref_chosen_logp": -30.327049255371094, "ref_rejected_logp": -1077.915283203125, "chosen_reward": 1.601723074913025, "rejected_reward": -2.0029008388519287, "time": 1765819515.1345184}
{"stage": "dpo", "step": 37050, "epoch": 579, "train_loss": 0.20810760140419007, "policy_chosen_logp": -11.949577331542969, "policy_rejected_logp": -992.3846435546875, "ref_chosen_logp": -26.760311126708984, "ref_rejected_logp": -969.75048828125, "chosen_reward": 1.4810733795166016, "rejected_reward": -2.263411045074463, "time": 1765819517.6318355}
{"stage": "dpo", "step": 37100, "epoch": 580, "train_loss": 0.18585321605205535, "policy_chosen_logp": -14.806117057800293, "policy_rejected_logp": -1012.1422729492188, "ref_chosen_logp": -38.06732177734375, "ref_rejected_logp": -1003.9020385742188, "chosen_reward": 2.326120376586914, "rejected_reward": -0.8240264654159546, "time": 1765819520.123512}
{"stage": "dpo", "step": 37107, "epoch": 580, "val_pref_acc": 1.0, "time": 1765819520.5943258}
