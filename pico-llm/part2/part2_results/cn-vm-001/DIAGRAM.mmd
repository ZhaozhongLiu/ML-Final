flowchart TD
  A[Input text prompts] --> B[Tokenizer]
  B --> C{Model Type}

  subgraph M[Language Model]
    C --> T[Transformer LM]
    C --> L[LSTM LM]
    C --> K[k-gram MLP]
  end

  subgraph P[Part2 Training Pipeline]
    D[TinyStories (pretrain corpus)] --> E[Pretrain base LM]
    F[Teacher LLM (DeepSeek/OpenAI-compatible)] --> G[Dataset Generator]
    G --> H[SFT dataset (prompt, answer)]
    G --> I[DPO dataset (prompt, chosen, rejected)]
    E --> J[SFT training]
    J --> K[DPO training]
    H --> J
    I --> K
    K --> Q[Final checkpoint]
  end

  Q --> R[Evaluation & Plots]
  Q --> S[Play / Inference CLI]
